{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5939cfd1160c7faa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-28T10:41:29.545164Z",
     "start_time": "2024-07-28T10:41:28.872080Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Jul 28 18:41:28 2024       \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 535.183.01             Driver Version: 535.183.01   CUDA Version: 12.2     |\r\n",
      "|-----------------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                      |               MIG M. |\r\n",
      "|=========================================+======================+======================|\r\n",
      "|   0  NVIDIA RTX A6000               Off | 00000000:01:00.0 Off |                  Off |\r\n",
      "| 30%   34C    P8              33W / 300W |      1MiB / 49140MiB |      0%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "|   1  NVIDIA RTX A6000               Off | 00000000:21:00.0 Off |                  Off |\r\n",
      "| 30%   33C    P8              26W / 300W |      1MiB / 49140MiB |      0%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "|   2  NVIDIA RTX A6000               Off | 00000000:41:00.0 Off |                  Off |\r\n",
      "| 32%   64C    P2             236W / 300W |  13274MiB / 49140MiB |     73%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "|   3  NVIDIA RTX A6000               Off | 00000000:42:00.0 Off |                  Off |\r\n",
      "| 49%   74C    P2             295W / 300W |  46368MiB / 49140MiB |     73%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                            |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\r\n",
      "|        ID   ID                                                             Usage      |\r\n",
      "|=======================================================================================|\r\n",
      "|    2   N/A  N/A   1830232      C   python                                    13268MiB |\r\n",
      "|    3   N/A  N/A   1808150      C   python                                    46362MiB |\r\n",
      "+---------------------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a810a7623eebb61b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-28T10:41:29.550612Z",
     "start_time": "2024-07-28T10:41:29.546829Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T17:30:41.618344Z",
     "start_time": "2024-06-06T17:30:22.689300Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/FYP/on0008an/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running CrowS-Pairs benchmark:\r\n",
      " - persistent_dir: /home/FYP/on0008an/bias-bench-main\r\n",
      " - model: BertForMaskedLM\r\n",
      " - model_name_or_path: bert-base-uncased\r\n",
      " - bias_type: gender\r\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\r\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\r\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\r\n",
      "Evaluating gender examples.\r\n",
      "100%|█████████████████████████████████████████| 262/262 [00:06<00:00, 40.01it/s]\r\n",
      "====================================================================================================\r\n",
      "Total examples: 262\r\n",
      "Metric score: 57.25\r\n",
      "Stereotype score: 57.86\r\n",
      "Anti-stereotype score: 56.31\r\n",
      "Num. neutral: 0.0\r\n",
      "====================================================================================================\r\n",
      "\r\n",
      "Metric: 57.25\r\n"
     ]
    }
   ],
   "source": [
    "!python crows.py --bias_type \"gender\" --model \"BertForMaskedLM\" --model_name_or_path \"bert-base-uncased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "961079de023cb4be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T13:45:48.542216Z",
     "start_time": "2024-06-03T13:45:30.651015Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/FYP/on0008an/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running CrowS-Pairs benchmark:\r\n",
      " - persistent_dir: /home/FYP/on0008an/bias-bench-main\r\n",
      " - model: AlbertForMaskedLM\r\n",
      " - model_name_or_path: albert-base-v2\r\n",
      " - bias_type: gender\r\n",
      "Some weights of the model checkpoint at albert-base-v2 were not used when initializing AlbertForMaskedLM: ['albert.pooler.bias', 'albert.pooler.weight']\r\n",
      "- This IS expected if you are initializing AlbertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\r\n",
      "- This IS NOT expected if you are initializing AlbertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\r\n",
      "Evaluating gender examples.\r\n",
      "100%|█████████████████████████████████████████| 262/262 [00:09<00:00, 28.98it/s]\r\n",
      "====================================================================================================\r\n",
      "Total examples: 262\r\n",
      "Metric score: 48.09\r\n",
      "Stereotype score: 47.8\r\n",
      "Anti-stereotype score: 48.54\r\n",
      "Num. neutral: 0.0\r\n",
      "====================================================================================================\r\n",
      "\r\n",
      "Metric: 48.09\r\n"
     ]
    }
   ],
   "source": [
    "!python crows.py --bias_type \"gender\" --model \"AlbertForMaskedLM\" --model_name_or_path \"albert-base-v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "612c0ff6a4f4f4af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T13:46:06.675010Z",
     "start_time": "2024-06-03T13:45:48.543668Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/FYP/on0008an/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running CrowS-Pairs benchmark:\r\n",
      " - persistent_dir: /home/FYP/on0008an/bias-bench-main\r\n",
      " - model: RobertaForMaskedLM\r\n",
      " - model_name_or_path: roberta-base\r\n",
      " - bias_type: gender\r\n",
      "Evaluating gender examples.\r\n",
      " 94%|██████████████████████████████████████▎  | 245/262 [00:08<00:00, 36.71it/s]Skipping example 245.\r\n",
      "100%|████████████████████████████████████████▊| 261/262 [00:09<00:00, 29.00it/s]\r\n",
      "====================================================================================================\r\n",
      "Total examples: 261\r\n",
      "Metric score: 60.15\r\n",
      "Stereotype score: 67.92\r\n",
      "Anti-stereotype score: 48.04\r\n",
      "Num. neutral: 0.0\r\n",
      "====================================================================================================\r\n",
      "\r\n",
      "Metric: 60.15\r\n"
     ]
    }
   ],
   "source": [
    "!python crows.py --bias_type \"gender\" --model \"RobertaForMaskedLM\" --model_name_or_path \"roberta-base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ba6dba7bc502e3f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-28T10:42:09.069126Z",
     "start_time": "2024-07-28T10:41:29.551619Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running CrowS-Pairs benchmark:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: GPT2LMHeadModel\r\n",
      " - model_name_or_path: gpt2\r\n",
      " - bias_type: None\r\n",
      "Evaluating race-color examples.\r\n",
      "Unconditional start token: <|endoftext|>\r\n",
      "100%|█████████████████████████████████████████| 516/516 [00:20<00:00, 24.85it/s]\r\n",
      "====================================================================================================\r\n",
      "Total examples: 516\r\n",
      "Metric score: 57.95\r\n",
      "Stereotype score: 57.84\r\n",
      "Anti-stereotype score: 60.47\r\n",
      "Num. neutral: 0.19\r\n",
      "====================================================================================================\r\n",
      "\r\n",
      "Evaluating gender examples.\r\n",
      "Unconditional start token: <|endoftext|>\r\n",
      "100%|█████████████████████████████████████████| 262/262 [00:09<00:00, 28.68it/s]\r\n",
      "====================================================================================================\r\n",
      "Total examples: 262\r\n",
      "Metric score: 54.96\r\n",
      "Stereotype score: 52.83\r\n",
      "Anti-stereotype score: 58.25\r\n",
      "Num. neutral: 0.0\r\n",
      "====================================================================================================\r\n",
      "\r\n",
      "Evaluating socioeconomic examples.\r\n",
      "Unconditional start token: <|endoftext|>\r\n",
      "  4%|█▊                                         | 7/172 [00:00<00:05, 29.44it/s]^C\r\n",
      "  5%|██▎                                        | 9/172 [00:00<00:05, 27.99it/s]\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/home/ongzhiyang/bias-bench-main/experiments/crows.py\", line 103, in <module>\r\n",
      "    results = runner()\r\n",
      "  File \"/home/ongzhiyang/bias-bench-main/bias_bench/benchmark/crows/crows.py\", line 84, in __call__\r\n",
      "    result = self._likelihood_score_generative() if self._is_generative else self._likelihood_score()\r\n",
      "  File \"/home/ongzhiyang/bias-bench-main/bias_bench/benchmark/crows/crows.py\", line 259, in _likelihood_score_generative\r\n",
      "    score1 = self._joint_log_probability(sent1_token_ids, unconditional_start_token)\r\n",
      "  File \"/home/ongzhiyang/bias-bench-main/bias_bench/benchmark/crows/crows.py\", line 380, in _joint_log_probability\r\n",
      "    output = torch.softmax(self._model(tokens_tensor)[0], dim=-1)\r\n",
      "  File \"/home/ongzhiyang/anaconda3/envs/fyp/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\r\n",
      "    return self._call_impl(*args, **kwargs)\r\n",
      "  File \"/home/ongzhiyang/anaconda3/envs/fyp/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\r\n",
      "    return forward_call(*args, **kwargs)\r\n",
      "  File \"/home/ongzhiyang/anaconda3/envs/fyp/lib/python3.10/site-packages/transformers/models/gpt2/modeling_gpt2.py\", line 1315, in forward\r\n",
      "    transformer_outputs = self.transformer(\r\n",
      "  File \"/home/ongzhiyang/anaconda3/envs/fyp/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\r\n",
      "    return self._call_impl(*args, **kwargs)\r\n",
      "  File \"/home/ongzhiyang/anaconda3/envs/fyp/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\r\n",
      "    return forward_call(*args, **kwargs)\r\n",
      "  File \"/home/ongzhiyang/anaconda3/envs/fyp/lib/python3.10/site-packages/transformers/models/gpt2/modeling_gpt2.py\", line 1129, in forward\r\n",
      "    outputs = block(\r\n",
      "  File \"/home/ongzhiyang/anaconda3/envs/fyp/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\r\n",
      "    return self._call_impl(*args, **kwargs)\r\n",
      "  File \"/home/ongzhiyang/anaconda3/envs/fyp/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\r\n",
      "    return forward_call(*args, **kwargs)\r\n",
      "  File \"/home/ongzhiyang/anaconda3/envs/fyp/lib/python3.10/site-packages/transformers/models/gpt2/modeling_gpt2.py\", line 614, in forward\r\n",
      "    attn_outputs = self.attn(\r\n",
      "  File \"/home/ongzhiyang/anaconda3/envs/fyp/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\r\n",
      "    return self._call_impl(*args, **kwargs)\r\n",
      "  File \"/home/ongzhiyang/anaconda3/envs/fyp/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\r\n",
      "    return forward_call(*args, **kwargs)\r\n",
      "  File \"/home/ongzhiyang/anaconda3/envs/fyp/lib/python3.10/site-packages/transformers/models/gpt2/modeling_gpt2.py\", line 558, in forward\r\n",
      "    attn_output = self.c_proj(attn_output)\r\n",
      "  File \"/home/ongzhiyang/anaconda3/envs/fyp/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\r\n",
      "    return self._call_impl(*args, **kwargs)\r\n",
      "  File \"/home/ongzhiyang/anaconda3/envs/fyp/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\r\n",
      "    return forward_call(*args, **kwargs)\r\n",
      "  File \"/home/ongzhiyang/anaconda3/envs/fyp/lib/python3.10/site-packages/transformers/pytorch_utils.py\", line 104, in forward\r\n",
      "    x = torch.addmm(self.bias, x.view(-1, x.size(-1)), self.weight)\r\n",
      "  File \"/home/ongzhiyang/anaconda3/envs/fyp/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1696, in __getattr__\r\n",
      "    def __getattr__(self, name: str) -> Any:\r\n",
      "KeyboardInterrupt\r\n"
     ]
    }
   ],
   "source": [
    "!python crows.py --model \"GPT2LMHeadModel\" --model_name_or_path \"gpt2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a0a1c203cc9de9",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-07-28T10:42:09.070390Z"
    }
   },
   "outputs": [],
   "source": [
    "!python crows.py --model \"PhiForCausalLM\" --model_name_or_path \"microsoft/phi-2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a331d7ad614e0af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python crows.py --model \"LlamaForCausalLM\" --model_name_or_path \"meta-llama/Llama-2-7b-hf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80c8f112964afc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fyp] *",
   "language": "python",
   "name": "conda-env-fyp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
