{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T05:45:53.054295Z",
     "start_time": "2024-06-01T05:45:32.805171Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/FYP/on0008an/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running CrowS-Pairs benchmark:\r\n",
      " - persistent_dir: /home/FYP/on0008an/bias-bench-main\r\n",
      " - model: BertForMaskedLM\r\n",
      " - model_name_or_path: bert-base-uncased\r\n",
      " - bias_type: gender\r\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\r\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\r\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\r\n",
      "Evaluating gender examples.\r\n",
      "100%|█████████████████████████████████████████| 262/262 [00:07<00:00, 35.92it/s]\r\n",
      "====================================================================================================\r\n",
      "Total examples: 262\r\n",
      "Metric score: 57.25\r\n",
      "Stereotype score: 57.86\r\n",
      "Anti-stereotype score: 56.31\r\n",
      "Num. neutral: 0.0\r\n",
      "====================================================================================================\r\n",
      "\r\n",
      "Metric: 57.25\r\n"
     ]
    }
   ],
   "source": [
    "!python crows.py --bias_type \"gender\" --model \"BertForMaskedLM\" --model_name_or_path \"bert-base-uncased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "961079de023cb4be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T05:46:12.030922Z",
     "start_time": "2024-06-01T05:45:53.056489Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/FYP/on0008an/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running CrowS-Pairs benchmark:\r\n",
      " - persistent_dir: /home/FYP/on0008an/bias-bench-main\r\n",
      " - model: AlbertForMaskedLM\r\n",
      " - model_name_or_path: albert-base-v2\r\n",
      " - bias_type: gender\r\n",
      "Some weights of the model checkpoint at albert-base-v2 were not used when initializing AlbertForMaskedLM: ['albert.pooler.bias', 'albert.pooler.weight']\r\n",
      "- This IS expected if you are initializing AlbertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\r\n",
      "- This IS NOT expected if you are initializing AlbertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\r\n",
      "Evaluating gender examples.\r\n",
      "100%|█████████████████████████████████████████| 262/262 [00:09<00:00, 26.38it/s]\r\n",
      "====================================================================================================\r\n",
      "Total examples: 262\r\n",
      "Metric score: 48.09\r\n",
      "Stereotype score: 47.8\r\n",
      "Anti-stereotype score: 48.54\r\n",
      "Num. neutral: 0.0\r\n",
      "====================================================================================================\r\n",
      "\r\n",
      "Metric: 48.09\r\n"
     ]
    }
   ],
   "source": [
    "!python crows.py --bias_type \"gender\" --model \"AlbertForMaskedLM\" --model_name_or_path \"albert-base-v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "612c0ff6a4f4f4af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T05:46:30.249234Z",
     "start_time": "2024-06-01T05:46:12.033990Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/FYP/on0008an/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running CrowS-Pairs benchmark:\r\n",
      " - persistent_dir: /home/FYP/on0008an/bias-bench-main\r\n",
      " - model: RobertaForMaskedLM\r\n",
      " - model_name_or_path: roberta-base\r\n",
      " - bias_type: gender\r\n",
      "Evaluating gender examples.\r\n",
      " 94%|██████████████████████████████████████▎  | 245/262 [00:08<00:00, 36.81it/s]Skipping example 245.\r\n",
      "100%|████████████████████████████████████████▊| 261/262 [00:09<00:00, 28.40it/s]\r\n",
      "====================================================================================================\r\n",
      "Total examples: 261\r\n",
      "Metric score: 60.15\r\n",
      "Stereotype score: 67.92\r\n",
      "Anti-stereotype score: 48.04\r\n",
      "Num. neutral: 0.0\r\n",
      "====================================================================================================\r\n",
      "\r\n",
      "Metric: 60.15\r\n"
     ]
    }
   ],
   "source": [
    "!python crows.py --bias_type \"gender\" --model \"RobertaForMaskedLM\" --model_name_or_path \"roberta-base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ba6dba7bc502e3f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T05:46:49.985027Z",
     "start_time": "2024-06-01T05:46:30.251354Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/FYP/on0008an/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running CrowS-Pairs benchmark:\r\n",
      " - persistent_dir: /home/FYP/on0008an/bias-bench-main\r\n",
      " - model: GPT2LMHeadModel\r\n",
      " - model_name_or_path: gpt2\r\n",
      " - bias_type: gender\r\n",
      "Evaluating gender examples.\r\n",
      "100%|█████████████████████████████████████████| 262/262 [00:10<00:00, 25.13it/s]\r\n",
      "====================================================================================================\r\n",
      "Total examples: 262\r\n",
      "Metric score: 56.87\r\n",
      "Stereotype score: 53.46\r\n",
      "Anti-stereotype score: 62.14\r\n",
      "Num. neutral: 0.0\r\n",
      "====================================================================================================\r\n",
      "\r\n",
      "Metric: 56.87\r\n"
     ]
    }
   ],
   "source": [
    "!python crows.py --bias_type \"gender\" --model \"GPT2LMHeadModel\" --model_name_or_path \"gpt2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8cc4e931ece089d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T06:32:00.106228Z",
     "start_time": "2024-06-01T06:30:21.131371Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/FYP/on0008an/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running CrowS-Pairs benchmark:\r\n",
      " - persistent_dir: /home/FYP/on0008an/bias-bench-main\r\n",
      " - model: LlamaForCausalLM\r\n",
      " - model_name_or_path: meta-llama/Llama-2-7b-chat-hf\r\n",
      " - bias_type: gender\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:16<00:00,  8.39s/it]\r\n",
      "Evaluating gender examples.\r\n",
      "100%|█████████████████████████████████████████| 262/262 [00:58<00:00,  4.50it/s]\r\n",
      "====================================================================================================\r\n",
      "Total examples: 262\r\n",
      "Metric score: 58.78\r\n",
      "Stereotype score: 61.01\r\n",
      "Anti-stereotype score: 55.34\r\n",
      "Num. neutral: 0.0\r\n",
      "====================================================================================================\r\n",
      "\r\n",
      "Metric: 58.78\r\n"
     ]
    }
   ],
   "source": [
    "!python crows.py --bias_type \"gender\" --model \"LlamaForCausalLM\" --model_name_or_path \"meta-llama/Llama-2-7b-chat-hf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a0a1c203cc9de9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
