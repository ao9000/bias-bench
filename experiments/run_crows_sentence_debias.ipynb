{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64aa678482aeaf8b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T15:46:09.775031Z",
     "start_time": "2024-08-02T15:46:09.123034Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Aug  2 23:46:09 2024       \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 535.183.01             Driver Version: 535.183.01   CUDA Version: 12.2     |\r\n",
      "|-----------------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                      |               MIG M. |\r\n",
      "|=========================================+======================+======================|\r\n",
      "|   0  NVIDIA RTX A6000               Off | 00000000:01:00.0 Off |                  Off |\r\n",
      "| 52%   76C    P2             257W / 300W |  31226MiB / 49140MiB |     67%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "|   1  NVIDIA RTX A6000               Off | 00000000:21:00.0 Off |                  Off |\r\n",
      "| 45%   71C    P2             204W / 300W |  31013MiB / 49140MiB |     65%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "|   2  NVIDIA RTX A6000               Off | 00000000:41:00.0 Off |                  Off |\r\n",
      "| 30%   35C    P8              17W / 300W |  14598MiB / 49140MiB |      0%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "|   3  NVIDIA RTX A6000               Off | 00000000:42:00.0 Off |                  Off |\r\n",
      "| 30%   32C    P8              16W / 300W |      3MiB / 49140MiB |      0%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                            |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\r\n",
      "|        ID   ID                                                             Usage      |\r\n",
      "|=======================================================================================|\r\n",
      "|    0   N/A  N/A    334597      C   ...e/vda/anaconda3/envs/mwp/bin/python      360MiB |\r\n",
      "|    0   N/A  N/A    336275      C   ...e/vda/anaconda3/envs/mwp/bin/python    14828MiB |\r\n",
      "|    0   N/A  N/A   3478574      C   ...e/vda/anaconda3/envs/mwp/bin/python      360MiB |\r\n",
      "|    0   N/A  N/A   3484221      C   ...e/vda/anaconda3/envs/mwp/bin/python    15300MiB |\r\n",
      "|    0   N/A  N/A   3496944      C   ...e/vda/anaconda3/envs/mwp/bin/python      360MiB |\r\n",
      "|    1   N/A  N/A    334597      C   ...e/vda/anaconda3/envs/mwp/bin/python    15026MiB |\r\n",
      "|    1   N/A  N/A   3478574      C   ...e/vda/anaconda3/envs/mwp/bin/python    15978MiB |\r\n",
      "|    2   N/A  N/A   3496944      C   ...e/vda/anaconda3/envs/mwp/bin/python    14592MiB |\r\n",
      "+---------------------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50864bb6a84aa28e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T15:46:09.791126Z",
     "start_time": "2024-08-02T15:46:09.779925Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7be79e2132ae168",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T15:47:20.495414Z",
     "start_time": "2024-08-02T15:46:09.795914Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing: python crows_debias.py --bias_type 'gender' --model 'SentenceDebiasGPT2LMHeadModel' --model_name_or_path 'gpt2' --bias_direction '../results/subspace/subspace_m-GPT2Model_c-gpt2_t-gender.pt'\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running CrowS-Pairs benchmark:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: SentenceDebiasGPT2LMHeadModel\r\n",
      " - model_name_or_path: gpt2\r\n",
      " - bias_direction: ../results/subspace/subspace_m-GPT2Model_c-gpt2_t-gender.pt\r\n",
      " - projection_matrix: None\r\n",
      " - load_path: None\r\n",
      " - bias_type: gender\r\n",
      "Evaluating gender examples.\r\n",
      "Unconditional start token: <|endoftext|>\r\n",
      "100%|█████████████████████████████████████████| 262/262 [00:11<00:00, 23.32it/s]\r\n",
      "====================================================================================================\r\n",
      "Total examples: 262\r\n",
      "Metric score: 56.11\r\n",
      "Stereotype score: 50.94\r\n",
      "Anti-stereotype score: 64.08\r\n",
      "Num. neutral: 0.0\r\n",
      "====================================================================================================\r\n",
      "\r\n",
      "Metric: {'gender': {'Total examples': 262, 'Metric score': 56.11, 'Stereotype score': 50.94, 'Anti-stereotype score': 64.08, 'Num. neutral': 0.0}}\r\n",
      "Executing: python crows_debias.py --bias_type 'religion' --model 'SentenceDebiasGPT2LMHeadModel' --model_name_or_path 'gpt2' --bias_direction '../results/subspace/subspace_m-GPT2Model_c-gpt2_t-religion.pt'\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running CrowS-Pairs benchmark:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: SentenceDebiasGPT2LMHeadModel\r\n",
      " - model_name_or_path: gpt2\r\n",
      " - bias_direction: ../results/subspace/subspace_m-GPT2Model_c-gpt2_t-religion.pt\r\n",
      " - projection_matrix: None\r\n",
      " - load_path: None\r\n",
      " - bias_type: religion\r\n",
      "Evaluating religion examples.\r\n",
      "Unconditional start token: <|endoftext|>\r\n",
      "100%|█████████████████████████████████████████| 105/105 [00:04<00:00, 21.18it/s]\r\n",
      "====================================================================================================\r\n",
      "Total examples: 105\r\n",
      "Metric score: 36.19\r\n",
      "Stereotype score: 33.33\r\n",
      "Anti-stereotype score: 83.33\r\n",
      "Num. neutral: 0.0\r\n",
      "====================================================================================================\r\n",
      "\r\n",
      "Metric: {'religion': {'Total examples': 105, 'Metric score': 36.19, 'Stereotype score': 33.33, 'Anti-stereotype score': 83.33, 'Num. neutral': 0.0}}\r\n",
      "Executing: python crows_debias.py --bias_type 'race-color' --model 'SentenceDebiasGPT2LMHeadModel' --model_name_or_path 'gpt2' --bias_direction '../results/subspace/subspace_m-GPT2Model_c-gpt2_t-race-color.pt'\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running CrowS-Pairs benchmark:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: SentenceDebiasGPT2LMHeadModel\r\n",
      " - model_name_or_path: gpt2\r\n",
      " - bias_direction: ../results/subspace/subspace_m-GPT2Model_c-gpt2_t-race-color.pt\r\n",
      " - projection_matrix: None\r\n",
      " - load_path: None\r\n",
      " - bias_type: race-color\r\n",
      "Evaluating race-color examples.\r\n",
      "Unconditional start token: <|endoftext|>\r\n",
      "100%|█████████████████████████████████████████| 516/516 [00:22<00:00, 22.87it/s]\r\n",
      "====================================================================================================\r\n",
      "Total examples: 516\r\n",
      "Metric score: 55.23\r\n",
      "Stereotype score: 54.55\r\n",
      "Anti-stereotype score: 62.79\r\n",
      "Num. neutral: 0.0\r\n",
      "====================================================================================================\r\n",
      "\r\n",
      "Metric: {'race-color': {'Total examples': 516, 'Metric score': 55.23, 'Stereotype score': 54.55, 'Anti-stereotype score': 62.79, 'Num. neutral': 0.0}}\r\n"
     ]
    }
   ],
   "source": [
    "bias_types = [\n",
    "    \"gender\", \n",
    "    \"religion\", \n",
    "    \"race-color\"\n",
    "]\n",
    "\n",
    "for bias in bias_types:\n",
    "    command = f\"python crows_debias.py --bias_type '{bias}' --model 'SentenceDebiasGPT2LMHeadModel' --model_name_or_path 'gpt2' --bias_direction '../results/subspace/subspace_m-GPT2Model_c-gpt2_t-{bias}.pt'\"\n",
    "    print(f\"Executing: {command}\")\n",
    "    get_ipython().system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea0dd4b74ec380b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T15:50:10.900144Z",
     "start_time": "2024-08-02T15:47:20.496935Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing: python crows_debias.py --bias_type 'gender' --model 'SentenceDebiasPhi2LMHeadModel' --model_name_or_path 'microsoft/phi-2' --bias_direction '../results/subspace/subspace_m-PhiForCausalLM_NonBFloat16_c-microsoft_phi-2_t-gender.pt'\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running CrowS-Pairs benchmark:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: SentenceDebiasPhi2LMHeadModel\r\n",
      " - model_name_or_path: microsoft/phi-2\r\n",
      " - bias_direction: ../results/subspace/subspace_m-PhiForCausalLM_NonBFloat16_c-microsoft_phi-2_t-gender.pt\r\n",
      " - projection_matrix: None\r\n",
      " - load_path: None\r\n",
      " - bias_type: gender\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:02<00:00,  1.26s/it]\r\n",
      "Evaluating gender examples.\r\n",
      "Unconditional start token: <|endoftext|>\r\n",
      "  0%|                                                   | 0/262 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\r\n",
      "100%|█████████████████████████████████████████| 262/262 [00:36<00:00,  7.22it/s]\r\n",
      "====================================================================================================\r\n",
      "Total examples: 262\r\n",
      "Metric score: 48.09\r\n",
      "Stereotype score: 47.8\r\n",
      "Anti-stereotype score: 48.54\r\n",
      "Num. neutral: 0.0\r\n",
      "====================================================================================================\r\n",
      "\r\n",
      "Metric: {'gender': {'Total examples': 262, 'Metric score': 48.09, 'Stereotype score': 47.8, 'Anti-stereotype score': 48.54, 'Num. neutral': 0.0}}\r\n",
      "Executing: python crows_debias.py --bias_type 'religion' --model 'SentenceDebiasPhi2LMHeadModel' --model_name_or_path 'microsoft/phi-2' --bias_direction '../results/subspace/subspace_m-PhiForCausalLM_NonBFloat16_c-microsoft_phi-2_t-religion.pt'\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running CrowS-Pairs benchmark:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: SentenceDebiasPhi2LMHeadModel\r\n",
      " - model_name_or_path: microsoft/phi-2\r\n",
      " - bias_direction: ../results/subspace/subspace_m-PhiForCausalLM_NonBFloat16_c-microsoft_phi-2_t-religion.pt\r\n",
      " - projection_matrix: None\r\n",
      " - load_path: None\r\n",
      " - bias_type: religion\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:02<00:00,  1.38s/it]\r\n",
      "Evaluating religion examples.\r\n",
      "Unconditional start token: <|endoftext|>\r\n",
      "  0%|                                                   | 0/105 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\r\n",
      "100%|█████████████████████████████████████████| 105/105 [00:14<00:00,  7.03it/s]\r\n",
      "====================================================================================================\r\n",
      "Total examples: 105\r\n",
      "Metric score: 64.76\r\n",
      "Stereotype score: 65.66\r\n",
      "Anti-stereotype score: 50.0\r\n",
      "Num. neutral: 0.0\r\n",
      "====================================================================================================\r\n",
      "\r\n",
      "Metric: {'religion': {'Total examples': 105, 'Metric score': 64.76, 'Stereotype score': 65.66, 'Anti-stereotype score': 50.0, 'Num. neutral': 0.0}}\r\n",
      "Executing: python crows_debias.py --bias_type 'race-color' --model 'SentenceDebiasPhi2LMHeadModel' --model_name_or_path 'microsoft/phi-2' --bias_direction '../results/subspace/subspace_m-PhiForCausalLM_NonBFloat16_c-microsoft_phi-2_t-race-color.pt'\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running CrowS-Pairs benchmark:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: SentenceDebiasPhi2LMHeadModel\r\n",
      " - model_name_or_path: microsoft/phi-2\r\n",
      " - bias_direction: ../results/subspace/subspace_m-PhiForCausalLM_NonBFloat16_c-microsoft_phi-2_t-race-color.pt\r\n",
      " - projection_matrix: None\r\n",
      " - load_path: None\r\n",
      " - bias_type: race-color\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:02<00:00,  1.30s/it]\r\n",
      "Evaluating race-color examples.\r\n",
      "Unconditional start token: <|endoftext|>\r\n",
      "  0%|                                                   | 0/516 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\r\n",
      "100%|█████████████████████████████████████████| 516/516 [01:09<00:00,  7.42it/s]\r\n",
      "====================================================================================================\r\n",
      "Total examples: 516\r\n",
      "Metric score: 61.05\r\n",
      "Stereotype score: 61.52\r\n",
      "Anti-stereotype score: 55.81\r\n",
      "Num. neutral: 0.0\r\n",
      "====================================================================================================\r\n",
      "\r\n",
      "Metric: {'race-color': {'Total examples': 516, 'Metric score': 61.05, 'Stereotype score': 61.52, 'Anti-stereotype score': 55.81, 'Num. neutral': 0.0}}\r\n"
     ]
    }
   ],
   "source": [
    "bias_types = [\n",
    "    \"gender\", \n",
    "    \"religion\", \n",
    "    \"race-color\"\n",
    "]\n",
    "\n",
    "for bias in bias_types:\n",
    "    command = f\"python crows_debias.py --bias_type '{bias}' --model 'SentenceDebiasPhi2LMHeadModel' --model_name_or_path 'microsoft/phi-2' --bias_direction '../results/subspace/subspace_m-PhiForCausalLM_NonBFloat16_c-microsoft_phi-2_t-{bias}.pt'\"\n",
    "    print(f\"Executing: {command}\")\n",
    "    get_ipython().system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aff894b26cc8f8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T15:54:26.514908Z",
     "start_time": "2024-08-02T15:50:10.901251Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing: python crows_debias.py --bias_type 'gender' --model 'SentenceDebiasLlama2LMHeadModel' --model_name_or_path 'meta-llama/Llama-2-7b-hf' --bias_direction '../results/subspace/subspace_m-LlamaForCausalLM_NonBFloat16_c-meta-llama_Llama-2-7b-hf_t-gender.pt'\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running CrowS-Pairs benchmark:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: SentenceDebiasLlama2LMHeadModel\r\n",
      " - model_name_or_path: meta-llama/Llama-2-7b-hf\r\n",
      " - bias_direction: ../results/subspace/subspace_m-LlamaForCausalLM_NonBFloat16_c-meta-llama_Llama-2-7b-hf_t-gender.pt\r\n",
      " - projection_matrix: None\r\n",
      " - load_path: None\r\n",
      " - bias_type: gender\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:04<00:00,  2.20s/it]\r\n",
      "Evaluating gender examples.\r\n",
      "Unconditional start token: <s>\r\n",
      "  0%|                                                   | 0/262 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\r\n",
      "100%|█████████████████████████████████████████| 262/262 [00:55<00:00,  4.75it/s]\r\n",
      "====================================================================================================\r\n",
      "Total examples: 262\r\n",
      "Metric score: 57.25\r\n",
      "Stereotype score: 45.28\r\n",
      "Anti-stereotype score: 75.73\r\n",
      "Num. neutral: 0.0\r\n",
      "====================================================================================================\r\n",
      "\r\n",
      "Metric: {'gender': {'Total examples': 262, 'Metric score': 57.25, 'Stereotype score': 45.28, 'Anti-stereotype score': 75.73, 'Num. neutral': 0.0}}\r\n",
      "Executing: python crows_debias.py --bias_type 'religion' --model 'SentenceDebiasLlama2LMHeadModel' --model_name_or_path 'meta-llama/Llama-2-7b-hf' --bias_direction '../results/subspace/subspace_m-LlamaForCausalLM_NonBFloat16_c-meta-llama_Llama-2-7b-hf_t-religion.pt'\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running CrowS-Pairs benchmark:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: SentenceDebiasLlama2LMHeadModel\r\n",
      " - model_name_or_path: meta-llama/Llama-2-7b-hf\r\n",
      " - bias_direction: ../results/subspace/subspace_m-LlamaForCausalLM_NonBFloat16_c-meta-llama_Llama-2-7b-hf_t-religion.pt\r\n",
      " - projection_matrix: None\r\n",
      " - load_path: None\r\n",
      " - bias_type: religion\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:04<00:00,  2.05s/it]\r\n",
      "Evaluating religion examples.\r\n",
      "Unconditional start token: <s>\r\n",
      "  0%|                                                   | 0/105 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\r\n",
      "100%|█████████████████████████████████████████| 105/105 [00:22<00:00,  4.61it/s]\r\n",
      "====================================================================================================\r\n",
      "Total examples: 105\r\n",
      "Metric score: 74.29\r\n",
      "Stereotype score: 73.74\r\n",
      "Anti-stereotype score: 83.33\r\n",
      "Num. neutral: 0.0\r\n",
      "====================================================================================================\r\n",
      "\r\n",
      "Metric: {'religion': {'Total examples': 105, 'Metric score': 74.29, 'Stereotype score': 73.74, 'Anti-stereotype score': 83.33, 'Num. neutral': 0.0}}\r\n",
      "Executing: python crows_debias.py --bias_type 'race-color' --model 'SentenceDebiasLlama2LMHeadModel' --model_name_or_path 'meta-llama/Llama-2-7b-hf' --bias_direction '../results/subspace/subspace_m-LlamaForCausalLM_NonBFloat16_c-meta-llama_Llama-2-7b-hf_t-race-color.pt'\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running CrowS-Pairs benchmark:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: SentenceDebiasLlama2LMHeadModel\r\n",
      " - model_name_or_path: meta-llama/Llama-2-7b-hf\r\n",
      " - bias_direction: ../results/subspace/subspace_m-LlamaForCausalLM_NonBFloat16_c-meta-llama_Llama-2-7b-hf_t-race-color.pt\r\n",
      " - projection_matrix: None\r\n",
      " - load_path: None\r\n",
      " - bias_type: race-color\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:04<00:00,  2.16s/it]\r\n",
      "Evaluating race-color examples.\r\n",
      "Unconditional start token: <s>\r\n",
      "  0%|                                                   | 0/516 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\r\n",
      "100%|█████████████████████████████████████████| 516/516 [01:48<00:00,  4.74it/s]\r\n",
      "====================================================================================================\r\n",
      "Total examples: 516\r\n",
      "Metric score: 67.25\r\n",
      "Stereotype score: 69.56\r\n",
      "Anti-stereotype score: 41.86\r\n",
      "Num. neutral: 0.0\r\n",
      "====================================================================================================\r\n",
      "\r\n",
      "Metric: {'race-color': {'Total examples': 516, 'Metric score': 67.25, 'Stereotype score': 69.56, 'Anti-stereotype score': 41.86, 'Num. neutral': 0.0}}\r\n"
     ]
    }
   ],
   "source": [
    "bias_types = [\n",
    "    \"gender\", \n",
    "    \"religion\", \n",
    "    \"race-color\"\n",
    "]\n",
    "\n",
    "for bias in bias_types:\n",
    "    command = f\"python crows_debias.py --bias_type '{bias}' --model 'SentenceDebiasLlama2LMHeadModel' --model_name_or_path 'meta-llama/Llama-2-7b-hf' --bias_direction '../results/subspace/subspace_m-LlamaForCausalLM_NonBFloat16_c-meta-llama_Llama-2-7b-hf_t-{bias}.pt'\"\n",
    "    print(f\"Executing: {command}\")\n",
    "    get_ipython().system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc41a76e4875326",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fyp] *",
   "language": "python",
   "name": "conda-env-fyp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
