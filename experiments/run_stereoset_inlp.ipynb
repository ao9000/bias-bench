{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3eeead8bc7e05d0d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T06:55:44.204688Z",
     "start_time": "2024-08-08T06:55:43.513302Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Aug  8 14:55:43 2024       \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 535.183.01             Driver Version: 535.183.01   CUDA Version: 12.2     |\r\n",
      "|-----------------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                      |               MIG M. |\r\n",
      "|=========================================+======================+======================|\r\n",
      "|   0  NVIDIA RTX A6000               Off | 00000000:01:00.0 Off |                  Off |\r\n",
      "| 58%   73C    P2             109W / 300W |   1788MiB / 49140MiB |      7%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "|   1  NVIDIA RTX A6000               Off | 00000000:21:00.0 Off |                  Off |\r\n",
      "| 48%   75C    P2             238W / 300W |   4746MiB / 49140MiB |     51%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "|   2  NVIDIA RTX A6000               Off | 00000000:41:00.0 Off |                  Off |\r\n",
      "| 56%   81C    P2             291W / 300W |  26134MiB / 49140MiB |     89%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "|   3  NVIDIA RTX A6000               Off | 00000000:42:00.0 Off |                  Off |\r\n",
      "| 30%   51C    P2             104W / 300W |   3588MiB / 49140MiB |     21%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                            |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\r\n",
      "|        ID   ID                                                             Usage      |\r\n",
      "|=======================================================================================|\r\n",
      "|    0   N/A  N/A   2747194      C   python                                     1804MiB |\r\n",
      "|    1   N/A  N/A   2743419      C   python                                     4740MiB |\r\n",
      "|    2   N/A  N/A   2728264      C   python                                    26128MiB |\r\n",
      "|    3   N/A  N/A   2738266      C   python                                     3582MiB |\r\n",
      "+---------------------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c211d4f194222a14",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T12:39:55.605400Z",
     "start_time": "2024-08-03T12:39:55.599478Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe424ddec668c5a",
   "metadata": {},
   "source": [
    "# n_classifiers = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc79a630a224ac9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T08:24:54.549942Z",
     "start_time": "2024-08-03T08:14:11.057978Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing: python stereoset_debias.py --model 'INLPGPT2LMHeadModel' --model_name_or_path 'gpt2' --projection_matrix '../results/projection_matrix/n_classifiers_80/projection_m-GPT2Model_c-gpt2_t-gender_s-42.pt' --bias_type 'gender' --batch_size 1 --seed 42\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: INLPGPT2LMHeadModel\r\n",
      " - model_name_or_path: gpt2\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: ../results/projection_matrix/n_classifiers_80/projection_m-GPT2Model_c-gpt2_t-gender_s-42.pt\r\n",
      " - load_path: None\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: gender\r\n",
      " - seed: 42\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <|endoftext|>\r\n",
      "torch.Size([1, 1, 50257])\r\n",
      "100%|███████████████████████████████████████| 6392/6392 [03:13<00:00, 33.02it/s]\r\n",
      "Executing: python stereoset_debias.py --model 'INLPGPT2LMHeadModel' --model_name_or_path 'gpt2' --projection_matrix '../results/projection_matrix/n_classifiers_80/projection_m-GPT2Model_c-gpt2_t-religion_s-42.pt' --bias_type 'religion' --batch_size 1 --seed 42\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: INLPGPT2LMHeadModel\r\n",
      " - model_name_or_path: gpt2\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: ../results/projection_matrix/n_classifiers_80/projection_m-GPT2Model_c-gpt2_t-religion_s-42.pt\r\n",
      " - load_path: None\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: religion\r\n",
      " - seed: 42\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <|endoftext|>\r\n",
      "torch.Size([1, 1, 50257])\r\n",
      "100%|███████████████████████████████████████| 6392/6392 [03:29<00:00, 30.53it/s]\r\n",
      "Executing: python stereoset_debias.py --model 'INLPGPT2LMHeadModel' --model_name_or_path 'gpt2' --projection_matrix '../results/projection_matrix/n_classifiers_80/projection_m-GPT2Model_c-gpt2_t-race-color_s-42.pt' --bias_type 'race-color' --batch_size 1 --seed 42\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: INLPGPT2LMHeadModel\r\n",
      " - model_name_or_path: gpt2\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: ../results/projection_matrix/n_classifiers_80/projection_m-GPT2Model_c-gpt2_t-race-color_s-42.pt\r\n",
      " - load_path: None\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: race-color\r\n",
      " - seed: 42\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <|endoftext|>\r\n",
      "torch.Size([1, 1, 50257])\r\n",
      "100%|███████████████████████████████████████| 6392/6392 [03:23<00:00, 31.38it/s]\r\n"
     ]
    }
   ],
   "source": [
    "bias_types = [\n",
    "    \"gender\", \n",
    "    \"religion\", \n",
    "    \"race-color\"\n",
    "]\n",
    "\n",
    "for bias in bias_types:\n",
    "    command = f\"python stereoset_debias.py --model 'INLPGPT2LMHeadModel' --model_name_or_path 'gpt2' --projection_matrix '../results/projection_matrix/n_classifiers_80/projection_m-GPT2Model_c-gpt2_t-{bias}_s-42.pt' --bias_type '{bias}' --batch_size 1 --seed 42\"\n",
    "    print(f\"Executing: {command}\")\n",
    "    get_ipython().system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9fa201e80b7e45e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T09:10:53.125276Z",
     "start_time": "2024-08-03T08:24:54.551519Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing: python stereoset_debias.py --model 'INLPPhi2LMHeadModel' --model_name_or_path 'microsoft/phi-2' --projection_matrix '../results/projection_matrix/n_classifiers_80/projection_m-PhiForCausalLM_NonBFloat16_c-microsoft_phi-2_t-gender_s-42.pt' --bias_type 'gender' --batch_size 1 --seed 42\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: INLPPhi2LMHeadModel\r\n",
      " - model_name_or_path: microsoft/phi-2\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: ../results/projection_matrix/n_classifiers_80/projection_m-PhiForCausalLM_NonBFloat16_c-microsoft_phi-2_t-gender_s-42.pt\r\n",
      " - load_path: None\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: gender\r\n",
      " - seed: 42\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:02<00:00,  1.48s/it]\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <|endoftext|>\r\n",
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\r\n",
      "torch.Size([1, 1, 51200])\r\n",
      "100%|███████████████████████████████████████| 6392/6392 [19:48<00:00,  5.38it/s]\r\n",
      "Executing: python stereoset_debias.py --model 'INLPPhi2LMHeadModel' --model_name_or_path 'microsoft/phi-2' --projection_matrix '../results/projection_matrix/n_classifiers_80/projection_m-PhiForCausalLM_NonBFloat16_c-microsoft_phi-2_t-religion_s-42.pt' --bias_type 'religion' --batch_size 1 --seed 42\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: INLPPhi2LMHeadModel\r\n",
      " - model_name_or_path: microsoft/phi-2\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: ../results/projection_matrix/n_classifiers_80/projection_m-PhiForCausalLM_NonBFloat16_c-microsoft_phi-2_t-religion_s-42.pt\r\n",
      " - load_path: None\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: religion\r\n",
      " - seed: 42\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:03<00:00,  1.60s/it]\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <|endoftext|>\r\n",
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\r\n",
      "torch.Size([1, 1, 51200])\r\n",
      "100%|███████████████████████████████████████| 6392/6392 [12:33<00:00,  8.48it/s]\r\n",
      "Executing: python stereoset_debias.py --model 'INLPPhi2LMHeadModel' --model_name_or_path 'microsoft/phi-2' --projection_matrix '../results/projection_matrix/n_classifiers_80/projection_m-PhiForCausalLM_NonBFloat16_c-microsoft_phi-2_t-race-color_s-42.pt' --bias_type 'race-color' --batch_size 1 --seed 42\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: INLPPhi2LMHeadModel\r\n",
      " - model_name_or_path: microsoft/phi-2\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: ../results/projection_matrix/n_classifiers_80/projection_m-PhiForCausalLM_NonBFloat16_c-microsoft_phi-2_t-race-color_s-42.pt\r\n",
      " - load_path: None\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: race-color\r\n",
      " - seed: 42\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:03<00:00,  1.55s/it]\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <|endoftext|>\r\n",
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\r\n",
      "torch.Size([1, 1, 51200])\r\n",
      "100%|███████████████████████████████████████| 6392/6392 [12:35<00:00,  8.46it/s]\r\n"
     ]
    }
   ],
   "source": [
    "bias_types = [\n",
    "    \"gender\", \n",
    "    \"religion\", \n",
    "    \"race-color\"\n",
    "]\n",
    "\n",
    "for bias in bias_types:\n",
    "    command = f\"python stereoset_debias.py --model 'INLPPhi2LMHeadModel' --model_name_or_path 'microsoft/phi-2' --projection_matrix '../results/projection_matrix/n_classifiers_80/projection_m-PhiForCausalLM_NonBFloat16_c-microsoft_phi-2_t-{bias}_s-42.pt' --bias_type '{bias}' --batch_size 1 --seed 42\"\n",
    "    print(f\"Executing: {command}\")\n",
    "    get_ipython().system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7eba11d763e81712",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T10:40:11.730962Z",
     "start_time": "2024-08-03T09:10:53.126663Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing: python stereoset_debias.py --model 'INLPLlama2LMHeadModel' --model_name_or_path 'meta-llama/Llama-2-7b-hf' --projection_matrix '../results/projection_matrix/n_classifiers_80/projection_m-LlamaForCausalLM_NonBFloat16_c-meta-llama_Llama-2-7b-hf_t-gender_s-42.pt' --bias_type 'gender' --batch_size 1 --seed 42\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: INLPLlama2LMHeadModel\r\n",
      " - model_name_or_path: meta-llama/Llama-2-7b-hf\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: ../results/projection_matrix/n_classifiers_80/projection_m-LlamaForCausalLM_NonBFloat16_c-meta-llama_Llama-2-7b-hf_t-gender_s-42.pt\r\n",
      " - load_path: None\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: gender\r\n",
      " - seed: 42\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:04<00:00,  2.29s/it]\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <s>\r\n",
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\r\n",
      "torch.Size([1, 1, 32000])\r\n",
      "100%|███████████████████████████████████████| 6392/6392 [27:08<00:00,  3.93it/s]\r\n",
      "Executing: python stereoset_debias.py --model 'INLPLlama2LMHeadModel' --model_name_or_path 'meta-llama/Llama-2-7b-hf' --projection_matrix '../results/projection_matrix/n_classifiers_80/projection_m-LlamaForCausalLM_NonBFloat16_c-meta-llama_Llama-2-7b-hf_t-religion_s-42.pt' --bias_type 'religion' --batch_size 1 --seed 42\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: INLPLlama2LMHeadModel\r\n",
      " - model_name_or_path: meta-llama/Llama-2-7b-hf\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: ../results/projection_matrix/n_classifiers_80/projection_m-LlamaForCausalLM_NonBFloat16_c-meta-llama_Llama-2-7b-hf_t-religion_s-42.pt\r\n",
      " - load_path: None\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: religion\r\n",
      " - seed: 42\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:04<00:00,  2.28s/it]\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <s>\r\n",
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\r\n",
      "torch.Size([1, 1, 32000])\r\n",
      "100%|███████████████████████████████████████| 6392/6392 [27:04<00:00,  3.94it/s]\r\n",
      "Executing: python stereoset_debias.py --model 'INLPLlama2LMHeadModel' --model_name_or_path 'meta-llama/Llama-2-7b-hf' --projection_matrix '../results/projection_matrix/n_classifiers_80/projection_m-LlamaForCausalLM_NonBFloat16_c-meta-llama_Llama-2-7b-hf_t-race-color_s-42.pt' --bias_type 'race-color' --batch_size 1 --seed 42\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: INLPLlama2LMHeadModel\r\n",
      " - model_name_or_path: meta-llama/Llama-2-7b-hf\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: ../results/projection_matrix/n_classifiers_80/projection_m-LlamaForCausalLM_NonBFloat16_c-meta-llama_Llama-2-7b-hf_t-race-color_s-42.pt\r\n",
      " - load_path: None\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: race-color\r\n",
      " - seed: 42\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:04<00:00,  2.25s/it]\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <s>\r\n",
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\r\n",
      "torch.Size([1, 1, 32000])\r\n",
      "100%|███████████████████████████████████████| 6392/6392 [33:44<00:00,  3.16it/s]\r\n"
     ]
    }
   ],
   "source": [
    "bias_types = [\n",
    "    \"gender\", \n",
    "    \"religion\", \n",
    "    \"race-color\"\n",
    "]\n",
    "\n",
    "for bias in bias_types:\n",
    "    command = f\"python stereoset_debias.py --model 'INLPLlama2LMHeadModel' --model_name_or_path 'meta-llama/Llama-2-7b-hf' --projection_matrix '../results/projection_matrix/n_classifiers_80/projection_m-LlamaForCausalLM_NonBFloat16_c-meta-llama_Llama-2-7b-hf_t-{bias}_s-42.pt' --bias_type '{bias}' --batch_size 1 --seed 42\"\n",
    "    print(f\"Executing: {command}\")\n",
    "    get_ipython().system(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8db2ccf2a19f7e",
   "metadata": {},
   "source": [
    "# n_classifiers = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d774a239ccb89b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T10:52:22.391316Z",
     "start_time": "2024-08-03T10:40:11.744424Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing: python stereoset_debias.py --model 'INLPGPT2LMHeadModel' --model_name_or_path 'gpt2' --projection_matrix '../results/projection_matrix/n_classifiers_10/projection_m-GPT2Model_c-gpt2_t-gender_s-42.pt' --bias_type 'gender' --batch_size 1 --seed 42\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: INLPGPT2LMHeadModel\r\n",
      " - model_name_or_path: gpt2\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: ../results/projection_matrix/n_classifiers_10/projection_m-GPT2Model_c-gpt2_t-gender_s-42.pt\r\n",
      " - load_path: None\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: gender\r\n",
      " - seed: 42\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <|endoftext|>\r\n",
      "torch.Size([1, 1, 50257])\r\n",
      "100%|███████████████████████████████████████| 6392/6392 [03:55<00:00, 27.11it/s]\r\n",
      "Executing: python stereoset_debias.py --model 'INLPGPT2LMHeadModel' --model_name_or_path 'gpt2' --projection_matrix '../results/projection_matrix/n_classifiers_10/projection_m-GPT2Model_c-gpt2_t-religion_s-42.pt' --bias_type 'religion' --batch_size 1 --seed 42\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: INLPGPT2LMHeadModel\r\n",
      " - model_name_or_path: gpt2\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: ../results/projection_matrix/n_classifiers_10/projection_m-GPT2Model_c-gpt2_t-religion_s-42.pt\r\n",
      " - load_path: None\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: religion\r\n",
      " - seed: 42\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <|endoftext|>\r\n",
      "torch.Size([1, 1, 50257])\r\n",
      "100%|███████████████████████████████████████| 6392/6392 [03:54<00:00, 27.24it/s]\r\n",
      "Executing: python stereoset_debias.py --model 'INLPGPT2LMHeadModel' --model_name_or_path 'gpt2' --projection_matrix '../results/projection_matrix/n_classifiers_10/projection_m-GPT2Model_c-gpt2_t-race-color_s-42.pt' --bias_type 'race-color' --batch_size 1 --seed 42\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: INLPGPT2LMHeadModel\r\n",
      " - model_name_or_path: gpt2\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: ../results/projection_matrix/n_classifiers_10/projection_m-GPT2Model_c-gpt2_t-race-color_s-42.pt\r\n",
      " - load_path: None\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: race-color\r\n",
      " - seed: 42\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <|endoftext|>\r\n",
      "torch.Size([1, 1, 50257])\r\n",
      "100%|███████████████████████████████████████| 6392/6392 [03:43<00:00, 28.63it/s]\r\n"
     ]
    }
   ],
   "source": [
    "bias_types = [\n",
    "    \"gender\", \n",
    "    \"religion\", \n",
    "    \"race-color\"\n",
    "]\n",
    "\n",
    "for bias in bias_types:\n",
    "    command = f\"python stereoset_debias.py --model 'INLPGPT2LMHeadModel' --model_name_or_path 'gpt2' --projection_matrix '../results/projection_matrix/n_classifiers_10/projection_m-GPT2Model_c-gpt2_t-{bias}_s-42.pt' --bias_type '{bias}' --batch_size 1 --seed 42\"\n",
    "    print(f\"Executing: {command}\")\n",
    "    get_ipython().system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35af0dfe02106e95",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T11:41:51.456513Z",
     "start_time": "2024-08-03T10:52:22.392633Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing: python stereoset_debias.py --model 'INLPPhi2LMHeadModel' --model_name_or_path 'microsoft/phi-2' --projection_matrix '../results/projection_matrix/n_classifiers_10/projection_m-PhiForCausalLM_NonBFloat16_c-microsoft_phi-2_t-gender_s-42.pt' --bias_type 'gender' --batch_size 1 --seed 42\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: INLPPhi2LMHeadModel\r\n",
      " - model_name_or_path: microsoft/phi-2\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: ../results/projection_matrix/n_classifiers_10/projection_m-PhiForCausalLM_NonBFloat16_c-microsoft_phi-2_t-gender_s-42.pt\r\n",
      " - load_path: None\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: gender\r\n",
      " - seed: 42\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:02<00:00,  1.42s/it]\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <|endoftext|>\r\n",
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\r\n",
      "torch.Size([1, 1, 51200])\r\n",
      "100%|███████████████████████████████████████| 6392/6392 [16:00<00:00,  6.65it/s]\r\n",
      "Executing: python stereoset_debias.py --model 'INLPPhi2LMHeadModel' --model_name_or_path 'microsoft/phi-2' --projection_matrix '../results/projection_matrix/n_classifiers_10/projection_m-PhiForCausalLM_NonBFloat16_c-microsoft_phi-2_t-religion_s-42.pt' --bias_type 'religion' --batch_size 1 --seed 42\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: INLPPhi2LMHeadModel\r\n",
      " - model_name_or_path: microsoft/phi-2\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: ../results/projection_matrix/n_classifiers_10/projection_m-PhiForCausalLM_NonBFloat16_c-microsoft_phi-2_t-religion_s-42.pt\r\n",
      " - load_path: None\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: religion\r\n",
      " - seed: 42\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:02<00:00,  1.40s/it]\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <|endoftext|>\r\n",
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\r\n",
      "torch.Size([1, 1, 51200])\r\n",
      "100%|███████████████████████████████████████| 6392/6392 [16:17<00:00,  6.54it/s]\r\n",
      "Executing: python stereoset_debias.py --model 'INLPPhi2LMHeadModel' --model_name_or_path 'microsoft/phi-2' --projection_matrix '../results/projection_matrix/n_classifiers_10/projection_m-PhiForCausalLM_NonBFloat16_c-microsoft_phi-2_t-race-color_s-42.pt' --bias_type 'race-color' --batch_size 1 --seed 42\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: INLPPhi2LMHeadModel\r\n",
      " - model_name_or_path: microsoft/phi-2\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: ../results/projection_matrix/n_classifiers_10/projection_m-PhiForCausalLM_NonBFloat16_c-microsoft_phi-2_t-race-color_s-42.pt\r\n",
      " - load_path: None\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: race-color\r\n",
      " - seed: 42\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:02<00:00,  1.28s/it]\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <|endoftext|>\r\n",
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\r\n",
      "torch.Size([1, 1, 51200])\r\n",
      "100%|███████████████████████████████████████| 6392/6392 [16:12<00:00,  6.57it/s]\r\n"
     ]
    }
   ],
   "source": [
    "bias_types = [\n",
    "    \"gender\", \n",
    "    \"religion\", \n",
    "    \"race-color\"\n",
    "]\n",
    "\n",
    "for bias in bias_types:\n",
    "    command = f\"python stereoset_debias.py --model 'INLPPhi2LMHeadModel' --model_name_or_path 'microsoft/phi-2' --projection_matrix '../results/projection_matrix/n_classifiers_10/projection_m-PhiForCausalLM_NonBFloat16_c-microsoft_phi-2_t-{bias}_s-42.pt' --bias_type '{bias}' --batch_size 1 --seed 42\"\n",
    "    print(f\"Executing: {command}\")\n",
    "    get_ipython().system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e40b7db0f258836",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T13:37:26.518929Z",
     "start_time": "2024-08-03T12:40:02.025855Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing: python stereoset_debias.py --model 'INLPLlama2LMHeadModel' --model_name_or_path 'meta-llama/Llama-2-7b-hf' --projection_matrix '../results/projection_matrix/n_classifiers_10/projection_m-LlamaForCausalLM_NonBFloat16_c-meta-llama_Llama-2-7b-hf_t-religion_s-42.pt' --bias_type 'religion' --batch_size 1 --seed 42\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: INLPLlama2LMHeadModel\r\n",
      " - model_name_or_path: meta-llama/Llama-2-7b-hf\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: ../results/projection_matrix/n_classifiers_10/projection_m-LlamaForCausalLM_NonBFloat16_c-meta-llama_Llama-2-7b-hf_t-religion_s-42.pt\r\n",
      " - load_path: None\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: religion\r\n",
      " - seed: 42\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:04<00:00,  2.14s/it]\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <s>\r\n",
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\r\n",
      "torch.Size([1, 1, 32000])\r\n",
      "100%|███████████████████████████████████████| 6392/6392 [28:18<00:00,  3.76it/s]\r\n",
      "Executing: python stereoset_debias.py --model 'INLPLlama2LMHeadModel' --model_name_or_path 'meta-llama/Llama-2-7b-hf' --projection_matrix '../results/projection_matrix/n_classifiers_10/projection_m-LlamaForCausalLM_NonBFloat16_c-meta-llama_Llama-2-7b-hf_t-race-color_s-42.pt' --bias_type 'race-color' --batch_size 1 --seed 42\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: INLPLlama2LMHeadModel\r\n",
      " - model_name_or_path: meta-llama/Llama-2-7b-hf\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: ../results/projection_matrix/n_classifiers_10/projection_m-LlamaForCausalLM_NonBFloat16_c-meta-llama_Llama-2-7b-hf_t-race-color_s-42.pt\r\n",
      " - load_path: None\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: race-color\r\n",
      " - seed: 42\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:04<00:00,  2.22s/it]\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <s>\r\n",
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\r\n",
      "torch.Size([1, 1, 32000])\r\n",
      "100%|███████████████████████████████████████| 6392/6392 [28:14<00:00,  3.77it/s]\r\n"
     ]
    }
   ],
   "source": [
    "bias_types = [\n",
    "    \"gender\", \n",
    "    \"religion\", \n",
    "    \"race-color\"\n",
    "]\n",
    "\n",
    "for bias in bias_types:\n",
    "    command = f\"python stereoset_debias.py --model 'INLPLlama2LMHeadModel' --model_name_or_path 'meta-llama/Llama-2-7b-hf' --projection_matrix '../results/projection_matrix/n_classifiers_10/projection_m-LlamaForCausalLM_NonBFloat16_c-meta-llama_Llama-2-7b-hf_t-{bias}_s-42.pt' --bias_type '{bias}' --batch_size 1 --seed 42\"\n",
    "    print(f\"Executing: {command}\")\n",
    "    get_ipython().system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7900941eb75526c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fyp] *",
   "language": "python",
   "name": "conda-env-fyp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
