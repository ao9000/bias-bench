{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef6b88f684b89f8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T06:00:23.743187Z",
     "start_time": "2024-07-23T06:00:23.068534Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jul 23 14:00:23 2024       \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 535.183.01             Driver Version: 535.183.01   CUDA Version: 12.2     |\r\n",
      "|-----------------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                      |               MIG M. |\r\n",
      "|=========================================+======================+======================|\r\n",
      "|   0  NVIDIA RTX A6000               Off | 00000000:01:00.0 Off |                  Off |\r\n",
      "| 30%   35C    P8              24W / 300W |    729MiB / 49140MiB |      0%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "|   1  NVIDIA RTX A6000               Off | 00000000:21:00.0 Off |                  Off |\r\n",
      "| 30%   33C    P8              19W / 300W |      3MiB / 49140MiB |      0%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "|   2  NVIDIA RTX A6000               Off | 00000000:41:00.0 Off |                  Off |\r\n",
      "| 48%   73C    P2             253W / 300W |  15932MiB / 49140MiB |     70%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "|   3  NVIDIA RTX A6000               Off | 00000000:42:00.0 Off |                  Off |\r\n",
      "| 38%   66C    P2             228W / 300W |  15406MiB / 49140MiB |     65%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                            |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\r\n",
      "|        ID   ID                                                             Usage      |\r\n",
      "|=======================================================================================|\r\n",
      "|    0   N/A  N/A    869791      C   ...e/vda/anaconda3/envs/mwp/bin/python      360MiB |\r\n",
      "|    0   N/A  N/A    873195      C   ...e/vda/anaconda3/envs/mwp/bin/python      360MiB |\r\n",
      "|    2   N/A  N/A    873195      C   ...e/vda/anaconda3/envs/mwp/bin/python    15926MiB |\r\n",
      "|    3   N/A  N/A    869791      C   ...e/vda/anaconda3/envs/mwp/bin/python    15400MiB |\r\n",
      "+---------------------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T06:00:23.748602Z",
     "start_time": "2024-07-23T06:00:23.744900Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1a8b912d47b04e",
   "metadata": {},
   "source": [
    "# GPT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fde06b0d3b039561",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T06:00:52.645901Z",
     "start_time": "2024-07-23T06:00:25.143423Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running CrowS-Pairs benchmark:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: GPT2LMHeadModel\r\n",
      " - model_name_or_path: gpt2\r\n",
      " - bias_type: religion\r\n",
      "Evaluating religion examples.\r\n",
      "Unconditional start token: <|endoftext|>\r\n",
      "100%|█████████████████████████████████████████| 105/105 [00:04<00:00, 23.18it/s]\r\n",
      "====================================================================================================\r\n",
      "Total examples: 105\r\n",
      "Metric score: 60.0\r\n",
      "Stereotype score: 62.0\r\n",
      "Anti-stereotype score: 20.0\r\n",
      "Num. neutral: 0.0\r\n",
      "====================================================================================================\r\n",
      "\r\n",
      "{\r\n",
      "    \"religion\": {\r\n",
      "        \"Total examples\": 105,\r\n",
      "        \"Metric score\": 60.0,\r\n",
      "        \"Stereotype score\": 62.0,\r\n",
      "        \"Anti-stereotype score\": 20.0,\r\n",
      "        \"Num. neutral\": 0.0\r\n",
      "    }\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "!python ../crows.py --bias_type \"religion\" --model \"GPT2LMHeadModel\" --model_name_or_path \"gpt2\" --custom_dataset_path \"crows_pairs_anonymized_adapted_sg.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5c2749564016a99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T06:01:22.247944Z",
     "start_time": "2024-07-23T06:00:52.647391Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running CrowS-Pairs benchmark:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: GPT2LMHeadModel\r\n",
      " - model_name_or_path: gpt2\r\n",
      " - bias_type: race\r\n",
      "Evaluating race-color examples.\r\n",
      "Unconditional start token: <|endoftext|>\r\n",
      "100%|█████████████████████████████████████████| 514/514 [00:19<00:00, 26.69it/s]\r\n",
      "====================================================================================================\r\n",
      "Total examples: 514\r\n",
      "Metric score: 46.69\r\n",
      "Stereotype score: 45.85\r\n",
      "Anti-stereotype score: 61.29\r\n",
      "Num. neutral: 0.19\r\n",
      "====================================================================================================\r\n",
      "\r\n",
      "{\r\n",
      "    \"race-color\": {\r\n",
      "        \"Total examples\": 514,\r\n",
      "        \"Metric score\": 46.69,\r\n",
      "        \"Stereotype score\": 45.85,\r\n",
      "        \"Anti-stereotype score\": 61.29,\r\n",
      "        \"Num. neutral\": 0.19\r\n",
      "    }\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "!python ../crows.py --bias_type \"race\" --model \"GPT2LMHeadModel\" --model_name_or_path \"gpt2\" --custom_dataset_path \"crows_pairs_anonymized_adapted_sg.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1981b067dac865d1",
   "metadata": {},
   "source": [
    "# Phi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2a5dd7169bad747",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T06:01:53.123684Z",
     "start_time": "2024-07-23T06:01:22.250Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running CrowS-Pairs benchmark:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: PhiForCausalLM\r\n",
      " - model_name_or_path: microsoft/phi-2\r\n",
      " - bias_type: religion\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:02<00:00,  1.28s/it]\r\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\r\n",
      "Evaluating religion examples.\r\n",
      "Unconditional start token: <|endoftext|>\r\n",
      "  0%|                                                   | 0/105 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\r\n",
      "100%|█████████████████████████████████████████| 105/105 [00:14<00:00,  7.33it/s]\r\n",
      "====================================================================================================\r\n",
      "Total examples: 105\r\n",
      "Metric score: 58.1\r\n",
      "Stereotype score: 60.0\r\n",
      "Anti-stereotype score: 20.0\r\n",
      "Num. neutral: 0.0\r\n",
      "====================================================================================================\r\n",
      "\r\n",
      "{\r\n",
      "    \"religion\": {\r\n",
      "        \"Total examples\": 105,\r\n",
      "        \"Metric score\": 58.1,\r\n",
      "        \"Stereotype score\": 60.0,\r\n",
      "        \"Anti-stereotype score\": 20.0,\r\n",
      "        \"Num. neutral\": 0.0\r\n",
      "    }\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "!python ../crows.py --bias_type \"religion\" --model \"PhiForCausalLM\" --model_name_or_path \"microsoft/phi-2\" --custom_dataset_path \"crows_pairs_anonymized_adapted_sg.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f619feab5eb0b6ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T06:03:18.495327Z",
     "start_time": "2024-07-23T06:01:53.125319Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running CrowS-Pairs benchmark:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: PhiForCausalLM\r\n",
      " - model_name_or_path: microsoft/phi-2\r\n",
      " - bias_type: race\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:02<00:00,  1.30s/it]\r\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\r\n",
      "Evaluating race-color examples.\r\n",
      "Unconditional start token: <|endoftext|>\r\n",
      "  0%|                                                   | 0/514 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\r\n",
      "100%|█████████████████████████████████████████| 514/514 [01:08<00:00,  7.54it/s]\r\n",
      "====================================================================================================\r\n",
      "Total examples: 514\r\n",
      "Metric score: 52.14\r\n",
      "Stereotype score: 52.07\r\n",
      "Anti-stereotype score: 54.84\r\n",
      "Num. neutral: 0.19\r\n",
      "====================================================================================================\r\n",
      "\r\n",
      "{\r\n",
      "    \"race-color\": {\r\n",
      "        \"Total examples\": 514,\r\n",
      "        \"Metric score\": 52.14,\r\n",
      "        \"Stereotype score\": 52.07,\r\n",
      "        \"Anti-stereotype score\": 54.84,\r\n",
      "        \"Num. neutral\": 0.19\r\n",
      "    }\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "!python ../crows.py --bias_type \"race\" --model \"PhiForCausalLM\" --model_name_or_path \"microsoft/phi-2\" --custom_dataset_path \"crows_pairs_anonymized_adapted_sg.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f080110b3ff6300f",
   "metadata": {},
   "source": [
    "# Llama 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c930fa5a6805141",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T06:03:59.444026Z",
     "start_time": "2024-07-23T06:03:18.496527Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running CrowS-Pairs benchmark:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: LlamaForCausalLM\r\n",
      " - model_name_or_path: meta-llama/Llama-2-7b-hf\r\n",
      " - bias_type: religion\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:04<00:00,  2.08s/it]\r\n",
      "Evaluating religion examples.\r\n",
      "Unconditional start token: <s>\r\n",
      "  0%|                                                   | 0/105 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\r\n",
      "100%|█████████████████████████████████████████| 105/105 [00:17<00:00,  5.98it/s]\r\n",
      "====================================================================================================\r\n",
      "Total examples: 105\r\n",
      "Metric score: 69.52\r\n",
      "Stereotype score: 72.0\r\n",
      "Anti-stereotype score: 20.0\r\n",
      "Num. neutral: 0.0\r\n",
      "====================================================================================================\r\n",
      "\r\n",
      "{\r\n",
      "    \"religion\": {\r\n",
      "        \"Total examples\": 105,\r\n",
      "        \"Metric score\": 69.52,\r\n",
      "        \"Stereotype score\": 72.0,\r\n",
      "        \"Anti-stereotype score\": 20.0,\r\n",
      "        \"Num. neutral\": 0.0\r\n",
      "    }\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "!python ../crows.py --bias_type \"religion\" --model \"LlamaForCausalLM\" --model_name_or_path \"meta-llama/Llama-2-7b-hf\" --custom_dataset_path \"crows_pairs_anonymized_adapted_sg.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a24a77b5bfb0fdc0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T06:05:47.611799Z",
     "start_time": "2024-07-23T06:03:59.445258Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running CrowS-Pairs benchmark:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: LlamaForCausalLM\r\n",
      " - model_name_or_path: meta-llama/Llama-2-7b-hf\r\n",
      " - bias_type: race\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:04<00:00,  2.05s/it]\r\n",
      "Evaluating race-color examples.\r\n",
      "Unconditional start token: <s>\r\n",
      "  0%|                                                   | 0/514 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\r\n",
      "100%|█████████████████████████████████████████| 514/514 [01:24<00:00,  6.05it/s]\r\n",
      "====================================================================================================\r\n",
      "Total examples: 514\r\n",
      "Metric score: 48.25\r\n",
      "Stereotype score: 47.41\r\n",
      "Anti-stereotype score: 61.29\r\n",
      "Num. neutral: 0.0\r\n",
      "====================================================================================================\r\n",
      "\r\n",
      "{\r\n",
      "    \"race-color\": {\r\n",
      "        \"Total examples\": 514,\r\n",
      "        \"Metric score\": 48.25,\r\n",
      "        \"Stereotype score\": 47.41,\r\n",
      "        \"Anti-stereotype score\": 61.29,\r\n",
      "        \"Num. neutral\": 0.0\r\n",
      "    }\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "!python ../crows.py --bias_type \"race\" --model \"LlamaForCausalLM\" --model_name_or_path \"meta-llama/Llama-2-7b-hf\" --custom_dataset_path \"crows_pairs_anonymized_adapted_sg.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acabd203bb835e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fyp] *",
   "language": "python",
   "name": "conda-env-fyp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
