{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f361ead929ce23d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T19:20:50.148756Z",
     "start_time": "2024-08-08T19:20:49.515030Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Aug  9 03:20:49 2024       \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 535.183.01             Driver Version: 535.183.01   CUDA Version: 12.2     |\r\n",
      "|-----------------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                      |               MIG M. |\r\n",
      "|=========================================+======================+======================|\r\n",
      "|   0  NVIDIA RTX A6000               Off | 00000000:01:00.0 Off |                  Off |\r\n",
      "| 34%   53C    P8              26W / 300W |      1MiB / 49140MiB |      0%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "|   1  NVIDIA RTX A6000               Off | 00000000:21:00.0 Off |                  Off |\r\n",
      "| 30%   48C    P8              21W / 300W |      1MiB / 49140MiB |      0%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "|   2  NVIDIA RTX A6000               Off | 00000000:41:00.0 Off |                  Off |\r\n",
      "| 30%   48C    P8              18W / 300W |      1MiB / 49140MiB |      0%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "|   3  NVIDIA RTX A6000               Off | 00000000:42:00.0 Off |                  Off |\r\n",
      "| 52%   76C    P2             298W / 300W |  14232MiB / 49140MiB |    100%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                            |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\r\n",
      "|        ID   ID                                                             Usage      |\r\n",
      "|=======================================================================================|\r\n",
      "|    3   N/A  N/A    101544      C   python                                     4740MiB |\r\n",
      "|    3   N/A  N/A    108857      C   python                                     4740MiB |\r\n",
      "|    3   N/A  N/A    113373      C   python                                     4740MiB |\r\n",
      "+---------------------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4bc140d99398a553",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T19:20:50.833379Z",
     "start_time": "2024-08-08T19:20:50.159359Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37mcil-hydra          \u001b[m  Fri Aug  9 03:20:50 2024  \u001b[1m\u001b[30m535.183.01\u001b[m\r\n",
      "\u001b[36m[0]\u001b[m \u001b[34mNVIDIA RTX A6000\u001b[m |\u001b[1m\u001b[31m 53°C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m    1\u001b[m / \u001b[33m49140\u001b[m MB |\r\n",
      "\u001b[36m[1]\u001b[m \u001b[34mNVIDIA RTX A6000\u001b[m |\u001b[31m 47°C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m    1\u001b[m / \u001b[33m49140\u001b[m MB |\r\n",
      "\u001b[36m[2]\u001b[m \u001b[34mNVIDIA RTX A6000\u001b[m |\u001b[31m 48°C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m    1\u001b[m / \u001b[33m49140\u001b[m MB |\r\n",
      "\u001b[36m[3]\u001b[m \u001b[34mNVIDIA RTX A6000\u001b[m |\u001b[1m\u001b[31m 76°C\u001b[m, \u001b[1m\u001b[32m100 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m14232\u001b[m / \u001b[33m49140\u001b[m MB | \u001b[1m\u001b[30mongzhiyang\u001b[m(\u001b[33m4740M\u001b[m) \u001b[1m\u001b[30mongzhiyang\u001b[m(\u001b[33m4740M\u001b[m) \u001b[1m\u001b[30mongzhiyang\u001b[m(\u001b[33m4740M\u001b[m)\r\n"
     ]
    }
   ],
   "source": [
    "!gpustat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T18:46:14.518778Z",
     "start_time": "2024-08-08T18:46:14.513754Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f579a466412a3580",
   "metadata": {},
   "source": [
    "# Pre debias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "931f617f687d27c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T04:15:39.222399Z",
     "start_time": "2024-08-08T04:13:58.640152Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: GPT2LMHeadModel\r\n",
      " - model_name_or_path: gpt2\r\n",
      " - batch_size: 1\r\n",
      " - seed: 42\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <|endoftext|>\r\n",
      "torch.Size([1, 1, 50257])\r\n",
      "100%|███████████████████████████████████████| 3970/3970 [01:30<00:00, 44.06it/s]\r\n"
     ]
    }
   ],
   "source": [
    "!python ../stereoset.py --model \"GPT2LMHeadModel\" --model_name_or_path \"gpt2\" --seed 42 --batch_size 1 --custom_dataset_path \"test_adapted_sg.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c8b1890af6b018e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T04:27:42.946529Z",
     "start_time": "2024-08-08T04:21:44.410208Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: PhiForCausalLM\r\n",
      " - model_name_or_path: microsoft/phi-2\r\n",
      " - batch_size: 1\r\n",
      " - seed: 42\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:02<00:00,  1.32s/it]\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <|endoftext|>\r\n",
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\r\n",
      "torch.Size([1, 1, 51200])\r\n",
      "100%|███████████████████████████████████████| 3970/3970 [05:41<00:00, 11.64it/s]\r\n"
     ]
    }
   ],
   "source": [
    "!python ../stereoset.py --model \"PhiForCausalLM\" --model_name_or_path \"microsoft/phi-2\" --seed 42 --batch_size 1 --custom_dataset_path \"test_adapted_sg.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7622fd1b6954fd8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T04:21:44.408566Z",
     "start_time": "2024-08-08T04:15:39.363435Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: LlamaForCausalLM\r\n",
      " - model_name_or_path: meta-llama/Llama-2-7b-hf\r\n",
      " - batch_size: 1\r\n",
      " - seed: 42\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:04<00:00,  2.35s/it]\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <s>\r\n",
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\r\n",
      "torch.Size([1, 1, 32000])\r\n",
      "100%|███████████████████████████████████████| 3970/3970 [05:40<00:00, 11.65it/s]\r\n"
     ]
    }
   ],
   "source": [
    "!python ../stereoset.py --model \"LlamaForCausalLM\" --model_name_or_path \"meta-llama/Llama-2-7b-hf\" --seed 42 --batch_size 1 --custom_dataset_path \"test_adapted_sg.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d604ee74cd348dcd",
   "metadata": {},
   "source": [
    "# After debias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f390a7172168cd60",
   "metadata": {},
   "source": [
    "# Self debias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23944f66497b98e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T05:13:38.530381Z",
     "start_time": "2024-08-08T05:03:10.202986Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing: python ../stereoset_debias.py --model 'SelfDebiasGPT2LMHeadModel' --model_name_or_path 'gpt2' --batch_size 1 --seed 42 --bias_type 'gender' --custom_dataset_path 'test_adapted_sg.json'\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: SelfDebiasGPT2LMHeadModel\r\n",
      " - model_name_or_path: gpt2\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: None\r\n",
      " - load_path: None\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: gender\r\n",
      " - seed: 42\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <|endoftext|>\r\n",
      "100%|███████████████████████████████████████| 3970/3970 [03:17<00:00, 20.05it/s]\r\n",
      "Executing: python ../stereoset_debias.py --model 'SelfDebiasGPT2LMHeadModel' --model_name_or_path 'gpt2' --batch_size 1 --seed 42 --bias_type 'religion' --custom_dataset_path 'test_adapted_sg.json'\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: SelfDebiasGPT2LMHeadModel\r\n",
      " - model_name_or_path: gpt2\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: None\r\n",
      " - load_path: None\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: religion\r\n",
      " - seed: 42\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <|endoftext|>\r\n",
      "100%|███████████████████████████████████████| 3970/3970 [03:16<00:00, 20.19it/s]\r\n",
      "Executing: python ../stereoset_debias.py --model 'SelfDebiasGPT2LMHeadModel' --model_name_or_path 'gpt2' --batch_size 1 --seed 42 --bias_type 'race-color' --custom_dataset_path 'test_adapted_sg.json'\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: SelfDebiasGPT2LMHeadModel\r\n",
      " - model_name_or_path: gpt2\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: None\r\n",
      " - load_path: None\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: race-color\r\n",
      " - seed: 42\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <|endoftext|>\r\n",
      "100%|███████████████████████████████████████| 3970/3970 [03:24<00:00, 19.44it/s]\r\n"
     ]
    }
   ],
   "source": [
    "bias_types = [\"gender\", \"religion\", \"race-color\"]\n",
    "\n",
    "for bias in bias_types:\n",
    "    command = f\"python ../stereoset_debias.py --model 'SelfDebiasGPT2LMHeadModel' --model_name_or_path 'gpt2' --batch_size 1 --seed 42 --bias_type '{bias}' --custom_dataset_path 'test_adapted_sg.json'\"\n",
    "    print(f\"Executing: {command}\")\n",
    "    get_ipython().system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9a5cdd6ff50aa99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T05:40:45.498087Z",
     "start_time": "2024-08-08T05:13:38.531932Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing: python ../stereoset_debias.py --model 'SelfDebiasPhi2LMHeadModel' --model_name_or_path 'microsoft/phi-2' --batch_size 1 --seed 42 --bias_type 'gender' --custom_dataset_path 'test_adapted_sg.json'\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: SelfDebiasPhi2LMHeadModel\r\n",
      " - model_name_or_path: microsoft/phi-2\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: None\r\n",
      " - load_path: None\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: gender\r\n",
      " - seed: 42\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:02<00:00,  1.46s/it]\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <|endoftext|>\r\n",
      "  0%|                                                  | 0/3970 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\r\n",
      "100%|███████████████████████████████████████| 3970/3970 [08:41<00:00,  7.61it/s]\r\n",
      "Executing: python ../stereoset_debias.py --model 'SelfDebiasPhi2LMHeadModel' --model_name_or_path 'microsoft/phi-2' --batch_size 1 --seed 42 --bias_type 'religion' --custom_dataset_path 'test_adapted_sg.json'\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: SelfDebiasPhi2LMHeadModel\r\n",
      " - model_name_or_path: microsoft/phi-2\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: None\r\n",
      " - load_path: None\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: religion\r\n",
      " - seed: 42\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:02<00:00,  1.34s/it]\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <|endoftext|>\r\n",
      "  0%|                                                  | 0/3970 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\r\n",
      "100%|███████████████████████████████████████| 3970/3970 [08:45<00:00,  7.55it/s]\r\n",
      "Executing: python ../stereoset_debias.py --model 'SelfDebiasPhi2LMHeadModel' --model_name_or_path 'microsoft/phi-2' --batch_size 1 --seed 42 --bias_type 'race-color' --custom_dataset_path 'test_adapted_sg.json'\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: SelfDebiasPhi2LMHeadModel\r\n",
      " - model_name_or_path: microsoft/phi-2\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: None\r\n",
      " - load_path: None\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: race-color\r\n",
      " - seed: 42\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:03<00:00,  1.55s/it]\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <|endoftext|>\r\n",
      "  0%|                                                  | 0/3970 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\r\n",
      "100%|███████████████████████████████████████| 3970/3970 [08:47<00:00,  7.52it/s]\r\n"
     ]
    }
   ],
   "source": [
    "bias_types = [\"gender\", \"religion\", \"race-color\"]\n",
    "\n",
    "for bias in bias_types:\n",
    "    command = f\"python ../stereoset_debias.py --model 'SelfDebiasPhi2LMHeadModel' --model_name_or_path 'microsoft/phi-2' --batch_size 1 --seed 42 --bias_type '{bias}' --custom_dataset_path 'test_adapted_sg.json'\"\n",
    "    print(f\"Executing: {command}\")\n",
    "    get_ipython().system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29f52d54c34261da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T06:07:56.931410Z",
     "start_time": "2024-08-08T05:40:45.499221Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing: python ../stereoset_debias.py --model 'SelfDebiasLlama2LMHeadModel' --model_name_or_path 'meta-llama/Llama-2-7b-hf' --batch_size 1 --seed 42 --bias_type 'gender' --custom_dataset_path 'test_adapted_sg.json'\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: SelfDebiasLlama2LMHeadModel\r\n",
      " - model_name_or_path: meta-llama/Llama-2-7b-hf\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: None\r\n",
      " - load_path: None\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: gender\r\n",
      " - seed: 42\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:04<00:00,  2.29s/it]\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <s>\r\n",
      "  0%|                                                  | 0/3970 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\r\n",
      "100%|███████████████████████████████████████| 3970/3970 [08:37<00:00,  7.67it/s]\r\n",
      "Executing: python ../stereoset_debias.py --model 'SelfDebiasLlama2LMHeadModel' --model_name_or_path 'meta-llama/Llama-2-7b-hf' --batch_size 1 --seed 42 --bias_type 'religion' --custom_dataset_path 'test_adapted_sg.json'\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: SelfDebiasLlama2LMHeadModel\r\n",
      " - model_name_or_path: meta-llama/Llama-2-7b-hf\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: None\r\n",
      " - load_path: None\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: religion\r\n",
      " - seed: 42\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:04<00:00,  2.23s/it]\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <s>\r\n",
      "  0%|                                                  | 0/3970 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\r\n",
      "100%|███████████████████████████████████████| 3970/3970 [08:35<00:00,  7.70it/s]\r\n",
      "Executing: python ../stereoset_debias.py --model 'SelfDebiasLlama2LMHeadModel' --model_name_or_path 'meta-llama/Llama-2-7b-hf' --batch_size 1 --seed 42 --bias_type 'race-color' --custom_dataset_path 'test_adapted_sg.json'\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: SelfDebiasLlama2LMHeadModel\r\n",
      " - model_name_or_path: meta-llama/Llama-2-7b-hf\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: None\r\n",
      " - load_path: None\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: race-color\r\n",
      " - seed: 42\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:06<00:00,  3.26s/it]\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <s>\r\n",
      "  0%|                                                  | 0/3970 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\r\n",
      "100%|███████████████████████████████████████| 3970/3970 [08:40<00:00,  7.63it/s]\r\n"
     ]
    }
   ],
   "source": [
    "bias_types = [\"gender\", \"religion\", \"race-color\"]\n",
    "\n",
    "for bias in bias_types:\n",
    "    command = f\"python ../stereoset_debias.py --model 'SelfDebiasLlama2LMHeadModel' --model_name_or_path 'meta-llama/Llama-2-7b-hf' --batch_size 1 --seed 42 --bias_type '{bias}' --custom_dataset_path 'test_adapted_sg.json'\"\n",
    "    print(f\"Executing: {command}\")\n",
    "    get_ipython().system(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6e981630860cbc",
   "metadata": {},
   "source": [
    "# Sentence Debias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a21dc896276372d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T06:18:33.120947Z",
     "start_time": "2024-08-08T06:12:35.972157Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing: python ../stereoset_debias.py --bias_type 'gender' --model 'SentenceDebiasGPT2LMHeadModel' --model_name_or_path 'gpt2' --batch_size 1 --seed 42  --bias_direction '../../results/subspace/subspace_m-GPT2Model_c-gpt2_t-gender.pt' --custom_dataset_path 'test_adapted_sg.json'\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: SentenceDebiasGPT2LMHeadModel\r\n",
      " - model_name_or_path: gpt2\r\n",
      " - bias_direction: ../../results/subspace/subspace_m-GPT2Model_c-gpt2_t-gender.pt\r\n",
      " - projection_matrix: None\r\n",
      " - load_path: None\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: gender\r\n",
      " - seed: 42\r\n",
      "Loaded bias direction.\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <|endoftext|>\r\n",
      "torch.Size([1, 1, 50257])\r\n",
      "100%|███████████████████████████████████████| 3970/3970 [01:48<00:00, 36.53it/s]\r\n",
      "Executing: python ../stereoset_debias.py --bias_type 'religion' --model 'SentenceDebiasGPT2LMHeadModel' --model_name_or_path 'gpt2' --batch_size 1 --seed 42  --bias_direction '../../results/subspace/subspace_m-GPT2Model_c-gpt2_t-religion.pt' --custom_dataset_path 'test_adapted_sg.json'\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: SentenceDebiasGPT2LMHeadModel\r\n",
      " - model_name_or_path: gpt2\r\n",
      " - bias_direction: ../../results/subspace/subspace_m-GPT2Model_c-gpt2_t-religion.pt\r\n",
      " - projection_matrix: None\r\n",
      " - load_path: None\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: religion\r\n",
      " - seed: 42\r\n",
      "Loaded bias direction.\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <|endoftext|>\r\n",
      "torch.Size([1, 1, 50257])\r\n",
      "100%|███████████████████████████████████████| 3970/3970 [01:48<00:00, 36.58it/s]\r\n",
      "Executing: python ../stereoset_debias.py --bias_type 'race-color' --model 'SentenceDebiasGPT2LMHeadModel' --model_name_or_path 'gpt2' --batch_size 1 --seed 42  --bias_direction '../../results/subspace/subspace_m-GPT2Model_c-gpt2_t-race-color.pt' --custom_dataset_path 'test_adapted_sg.json'\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: SentenceDebiasGPT2LMHeadModel\r\n",
      " - model_name_or_path: gpt2\r\n",
      " - bias_direction: ../../results/subspace/subspace_m-GPT2Model_c-gpt2_t-race-color.pt\r\n",
      " - projection_matrix: None\r\n",
      " - load_path: None\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: race-color\r\n",
      " - seed: 42\r\n",
      "Loaded bias direction.\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <|endoftext|>\r\n",
      "torch.Size([1, 1, 50257])\r\n",
      "100%|███████████████████████████████████████| 3970/3970 [01:48<00:00, 36.59it/s]\r\n"
     ]
    }
   ],
   "source": [
    "bias_types = [\"gender\", \"religion\", \"race-color\"]\n",
    "\n",
    "for bias in bias_types:\n",
    "    command = f\"python ../stereoset_debias.py --bias_type '{bias}' --model 'SentenceDebiasGPT2LMHeadModel' --model_name_or_path 'gpt2' --batch_size 1 --seed 42  --bias_direction '../../results/subspace/subspace_m-GPT2Model_c-gpt2_t-{bias}.pt' --custom_dataset_path 'test_adapted_sg.json'\"\n",
    "    print(f\"Executing: {command}\")\n",
    "    get_ipython().system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e3e293960d82c4b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T06:37:35.479408Z",
     "start_time": "2024-08-08T06:18:33.122667Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing: python ../stereoset_debias.py --bias_type 'gender' --model 'SentenceDebiasPhi2LMHeadModel' --model_name_or_path 'microsoft/phi-2' --batch_size 1 --seed 42  --bias_direction '../../results/subspace/subspace_m-PhiForCausalLM_NonBFloat16_c-microsoft_phi-2_t-gender.pt' --custom_dataset_path 'test_adapted_sg.json'\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: SentenceDebiasPhi2LMHeadModel\r\n",
      " - model_name_or_path: microsoft/phi-2\r\n",
      " - bias_direction: ../../results/subspace/subspace_m-PhiForCausalLM_NonBFloat16_c-microsoft_phi-2_t-gender.pt\r\n",
      " - projection_matrix: None\r\n",
      " - load_path: None\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: gender\r\n",
      " - seed: 42\r\n",
      "Loaded bias direction.\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:02<00:00,  1.40s/it]\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <|endoftext|>\r\n",
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\r\n",
      "torch.Size([1, 1, 51200])\r\n",
      "100%|███████████████████████████████████████| 3970/3970 [06:04<00:00, 10.89it/s]\r\n",
      "Executing: python ../stereoset_debias.py --bias_type 'religion' --model 'SentenceDebiasPhi2LMHeadModel' --model_name_or_path 'microsoft/phi-2' --batch_size 1 --seed 42  --bias_direction '../../results/subspace/subspace_m-PhiForCausalLM_NonBFloat16_c-microsoft_phi-2_t-religion.pt' --custom_dataset_path 'test_adapted_sg.json'\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: SentenceDebiasPhi2LMHeadModel\r\n",
      " - model_name_or_path: microsoft/phi-2\r\n",
      " - bias_direction: ../../results/subspace/subspace_m-PhiForCausalLM_NonBFloat16_c-microsoft_phi-2_t-religion.pt\r\n",
      " - projection_matrix: None\r\n",
      " - load_path: None\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: religion\r\n",
      " - seed: 42\r\n",
      "Loaded bias direction.\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:02<00:00,  1.37s/it]\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <|endoftext|>\r\n",
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\r\n",
      "torch.Size([1, 1, 51200])\r\n",
      "100%|███████████████████████████████████████| 3970/3970 [06:02<00:00, 10.96it/s]\r\n",
      "Executing: python ../stereoset_debias.py --bias_type 'race-color' --model 'SentenceDebiasPhi2LMHeadModel' --model_name_or_path 'microsoft/phi-2' --batch_size 1 --seed 42  --bias_direction '../../results/subspace/subspace_m-PhiForCausalLM_NonBFloat16_c-microsoft_phi-2_t-race-color.pt' --custom_dataset_path 'test_adapted_sg.json'\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: SentenceDebiasPhi2LMHeadModel\r\n",
      " - model_name_or_path: microsoft/phi-2\r\n",
      " - bias_direction: ../../results/subspace/subspace_m-PhiForCausalLM_NonBFloat16_c-microsoft_phi-2_t-race-color.pt\r\n",
      " - projection_matrix: None\r\n",
      " - load_path: None\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: race-color\r\n",
      " - seed: 42\r\n",
      "Loaded bias direction.\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:03<00:00,  1.90s/it]\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <|endoftext|>\r\n",
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\r\n",
      "torch.Size([1, 1, 51200])\r\n",
      "100%|███████████████████████████████████████| 3970/3970 [06:03<00:00, 10.93it/s]\r\n"
     ]
    }
   ],
   "source": [
    "bias_types = [\"gender\", \"religion\", \"race-color\"]\n",
    "\n",
    "for bias in bias_types:\n",
    "    command = f\"python ../stereoset_debias.py --bias_type '{bias}' --model 'SentenceDebiasPhi2LMHeadModel' --model_name_or_path 'microsoft/phi-2' --batch_size 1 --seed 42  --bias_direction '../../results/subspace/subspace_m-PhiForCausalLM_NonBFloat16_c-microsoft_phi-2_t-{bias}.pt' --custom_dataset_path 'test_adapted_sg.json'\"\n",
    "    print(f\"Executing: {command}\")\n",
    "    get_ipython().system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6fd0cd6b8bf0c016",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T07:09:57.930805Z",
     "start_time": "2024-08-08T06:37:35.480550Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing: python ../stereoset_debias.py --bias_type 'gender' --model 'SentenceDebiasLlama2LMHeadModel' --model_name_or_path 'meta-llama/Llama-2-7b-hf' --batch_size 1 --seed 42  --bias_direction '../../results/subspace/subspace_m-LlamaForCausalLM_NonBFloat16_c-meta-llama_Llama-2-7b-hf_t-gender.pt' --custom_dataset_path 'test_adapted_sg.json'\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: SentenceDebiasLlama2LMHeadModel\r\n",
      " - model_name_or_path: meta-llama/Llama-2-7b-hf\r\n",
      " - bias_direction: ../../results/subspace/subspace_m-LlamaForCausalLM_NonBFloat16_c-meta-llama_Llama-2-7b-hf_t-gender.pt\r\n",
      " - projection_matrix: None\r\n",
      " - load_path: None\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: gender\r\n",
      " - seed: 42\r\n",
      "Loaded bias direction.\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:04<00:00,  2.14s/it]\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <s>\r\n",
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\r\n",
      "torch.Size([1, 1, 32000])\r\n",
      "100%|███████████████████████████████████████| 3970/3970 [10:23<00:00,  6.37it/s]\r\n",
      "Executing: python ../stereoset_debias.py --bias_type 'religion' --model 'SentenceDebiasLlama2LMHeadModel' --model_name_or_path 'meta-llama/Llama-2-7b-hf' --batch_size 1 --seed 42  --bias_direction '../../results/subspace/subspace_m-LlamaForCausalLM_NonBFloat16_c-meta-llama_Llama-2-7b-hf_t-religion.pt' --custom_dataset_path 'test_adapted_sg.json'\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: SentenceDebiasLlama2LMHeadModel\r\n",
      " - model_name_or_path: meta-llama/Llama-2-7b-hf\r\n",
      " - bias_direction: ../../results/subspace/subspace_m-LlamaForCausalLM_NonBFloat16_c-meta-llama_Llama-2-7b-hf_t-religion.pt\r\n",
      " - projection_matrix: None\r\n",
      " - load_path: None\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: religion\r\n",
      " - seed: 42\r\n",
      "Loaded bias direction.\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:04<00:00,  2.13s/it]\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <s>\r\n",
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\r\n",
      "torch.Size([1, 1, 32000])\r\n",
      "100%|███████████████████████████████████████| 3970/3970 [10:24<00:00,  6.35it/s]\r\n",
      "Executing: python ../stereoset_debias.py --bias_type 'race-color' --model 'SentenceDebiasLlama2LMHeadModel' --model_name_or_path 'meta-llama/Llama-2-7b-hf' --batch_size 1 --seed 42  --bias_direction '../../results/subspace/subspace_m-LlamaForCausalLM_NonBFloat16_c-meta-llama_Llama-2-7b-hf_t-race-color.pt' --custom_dataset_path 'test_adapted_sg.json'\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: SentenceDebiasLlama2LMHeadModel\r\n",
      " - model_name_or_path: meta-llama/Llama-2-7b-hf\r\n",
      " - bias_direction: ../../results/subspace/subspace_m-LlamaForCausalLM_NonBFloat16_c-meta-llama_Llama-2-7b-hf_t-race-color.pt\r\n",
      " - projection_matrix: None\r\n",
      " - load_path: None\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: race-color\r\n",
      " - seed: 42\r\n",
      "Loaded bias direction.\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:04<00:00,  2.08s/it]\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <s>\r\n",
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\r\n",
      "torch.Size([1, 1, 32000])\r\n",
      "100%|███████████████████████████████████████| 3970/3970 [10:24<00:00,  6.36it/s]\r\n"
     ]
    }
   ],
   "source": [
    "bias_types = [\"gender\", \"religion\", \"race-color\"]\n",
    "\n",
    "for bias in bias_types:\n",
    "    command = f\"python ../stereoset_debias.py --bias_type '{bias}' --model 'SentenceDebiasLlama2LMHeadModel' --model_name_or_path 'meta-llama/Llama-2-7b-hf' --batch_size 1 --seed 42  --bias_direction '../../results/subspace/subspace_m-LlamaForCausalLM_NonBFloat16_c-meta-llama_Llama-2-7b-hf_t-{bias}.pt' --custom_dataset_path 'test_adapted_sg.json'\"\n",
    "    print(f\"Executing: {command}\")\n",
    "    get_ipython().system(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b92017523e354e",
   "metadata": {},
   "source": [
    "# INLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b3f7300b7c46ba",
   "metadata": {},
   "source": [
    "## n_classifiers = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ac32a120f1e971",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T07:15:49.047050Z",
     "start_time": "2024-08-08T07:09:57.932586Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing: python ../stereoset_debias.py --model 'INLPGPT2LMHeadModel' --model_name_or_path 'gpt2' --projection_matrix '../../results/projection_matrix/n_classifiers_80/projection_m-GPT2Model_c-gpt2_t-gender_s-42.pt' --bias_type 'gender' --batch_size 1 --seed 42 --custom_dataset_path 'test_adapted_sg.json'\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: INLPGPT2LMHeadModel\r\n",
      " - model_name_or_path: gpt2\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: ../../results/projection_matrix/n_classifiers_80/projection_m-GPT2Model_c-gpt2_t-gender_s-42.pt\r\n",
      " - load_path: None\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: gender\r\n",
      " - seed: 42\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <|endoftext|>\r\n",
      "torch.Size([1, 1, 50257])\r\n",
      "100%|███████████████████████████████████████| 3970/3970 [01:45<00:00, 37.80it/s]\r\n",
      "Executing: python ../stereoset_debias.py --model 'INLPGPT2LMHeadModel' --model_name_or_path 'gpt2' --projection_matrix '../../results/projection_matrix/n_classifiers_80/projection_m-GPT2Model_c-gpt2_t-religion_s-42.pt' --bias_type 'religion' --batch_size 1 --seed 42 --custom_dataset_path 'test_adapted_sg.json'\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: INLPGPT2LMHeadModel\r\n",
      " - model_name_or_path: gpt2\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: ../../results/projection_matrix/n_classifiers_80/projection_m-GPT2Model_c-gpt2_t-religion_s-42.pt\r\n",
      " - load_path: None\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: religion\r\n",
      " - seed: 42\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <|endoftext|>\r\n",
      "torch.Size([1, 1, 50257])\r\n",
      "100%|███████████████████████████████████████| 3970/3970 [01:47<00:00, 36.89it/s]\r\n",
      "Executing: python ../stereoset_debias.py --model 'INLPGPT2LMHeadModel' --model_name_or_path 'gpt2' --projection_matrix '../../results/projection_matrix/n_classifiers_80/projection_m-GPT2Model_c-gpt2_t-race-color_s-42.pt' --bias_type 'race-color' --batch_size 1 --seed 42 --custom_dataset_path 'test_adapted_sg.json'\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: INLPGPT2LMHeadModel\r\n",
      " - model_name_or_path: gpt2\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: ../../results/projection_matrix/n_classifiers_80/projection_m-GPT2Model_c-gpt2_t-race-color_s-42.pt\r\n",
      " - load_path: None\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: race-color\r\n",
      " - seed: 42\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <|endoftext|>\r\n",
      "torch.Size([1, 1, 50257])\r\n",
      "100%|███████████████████████████████████████| 3970/3970 [01:47<00:00, 36.86it/s]\r\n"
     ]
    }
   ],
   "source": [
    "bias_types = [\"gender\", \"religion\", \"race-color\"]\n",
    "\n",
    "for bias in bias_types:\n",
    "    command = f\"python ../stereoset_debias.py --model 'INLPGPT2LMHeadModel' --model_name_or_path 'gpt2' --projection_matrix '../../results/projection_matrix/n_classifiers_80/projection_m-GPT2Model_c-gpt2_t-{bias}_s-42.pt' --bias_type '{bias}' --batch_size 1 --seed 42 --custom_dataset_path 'test_adapted_sg.json'\"\n",
    "    print(f\"Executing: {command}\")\n",
    "    get_ipython().system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43e85e6b02afead2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T07:48:52.835251Z",
     "start_time": "2024-08-08T07:41:03.962854Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing: python ../stereoset_debias.py --model 'INLPPhi2LMHeadModel' --model_name_or_path 'microsoft/phi-2' --projection_matrix '../../results/projection_matrix/n_classifiers_80/projection_m-PhiForCausalLM_NonBFloat16_c-microsoft_phi-2_t-race-color_s-42.pt' --bias_type 'race-color' --batch_size 1 --seed 42 --custom_dataset_path 'test_adapted_sg.json'\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: INLPPhi2LMHeadModel\r\n",
      " - model_name_or_path: microsoft/phi-2\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: ../../results/projection_matrix/n_classifiers_80/projection_m-PhiForCausalLM_NonBFloat16_c-microsoft_phi-2_t-race-color_s-42.pt\r\n",
      " - load_path: None\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: race-color\r\n",
      " - seed: 42\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:02<00:00,  1.22s/it]\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <|endoftext|>\r\n",
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\r\n",
      "torch.Size([1, 1, 51200])\r\n",
      "100%|███████████████████████████████████████| 3970/3970 [07:32<00:00,  8.78it/s]\r\n"
     ]
    }
   ],
   "source": [
    "bias_types = [\"gender\", \"religion\", \"race-color\"]\n",
    "\n",
    "for bias in bias_types:\n",
    "    command = f\"python ../stereoset_debias.py --model 'INLPPhi2LMHeadModel' --model_name_or_path 'microsoft/phi-2' --projection_matrix '../../results/projection_matrix/n_classifiers_80/projection_m-PhiForCausalLM_NonBFloat16_c-microsoft_phi-2_t-{bias}_s-42.pt' --bias_type '{bias}' --batch_size 1 --seed 42 --custom_dataset_path 'test_adapted_sg.json'\"\n",
    "    print(f\"Executing: {command}\")\n",
    "    get_ipython().system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d2143b3aa461f45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T08:31:22.524960Z",
     "start_time": "2024-08-08T07:48:52.836532Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing: python ../stereoset_debias.py --model 'INLPLlama2LMHeadModel' --model_name_or_path 'meta-llama/Llama-2-7b-hf' --projection_matrix '../../results/projection_matrix/n_classifiers_80/projection_m-LlamaForCausalLM_NonBFloat16_c-meta-llama_Llama-2-7b-hf_t-gender_s-42.pt' --bias_type 'gender' --batch_size 1 --seed 42 --custom_dataset_path 'test_adapted_sg.json'\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: INLPLlama2LMHeadModel\r\n",
      " - model_name_or_path: meta-llama/Llama-2-7b-hf\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: ../../results/projection_matrix/n_classifiers_80/projection_m-LlamaForCausalLM_NonBFloat16_c-meta-llama_Llama-2-7b-hf_t-gender_s-42.pt\r\n",
      " - load_path: None\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: gender\r\n",
      " - seed: 42\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:04<00:00,  2.29s/it]\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <s>\r\n",
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\r\n",
      "torch.Size([1, 1, 32000])\r\n",
      "100%|███████████████████████████████████████| 3970/3970 [13:42<00:00,  4.83it/s]\r\n",
      "Executing: python ../stereoset_debias.py --model 'INLPLlama2LMHeadModel' --model_name_or_path 'meta-llama/Llama-2-7b-hf' --projection_matrix '../../results/projection_matrix/n_classifiers_80/projection_m-LlamaForCausalLM_NonBFloat16_c-meta-llama_Llama-2-7b-hf_t-religion_s-42.pt' --bias_type 'religion' --batch_size 1 --seed 42 --custom_dataset_path 'test_adapted_sg.json'\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: INLPLlama2LMHeadModel\r\n",
      " - model_name_or_path: meta-llama/Llama-2-7b-hf\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: ../../results/projection_matrix/n_classifiers_80/projection_m-LlamaForCausalLM_NonBFloat16_c-meta-llama_Llama-2-7b-hf_t-religion_s-42.pt\r\n",
      " - load_path: None\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: religion\r\n",
      " - seed: 42\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:04<00:00,  2.34s/it]\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <s>\r\n",
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\r\n",
      "torch.Size([1, 1, 32000])\r\n",
      "100%|███████████████████████████████████████| 3970/3970 [13:45<00:00,  4.81it/s]\r\n",
      "Executing: python ../stereoset_debias.py --model 'INLPLlama2LMHeadModel' --model_name_or_path 'meta-llama/Llama-2-7b-hf' --projection_matrix '../../results/projection_matrix/n_classifiers_80/projection_m-LlamaForCausalLM_NonBFloat16_c-meta-llama_Llama-2-7b-hf_t-race-color_s-42.pt' --bias_type 'race-color' --batch_size 1 --seed 42 --custom_dataset_path 'test_adapted_sg.json'\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: INLPLlama2LMHeadModel\r\n",
      " - model_name_or_path: meta-llama/Llama-2-7b-hf\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: ../../results/projection_matrix/n_classifiers_80/projection_m-LlamaForCausalLM_NonBFloat16_c-meta-llama_Llama-2-7b-hf_t-race-color_s-42.pt\r\n",
      " - load_path: None\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: race-color\r\n",
      " - seed: 42\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:04<00:00,  2.34s/it]\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <s>\r\n",
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\r\n",
      "torch.Size([1, 1, 32000])\r\n",
      "100%|███████████████████████████████████████| 3970/3970 [13:46<00:00,  4.80it/s]\r\n"
     ]
    }
   ],
   "source": [
    "bias_types = [\"gender\", \"religion\", \"race-color\"]\n",
    "\n",
    "for bias in bias_types:\n",
    "    command = f\"python ../stereoset_debias.py --model 'INLPLlama2LMHeadModel' --model_name_or_path 'meta-llama/Llama-2-7b-hf' --projection_matrix '../../results/projection_matrix/n_classifiers_80/projection_m-LlamaForCausalLM_NonBFloat16_c-meta-llama_Llama-2-7b-hf_t-{bias}_s-42.pt' --bias_type '{bias}' --batch_size 1 --seed 42 --custom_dataset_path 'test_adapted_sg.json'\"\n",
    "    print(f\"Executing: {command}\")\n",
    "    get_ipython().system(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3bf7c020404ee",
   "metadata": {},
   "source": [
    "# n_classifiers = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7abc9e636fe1efd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T08:42:12.422110Z",
     "start_time": "2024-08-08T08:35:38.585567Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing: python ../stereoset_debias.py --model 'INLPGPT2LMHeadModel' --model_name_or_path 'gpt2' --projection_matrix '../../results/projection_matrix/n_classifiers_10/projection_m-GPT2Model_c-gpt2_t-gender_s-42.pt' --bias_type 'gender' --batch_size 1 --seed 42 --custom_dataset_path 'test_adapted_sg.json'\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: INLPGPT2LMHeadModel\r\n",
      " - model_name_or_path: gpt2\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: ../../results/projection_matrix/n_classifiers_10/projection_m-GPT2Model_c-gpt2_t-gender_s-42.pt\r\n",
      " - load_path: None\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: gender\r\n",
      " - seed: 42\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <|endoftext|>\r\n",
      "torch.Size([1, 1, 50257])\r\n",
      "100%|███████████████████████████████████████| 3970/3970 [01:57<00:00, 33.87it/s]\r\n",
      "Executing: python ../stereoset_debias.py --model 'INLPGPT2LMHeadModel' --model_name_or_path 'gpt2' --projection_matrix '../../results/projection_matrix/n_classifiers_10/projection_m-GPT2Model_c-gpt2_t-religion_s-42.pt' --bias_type 'religion' --batch_size 1 --seed 42 --custom_dataset_path 'test_adapted_sg.json'\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: INLPGPT2LMHeadModel\r\n",
      " - model_name_or_path: gpt2\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: ../../results/projection_matrix/n_classifiers_10/projection_m-GPT2Model_c-gpt2_t-religion_s-42.pt\r\n",
      " - load_path: None\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: religion\r\n",
      " - seed: 42\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <|endoftext|>\r\n",
      "torch.Size([1, 1, 50257])\r\n",
      "100%|███████████████████████████████████████| 3970/3970 [01:57<00:00, 33.70it/s]\r\n",
      "Executing: python ../stereoset_debias.py --model 'INLPGPT2LMHeadModel' --model_name_or_path 'gpt2' --projection_matrix '../../results/projection_matrix/n_classifiers_10/projection_m-GPT2Model_c-gpt2_t-race-color_s-42.pt' --bias_type 'race-color' --batch_size 1 --seed 42 --custom_dataset_path 'test_adapted_sg.json'\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: INLPGPT2LMHeadModel\r\n",
      " - model_name_or_path: gpt2\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: ../../results/projection_matrix/n_classifiers_10/projection_m-GPT2Model_c-gpt2_t-race-color_s-42.pt\r\n",
      " - load_path: None\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: race-color\r\n",
      " - seed: 42\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <|endoftext|>\r\n",
      "torch.Size([1, 1, 50257])\r\n",
      "100%|███████████████████████████████████████| 3970/3970 [01:58<00:00, 33.42it/s]\r\n"
     ]
    }
   ],
   "source": [
    "bias_types = [\"gender\", \"religion\", \"race-color\"]\n",
    "\n",
    "for bias in bias_types:\n",
    "    command = f\"python ../stereoset_debias.py --model 'INLPGPT2LMHeadModel' --model_name_or_path 'gpt2' --projection_matrix '../../results/projection_matrix/n_classifiers_10/projection_m-GPT2Model_c-gpt2_t-{bias}_s-42.pt' --bias_type '{bias}' --batch_size 1 --seed 42 --custom_dataset_path 'test_adapted_sg.json'\"\n",
    "    print(f\"Executing: {command}\")\n",
    "    get_ipython().system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fbc04ca18defbda",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T09:06:40.607802Z",
     "start_time": "2024-08-08T08:42:12.423830Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing: python ../stereoset_debias.py --model 'INLPPhi2LMHeadModel' --model_name_or_path 'microsoft/phi-2' --projection_matrix '../../results/projection_matrix/n_classifiers_10/projection_m-PhiForCausalLM_NonBFloat16_c-microsoft_phi-2_t-gender_s-42.pt' --bias_type 'gender' --batch_size 1 --seed 42 --custom_dataset_path 'test_adapted_sg.json'\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: INLPPhi2LMHeadModel\r\n",
      " - model_name_or_path: microsoft/phi-2\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: ../../results/projection_matrix/n_classifiers_10/projection_m-PhiForCausalLM_NonBFloat16_c-microsoft_phi-2_t-gender_s-42.pt\r\n",
      " - load_path: None\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: gender\r\n",
      " - seed: 42\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:03<00:00,  1.53s/it]\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <|endoftext|>\r\n",
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\r\n",
      "torch.Size([1, 1, 51200])\r\n",
      "100%|███████████████████████████████████████| 3970/3970 [07:50<00:00,  8.43it/s]\r\n",
      "Executing: python ../stereoset_debias.py --model 'INLPPhi2LMHeadModel' --model_name_or_path 'microsoft/phi-2' --projection_matrix '../../results/projection_matrix/n_classifiers_10/projection_m-PhiForCausalLM_NonBFloat16_c-microsoft_phi-2_t-religion_s-42.pt' --bias_type 'religion' --batch_size 1 --seed 42 --custom_dataset_path 'test_adapted_sg.json'\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: INLPPhi2LMHeadModel\r\n",
      " - model_name_or_path: microsoft/phi-2\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: ../../results/projection_matrix/n_classifiers_10/projection_m-PhiForCausalLM_NonBFloat16_c-microsoft_phi-2_t-religion_s-42.pt\r\n",
      " - load_path: None\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: religion\r\n",
      " - seed: 42\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:03<00:00,  1.56s/it]\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <|endoftext|>\r\n",
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\r\n",
      "torch.Size([1, 1, 51200])\r\n",
      "100%|███████████████████████████████████████| 3970/3970 [07:55<00:00,  8.35it/s]\r\n",
      "Executing: python ../stereoset_debias.py --model 'INLPPhi2LMHeadModel' --model_name_or_path 'microsoft/phi-2' --projection_matrix '../../results/projection_matrix/n_classifiers_10/projection_m-PhiForCausalLM_NonBFloat16_c-microsoft_phi-2_t-race-color_s-42.pt' --bias_type 'race-color' --batch_size 1 --seed 42 --custom_dataset_path 'test_adapted_sg.json'\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: INLPPhi2LMHeadModel\r\n",
      " - model_name_or_path: microsoft/phi-2\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: ../../results/projection_matrix/n_classifiers_10/projection_m-PhiForCausalLM_NonBFloat16_c-microsoft_phi-2_t-race-color_s-42.pt\r\n",
      " - load_path: None\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: race-color\r\n",
      " - seed: 42\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:03<00:00,  1.52s/it]\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <|endoftext|>\r\n",
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\r\n",
      "torch.Size([1, 1, 51200])\r\n",
      "100%|███████████████████████████████████████| 3970/3970 [07:45<00:00,  8.53it/s]\r\n"
     ]
    }
   ],
   "source": [
    "bias_types = [\"gender\", \"religion\", \"race-color\"]\n",
    "\n",
    "for bias in bias_types:\n",
    "    command = f\"python ../stereoset_debias.py --model 'INLPPhi2LMHeadModel' --model_name_or_path 'microsoft/phi-2' --projection_matrix '../../results/projection_matrix/n_classifiers_10/projection_m-PhiForCausalLM_NonBFloat16_c-microsoft_phi-2_t-{bias}_s-42.pt' --bias_type '{bias}' --batch_size 1 --seed 42 --custom_dataset_path 'test_adapted_sg.json'\"\n",
    "    print(f\"Executing: {command}\")\n",
    "    get_ipython().system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f5479269a53cbdf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T10:01:39.650754Z",
     "start_time": "2024-08-08T09:33:18.538659Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing: python ../stereoset_debias.py --model 'INLPLlama2LMHeadModel' --model_name_or_path 'meta-llama/Llama-2-7b-hf' --projection_matrix '../../results/projection_matrix/n_classifiers_10/projection_m-LlamaForCausalLM_NonBFloat16_c-meta-llama_Llama-2-7b-hf_t-religion_s-42.pt' --bias_type 'religion' --batch_size 1 --seed 42 --custom_dataset_path 'test_adapted_sg.json'\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: INLPLlama2LMHeadModel\r\n",
      " - model_name_or_path: meta-llama/Llama-2-7b-hf\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: ../../results/projection_matrix/n_classifiers_10/projection_m-LlamaForCausalLM_NonBFloat16_c-meta-llama_Llama-2-7b-hf_t-religion_s-42.pt\r\n",
      " - load_path: None\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: religion\r\n",
      " - seed: 42\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:04<00:00,  2.04s/it]\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <s>\r\n",
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\r\n",
      "torch.Size([1, 1, 32000])\r\n",
      "100%|███████████████████████████████████████| 3970/3970 [13:51<00:00,  4.77it/s]\r\n",
      "Executing: python ../stereoset_debias.py --model 'INLPLlama2LMHeadModel' --model_name_or_path 'meta-llama/Llama-2-7b-hf' --projection_matrix '../../results/projection_matrix/n_classifiers_10/projection_m-LlamaForCausalLM_NonBFloat16_c-meta-llama_Llama-2-7b-hf_t-race-color_s-42.pt' --bias_type 'race-color' --batch_size 1 --seed 42 --custom_dataset_path 'test_adapted_sg.json'\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: INLPLlama2LMHeadModel\r\n",
      " - model_name_or_path: meta-llama/Llama-2-7b-hf\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: ../../results/projection_matrix/n_classifiers_10/projection_m-LlamaForCausalLM_NonBFloat16_c-meta-llama_Llama-2-7b-hf_t-race-color_s-42.pt\r\n",
      " - load_path: None\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: race-color\r\n",
      " - seed: 42\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:04<00:00,  2.34s/it]\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <s>\r\n",
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\r\n",
      "torch.Size([1, 1, 32000])\r\n",
      "100%|███████████████████████████████████████| 3970/3970 [13:42<00:00,  4.83it/s]\r\n"
     ]
    }
   ],
   "source": [
    "bias_types = [\n",
    "    #\"gender\", \n",
    "    \"religion\", \"race-color\"]\n",
    "\n",
    "for bias in bias_types:\n",
    "    command = f\"python ../stereoset_debias.py --model 'INLPLlama2LMHeadModel' --model_name_or_path 'meta-llama/Llama-2-7b-hf' --projection_matrix '../../results/projection_matrix/n_classifiers_10/projection_m-LlamaForCausalLM_NonBFloat16_c-meta-llama_Llama-2-7b-hf_t-{bias}_s-42.pt' --bias_type '{bias}' --batch_size 1 --seed 42 --custom_dataset_path 'test_adapted_sg.json'\"\n",
    "    print(f\"Executing: {command}\")\n",
    "    get_ipython().system(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1563e48c7257e15",
   "metadata": {},
   "source": [
    "# CDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb25c398fc27e679",
   "metadata": {},
   "source": [
    "# GPT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21ecdf3de532262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ckpt_num in range(100, 2001, 100):\n",
    "for ckpt_num in range(100, 2001, 100):\n",
    "    command = f\"python ../stereoset_debias.py --model 'CDAGPT2LMHeadModel' --model_name_or_path 'gpt2' --load_path '/home/ongzhiyang/bias-bench-main/results/CDA_FT/gpt2/gender/checkpoint-{ckpt_num}' --bias_type 'gender' --ckpt_num {ckpt_num} --batch_size 1 --seed 42 --custom_dataset_path 'test_adapted_sg.json'\"\n",
    "    print(f\"Executing: {command}\")\n",
    "    get_ipython().system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d02dbb98483043c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ckpt_num in range(100, 2001, 100):\n",
    "for ckpt_num in range(100, 2001, 100):\n",
    "    command = f\"python ../stereoset_debias.py --model 'CDAGPT2LMHeadModel' --model_name_or_path 'gpt2' --load_path '/home/ongzhiyang/bias-bench-main/results/CDA_FT/gpt2/race/checkpoint-{ckpt_num}' --bias_type 'race-color' --ckpt_num {ckpt_num} --batch_size 1 --seed 42 --custom_dataset_path 'test_adapted_sg.json'\"\n",
    "    print(f\"Executing: {command}\")\n",
    "    get_ipython().system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb242dbc182e764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ckpt_num in range(100, 2001, 100):\n",
    "for ckpt_num in range(100, 2001, 100):\n",
    "    command = f\"python ../stereoset_debias.py --model 'CDAGPT2LMHeadModel' --model_name_or_path 'gpt2' --load_path '/home/ongzhiyang/bias-bench-main/results/CDA_FT/gpt2/religion/checkpoint-{ckpt_num}' --bias_type 'religion' --ckpt_num {ckpt_num} --batch_size 1 --seed 42 --custom_dataset_path 'test_adapted_sg.json'\"\n",
    "    print(f\"Executing: {command}\")\n",
    "    get_ipython().system(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3980e849b2e94",
   "metadata": {},
   "source": [
    "# Phi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f794c67c53da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ckpt_num in range(100, 2001, 100):\n",
    "for ckpt_num in range(100, 2001, 100):\n",
    "    command = f\"python ../stereoset_debias.py --model 'CDAPhi2LMHeadModel' --model_name_or_path 'microsoft/phi-2' --load_path '/home/ongzhiyang/bias-bench-main/results/CDA_FT/phi2/gender/checkpoint-{ckpt_num}' --bias_type 'gender' --ckpt_num {ckpt_num} --batch_size 1 --seed 42 --custom_dataset_path 'test_adapted_sg.json'\"\n",
    "    print(f\"Executing: {command}\")\n",
    "    get_ipython().system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b04fdf16879e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ckpt_num in range(100, 2001, 100):\n",
    "for ckpt_num in range(100, 2001, 100):\n",
    "    command = f\"python ../stereoset_debias.py --model 'CDAPhi2LMHeadModel' --model_name_or_path 'microsoft/phi-2' --load_path '/home/ongzhiyang/bias-bench-main/results/CDA_FT/phi2/race/checkpoint-{ckpt_num}' --bias_type 'race-color' --ckpt_num {ckpt_num} --batch_size 1 --seed 42 --custom_dataset_path 'test_adapted_sg.json'\"\n",
    "    print(f\"Executing: {command}\")\n",
    "    get_ipython().system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397b830d1c73d817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ckpt_num in range(100, 2001, 100):\n",
    "for ckpt_num in range(100, 2001, 100):\n",
    "    command = f\"python ../stereoset_debias.py --model 'CDAPhi2LMHeadModel' --model_name_or_path 'microsoft/phi-2' --load_path '/home/ongzhiyang/bias-bench-main/results/CDA_FT/phi2/religion/checkpoint-{ckpt_num}' --bias_type 'religion' --ckpt_num {ckpt_num} --batch_size 1 --seed 42 --custom_dataset_path 'test_adapted_sg.json'\"\n",
    "    print(f\"Executing: {command}\")\n",
    "    get_ipython().system(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86d435960b3a83f",
   "metadata": {},
   "source": [
    "# Llama2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106ac3df41f94ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ckpt_num in range(100, 2001, 100):\n",
    "for ckpt_num in range(100, 2001, 100):\n",
    "    command = f\"python ../stereoset_debias.py --model 'CDALlama2LMHeadModel' --model_name_or_path 'meta-llama/Llama-2-7b-hf' --load_path '/home/ongzhiyang/bias-bench-main/results/CDA_FT/llama2/gender/checkpoint-{ckpt_num}' --bias_type 'gender' --ckpt_num {ckpt_num} --batch_size 1 --seed 42 --custom_dataset_path 'test_adapted_sg.json'\"\n",
    "    print(f\"Executing: {command}\")\n",
    "    get_ipython().system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc9dde34a194155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ckpt_num in range(100, 2001, 100):\n",
    "for ckpt_num in range(100, 2001, 100):\n",
    "    command = f\"python ../stereoset_debias.py --model 'CDALlama2LMHeadModel' --model_name_or_path 'meta-llama/Llama-2-7b-hf' --load_path '/home/ongzhiyang/bias-bench-main/results/CDA_FT/llama2/race/checkpoint-{ckpt_num}' --bias_type 'race-color' --ckpt_num {ckpt_num} --batch_size 1 --seed 42 --custom_dataset_path 'test_adapted_sg.json'\"\n",
    "    print(f\"Executing: {command}\")\n",
    "    get_ipython().system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3902f3ab92e0dc3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T17:22:01.465782Z",
     "start_time": "2024-08-08T13:36:49.073303Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing: python ../stereoset_debias.py --model 'CDALlama2LMHeadModel' --model_name_or_path 'meta-llama/Llama-2-7b-hf' --load_path '/home/ongzhiyang/bias-bench-main/results/CDA_FT/llama2/religion/checkpoint-1100' --bias_type 'religion' --ckpt_num 1100 --batch_size 1 --seed 42 --custom_dataset_path 'test_adapted_sg.json'\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: CDALlama2LMHeadModel\r\n",
      " - model_name_or_path: meta-llama/Llama-2-7b-hf\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: None\r\n",
      " - load_path: /home/ongzhiyang/bias-bench-main/results/CDA_FT/llama2/religion/checkpoint-1100\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: religion\r\n",
      " - seed: 42\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:10<00:00,  5.11s/it]\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <s>\r\n",
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\r\n",
      "torch.Size([1, 1, 32000])\r\n",
      "100%|███████████████████████████████████████| 3970/3970 [21:13<00:00,  3.12it/s]\r\n",
      "Executing: python ../stereoset_debias.py --model 'CDALlama2LMHeadModel' --model_name_or_path 'meta-llama/Llama-2-7b-hf' --load_path '/home/ongzhiyang/bias-bench-main/results/CDA_FT/llama2/religion/checkpoint-1200' --bias_type 'religion' --ckpt_num 1200 --batch_size 1 --seed 42 --custom_dataset_path 'test_adapted_sg.json'\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: CDALlama2LMHeadModel\r\n",
      " - model_name_or_path: meta-llama/Llama-2-7b-hf\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: None\r\n",
      " - load_path: /home/ongzhiyang/bias-bench-main/results/CDA_FT/llama2/religion/checkpoint-1200\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: religion\r\n",
      " - seed: 42\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:14<00:00,  7.36s/it]\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <s>\r\n",
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\r\n",
      "torch.Size([1, 1, 32000])\r\n",
      "100%|███████████████████████████████████████| 3970/3970 [21:21<00:00,  3.10it/s]\r\n",
      "Executing: python ../stereoset_debias.py --model 'CDALlama2LMHeadModel' --model_name_or_path 'meta-llama/Llama-2-7b-hf' --load_path '/home/ongzhiyang/bias-bench-main/results/CDA_FT/llama2/religion/checkpoint-1300' --bias_type 'religion' --ckpt_num 1300 --batch_size 1 --seed 42 --custom_dataset_path 'test_adapted_sg.json'\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: CDALlama2LMHeadModel\r\n",
      " - model_name_or_path: meta-llama/Llama-2-7b-hf\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: None\r\n",
      " - load_path: /home/ongzhiyang/bias-bench-main/results/CDA_FT/llama2/religion/checkpoint-1300\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: religion\r\n",
      " - seed: 42\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:11<00:00,  5.80s/it]\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <s>\r\n",
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\r\n",
      "torch.Size([1, 1, 32000])\r\n",
      "100%|███████████████████████████████████████| 3970/3970 [21:00<00:00,  3.15it/s]\r\n",
      "Executing: python ../stereoset_debias.py --model 'CDALlama2LMHeadModel' --model_name_or_path 'meta-llama/Llama-2-7b-hf' --load_path '/home/ongzhiyang/bias-bench-main/results/CDA_FT/llama2/religion/checkpoint-1400' --bias_type 'religion' --ckpt_num 1400 --batch_size 1 --seed 42 --custom_dataset_path 'test_adapted_sg.json'\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: CDALlama2LMHeadModel\r\n",
      " - model_name_or_path: meta-llama/Llama-2-7b-hf\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: None\r\n",
      " - load_path: /home/ongzhiyang/bias-bench-main/results/CDA_FT/llama2/religion/checkpoint-1400\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: religion\r\n",
      " - seed: 42\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:10<00:00,  5.48s/it]\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <s>\r\n",
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\r\n",
      "torch.Size([1, 1, 32000])\r\n",
      "100%|███████████████████████████████████████| 3970/3970 [20:42<00:00,  3.20it/s]\r\n",
      "Executing: python ../stereoset_debias.py --model 'CDALlama2LMHeadModel' --model_name_or_path 'meta-llama/Llama-2-7b-hf' --load_path '/home/ongzhiyang/bias-bench-main/results/CDA_FT/llama2/religion/checkpoint-1500' --bias_type 'religion' --ckpt_num 1500 --batch_size 1 --seed 42 --custom_dataset_path 'test_adapted_sg.json'\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: CDALlama2LMHeadModel\r\n",
      " - model_name_or_path: meta-llama/Llama-2-7b-hf\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: None\r\n",
      " - load_path: /home/ongzhiyang/bias-bench-main/results/CDA_FT/llama2/religion/checkpoint-1500\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: religion\r\n",
      " - seed: 42\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:12<00:00,  6.44s/it]\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <s>\r\n",
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\r\n",
      "torch.Size([1, 1, 32000])\r\n",
      "100%|███████████████████████████████████████| 3970/3970 [20:46<00:00,  3.19it/s]\r\n",
      "Executing: python ../stereoset_debias.py --model 'CDALlama2LMHeadModel' --model_name_or_path 'meta-llama/Llama-2-7b-hf' --load_path '/home/ongzhiyang/bias-bench-main/results/CDA_FT/llama2/religion/checkpoint-1600' --bias_type 'religion' --ckpt_num 1600 --batch_size 1 --seed 42 --custom_dataset_path 'test_adapted_sg.json'\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: CDALlama2LMHeadModel\r\n",
      " - model_name_or_path: meta-llama/Llama-2-7b-hf\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: None\r\n",
      " - load_path: /home/ongzhiyang/bias-bench-main/results/CDA_FT/llama2/religion/checkpoint-1600\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: religion\r\n",
      " - seed: 42\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:10<00:00,  5.25s/it]\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <s>\r\n",
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\r\n",
      "torch.Size([1, 1, 32000])\r\n",
      "100%|███████████████████████████████████████| 3970/3970 [20:44<00:00,  3.19it/s]\r\n",
      "Executing: python ../stereoset_debias.py --model 'CDALlama2LMHeadModel' --model_name_or_path 'meta-llama/Llama-2-7b-hf' --load_path '/home/ongzhiyang/bias-bench-main/results/CDA_FT/llama2/religion/checkpoint-1700' --bias_type 'religion' --ckpt_num 1700 --batch_size 1 --seed 42 --custom_dataset_path 'test_adapted_sg.json'\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: CDALlama2LMHeadModel\r\n",
      " - model_name_or_path: meta-llama/Llama-2-7b-hf\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: None\r\n",
      " - load_path: /home/ongzhiyang/bias-bench-main/results/CDA_FT/llama2/religion/checkpoint-1700\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: religion\r\n",
      " - seed: 42\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:10<00:00,  5.24s/it]\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <s>\r\n",
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\r\n",
      "torch.Size([1, 1, 32000])\r\n",
      "100%|███████████████████████████████████████| 3970/3970 [20:45<00:00,  3.19it/s]\r\n",
      "Executing: python ../stereoset_debias.py --model 'CDALlama2LMHeadModel' --model_name_or_path 'meta-llama/Llama-2-7b-hf' --load_path '/home/ongzhiyang/bias-bench-main/results/CDA_FT/llama2/religion/checkpoint-1800' --bias_type 'religion' --ckpt_num 1800 --batch_size 1 --seed 42 --custom_dataset_path 'test_adapted_sg.json'\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: CDALlama2LMHeadModel\r\n",
      " - model_name_or_path: meta-llama/Llama-2-7b-hf\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: None\r\n",
      " - load_path: /home/ongzhiyang/bias-bench-main/results/CDA_FT/llama2/religion/checkpoint-1800\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: religion\r\n",
      " - seed: 42\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:10<00:00,  5.32s/it]\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <s>\r\n",
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\r\n",
      "torch.Size([1, 1, 32000])\r\n",
      "100%|███████████████████████████████████████| 3970/3970 [20:47<00:00,  3.18it/s]\r\n",
      "Executing: python ../stereoset_debias.py --model 'CDALlama2LMHeadModel' --model_name_or_path 'meta-llama/Llama-2-7b-hf' --load_path '/home/ongzhiyang/bias-bench-main/results/CDA_FT/llama2/religion/checkpoint-1900' --bias_type 'religion' --ckpt_num 1900 --batch_size 1 --seed 42 --custom_dataset_path 'test_adapted_sg.json'\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: CDALlama2LMHeadModel\r\n",
      " - model_name_or_path: meta-llama/Llama-2-7b-hf\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: None\r\n",
      " - load_path: /home/ongzhiyang/bias-bench-main/results/CDA_FT/llama2/religion/checkpoint-1900\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: religion\r\n",
      " - seed: 42\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:10<00:00,  5.35s/it]\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <s>\r\n",
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\r\n",
      "torch.Size([1, 1, 32000])\r\n",
      "100%|███████████████████████████████████████| 3970/3970 [26:59<00:00,  2.45it/s]\r\n",
      "Executing: python ../stereoset_debias.py --model 'CDALlama2LMHeadModel' --model_name_or_path 'meta-llama/Llama-2-7b-hf' --load_path '/home/ongzhiyang/bias-bench-main/results/CDA_FT/llama2/religion/checkpoint-2000' --bias_type 'religion' --ckpt_num 2000 --batch_size 1 --seed 42 --custom_dataset_path 'test_adapted_sg.json'\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: CDALlama2LMHeadModel\r\n",
      " - model_name_or_path: meta-llama/Llama-2-7b-hf\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: None\r\n",
      " - load_path: /home/ongzhiyang/bias-bench-main/results/CDA_FT/llama2/religion/checkpoint-2000\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: religion\r\n",
      " - seed: 42\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:10<00:00,  5.47s/it]\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <s>\r\n",
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\r\n",
      "torch.Size([1, 1, 32000])\r\n",
      "100%|███████████████████████████████████████| 3970/3970 [26:56<00:00,  2.46it/s]\r\n"
     ]
    }
   ],
   "source": [
    "# for ckpt_num in range(100, 2001, 100):\n",
    "for ckpt_num in range(1100, 2001, 100):\n",
    "    command = f\"python ../stereoset_debias.py --model 'CDALlama2LMHeadModel' --model_name_or_path 'meta-llama/Llama-2-7b-hf' --load_path '/home/ongzhiyang/bias-bench-main/results/CDA_FT/llama2/religion/checkpoint-{ckpt_num}' --bias_type 'religion' --ckpt_num {ckpt_num} --batch_size 1 --seed 42 --custom_dataset_path 'test_adapted_sg.json'\"\n",
    "    print(f\"Executing: {command}\")\n",
    "    get_ipython().system(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37d445ab99b12ba",
   "metadata": {},
   "source": [
    "# Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3531755f0df4a9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ckpt_num in range(100, 2001, 100):\n",
    "for ckpt_num in range(100, 2001, 100):\n",
    "    command = f\"python ../stereoset_debias.py --model 'DropoutGPT2LMHeadModel' --model_name_or_path 'gpt2' --load_path '/home/ongzhiyang/bias-bench-main/results/dropout_FT/gpt2/checkpoint-{ckpt_num}' --ckpt_num {ckpt_num} --batch_size 1 --seed 42 --custom_dataset_path 'test_adapted_sg.json'\"\n",
    "    print(f\"Executing: {command}\")\n",
    "    get_ipython().system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489ff0fb8e97cef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ckpt_num in range(100, 2001, 100):\n",
    "for ckpt_num in range(100, 2001, 100):\n",
    "    command = f\"python ../stereoset_debias.py --model 'DropoutPhi2LMHeadModel' --model_name_or_path 'microsoft/phi-2' --load_path '/home/ongzhiyang/bias-bench-main/results/dropout_FT/phi2/checkpoint-{ckpt_num}' --ckpt_num {ckpt_num} --batch_size 1 --seed 42 --custom_dataset_path 'test_adapted_sg.json'\"\n",
    "    print(f\"Executing: {command}\")\n",
    "    get_ipython().system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f12ae10ded4c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ckpt_num in range(100, 2001, 100):\n",
    "    command = f\"python ../stereoset_debias.py --model 'DropoutLlama2LMHeadModel' --model_name_or_path 'meta-llama/Llama-2-7b-hf' --load_path '/home/ongzhiyang/bias-bench-main/results/dropout_FT/llama2/checkpoint-{ckpt_num}' --ckpt_num {ckpt_num} --batch_size 1 --seed 42 --custom_dataset_path 'test_adapted_sg.json'\"\n",
    "    print(f\"Executing: {command}\")\n",
    "    get_ipython().system(command)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fyp] *",
   "language": "python",
   "name": "conda-env-fyp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
