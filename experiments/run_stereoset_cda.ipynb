{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39d219200edf9527",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T07:49:59.604312Z",
     "start_time": "2024-08-08T07:49:59.008584Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Aug  8 15:49:59 2024       \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 535.183.01             Driver Version: 535.183.01   CUDA Version: 12.2     |\r\n",
      "|-----------------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                      |               MIG M. |\r\n",
      "|=========================================+======================+======================|\r\n",
      "|   0  NVIDIA RTX A6000               Off | 00000000:01:00.0 Off |                  Off |\r\n",
      "| 43%   66C    P2             127W / 300W |   4746MiB / 49140MiB |     39%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "|   1  NVIDIA RTX A6000               Off | 00000000:21:00.0 Off |                  Off |\r\n",
      "| 38%   70C    P2             290W / 300W |   7173MiB / 49140MiB |     99%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "|   2  NVIDIA RTX A6000               Off | 00000000:41:00.0 Off |                  Off |\r\n",
      "| 42%   72C    P2             284W / 300W |  26226MiB / 49140MiB |     86%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "|   3  NVIDIA RTX A6000               Off | 00000000:42:00.0 Off |                  Off |\r\n",
      "| 30%   62C    P2             239W / 300W |   5079MiB / 49140MiB |    100%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                            |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\r\n",
      "|        ID   ID                                                             Usage      |\r\n",
      "|=======================================================================================|\r\n",
      "|    0   N/A  N/A   2930955      C   python                                     4740MiB |\r\n",
      "|    1   N/A  N/A   2906921      C   python                                     3582MiB |\r\n",
      "|    1   N/A  N/A   2915798      C   python                                     3582MiB |\r\n",
      "|    2   N/A  N/A   2923054      C   python                                    26220MiB |\r\n",
      "|    3   N/A  N/A   2899805      C   python                                      494MiB |\r\n",
      "|    3   N/A  N/A   2910471      C   python                                      494MiB |\r\n",
      "|    3   N/A  N/A   2925445      C   python                                     3582MiB |\r\n",
      "|    3   N/A  N/A   2927974      C   python                                      494MiB |\r\n",
      "+---------------------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1643139a4205937e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T07:51:27.000746Z",
     "start_time": "2024-08-08T07:51:26.308477Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37mcil-hydra          \u001b[m  Thu Aug  8 15:51:26 2024  \u001b[1m\u001b[30m535.183.01\u001b[m\r\n",
      "\u001b[36m[0]\u001b[m \u001b[34mNVIDIA RTX A6000\u001b[m |\u001b[1m\u001b[31m 53°C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m    1\u001b[m / \u001b[33m49140\u001b[m MB |\r\n",
      "\u001b[36m[1]\u001b[m \u001b[34mNVIDIA RTX A6000\u001b[m |\u001b[1m\u001b[31m 72°C\u001b[m, \u001b[1m\u001b[32m 87 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m 7173\u001b[m / \u001b[33m49140\u001b[m MB | \u001b[1m\u001b[30mongzhiyang\u001b[m(\u001b[33m3582M\u001b[m) \u001b[1m\u001b[30mongzhiyang\u001b[m(\u001b[33m3582M\u001b[m)\r\n",
      "\u001b[36m[2]\u001b[m \u001b[34mNVIDIA RTX A6000\u001b[m |\u001b[1m\u001b[31m 76°C\u001b[m, \u001b[1m\u001b[32m 73 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m26226\u001b[m / \u001b[33m49140\u001b[m MB | \u001b[1m\u001b[30mongzhiyang\u001b[m(\u001b[33m26220M\u001b[m)\r\n",
      "\u001b[36m[3]\u001b[m \u001b[34mNVIDIA RTX A6000\u001b[m |\u001b[1m\u001b[31m 64°C\u001b[m, \u001b[1m\u001b[32m 97 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m 5079\u001b[m / \u001b[33m49140\u001b[m MB | \u001b[1m\u001b[30mongzhiyang\u001b[m(\u001b[33m494M\u001b[m) \u001b[1m\u001b[30mongzhiyang\u001b[m(\u001b[33m3582M\u001b[m) \u001b[1m\u001b[30mongzhiyang\u001b[m(\u001b[33m494M\u001b[m) \u001b[1m\u001b[30mongzhiyang\u001b[m(\u001b[33m494M\u001b[m)\r\n"
     ]
    }
   ],
   "source": [
    "!gpustat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a820a8cb69b8c3d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T13:46:38.944821Z",
     "start_time": "2024-08-06T13:46:38.941831Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d04ee7382216719",
   "metadata": {},
   "source": [
    "# GPT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87365dfaf531bd27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T14:13:08.626581Z",
     "start_time": "2024-08-03T12:49:15.763311Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing: python stereoset_debias.py --model 'CDAGPT2LMHeadModel' --model_name_or_path 'gpt2' --load_path '/home/ongzhiyang/bias-bench-main/results/CDA_FT/gpt2/gender/checkpoint-100' --bias_type 'gender' --ckpt_num 100 --batch_size 1 --seed 42\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: CDAGPT2LMHeadModel\r\n",
      " - model_name_or_path: gpt2\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: None\r\n",
      " - load_path: /home/ongzhiyang/bias-bench-main/results/CDA_FT/gpt2/gender/checkpoint-100\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: gender\r\n",
      " - seed: 42\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <|endoftext|>\r\n",
      "torch.Size([1, 1, 50257])\r\n",
      "100%|███████████████████████████████████████| 6392/6392 [07:24<00:00, 14.38it/s]\r\n",
      "Executing: python stereoset_debias.py --model 'CDAGPT2LMHeadModel' --model_name_or_path 'gpt2' --load_path '/home/ongzhiyang/bias-bench-main/results/CDA_FT/gpt2/gender/checkpoint-200' --bias_type 'gender' --ckpt_num 200 --batch_size 1 --seed 42\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: CDAGPT2LMHeadModel\r\n",
      " - model_name_or_path: gpt2\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: None\r\n",
      " - load_path: /home/ongzhiyang/bias-bench-main/results/CDA_FT/gpt2/gender/checkpoint-200\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: gender\r\n",
      " - seed: 42\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <|endoftext|>\r\n",
      "torch.Size([1, 1, 50257])\r\n",
      "100%|███████████████████████████████████████| 6392/6392 [07:39<00:00, 13.91it/s]\r\n",
      "Executing: python stereoset_debias.py --model 'CDAGPT2LMHeadModel' --model_name_or_path 'gpt2' --load_path '/home/ongzhiyang/bias-bench-main/results/CDA_FT/gpt2/gender/checkpoint-300' --bias_type 'gender' --ckpt_num 300 --batch_size 1 --seed 42\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: CDAGPT2LMHeadModel\r\n",
      " - model_name_or_path: gpt2\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: None\r\n",
      " - load_path: /home/ongzhiyang/bias-bench-main/results/CDA_FT/gpt2/gender/checkpoint-300\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: gender\r\n",
      " - seed: 42\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <|endoftext|>\r\n",
      "torch.Size([1, 1, 50257])\r\n",
      "100%|███████████████████████████████████████| 6392/6392 [07:34<00:00, 14.07it/s]\r\n",
      "Executing: python stereoset_debias.py --model 'CDAGPT2LMHeadModel' --model_name_or_path 'gpt2' --load_path '/home/ongzhiyang/bias-bench-main/results/CDA_FT/gpt2/gender/checkpoint-400' --bias_type 'gender' --ckpt_num 400 --batch_size 1 --seed 42\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: CDAGPT2LMHeadModel\r\n",
      " - model_name_or_path: gpt2\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: None\r\n",
      " - load_path: /home/ongzhiyang/bias-bench-main/results/CDA_FT/gpt2/gender/checkpoint-400\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: gender\r\n",
      " - seed: 42\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <|endoftext|>\r\n",
      "torch.Size([1, 1, 50257])\r\n",
      "100%|███████████████████████████████████████| 6392/6392 [07:33<00:00, 14.11it/s]\r\n",
      "Executing: python stereoset_debias.py --model 'CDAGPT2LMHeadModel' --model_name_or_path 'gpt2' --load_path '/home/ongzhiyang/bias-bench-main/results/CDA_FT/gpt2/gender/checkpoint-500' --bias_type 'gender' --ckpt_num 500 --batch_size 1 --seed 42\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: CDAGPT2LMHeadModel\r\n",
      " - model_name_or_path: gpt2\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: None\r\n",
      " - load_path: /home/ongzhiyang/bias-bench-main/results/CDA_FT/gpt2/gender/checkpoint-500\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: gender\r\n",
      " - seed: 42\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <|endoftext|>\r\n",
      "torch.Size([1, 1, 50257])\r\n",
      "100%|███████████████████████████████████████| 6392/6392 [07:34<00:00, 14.07it/s]\r\n",
      "Executing: python stereoset_debias.py --model 'CDAGPT2LMHeadModel' --model_name_or_path 'gpt2' --load_path '/home/ongzhiyang/bias-bench-main/results/CDA_FT/gpt2/gender/checkpoint-600' --bias_type 'gender' --ckpt_num 600 --batch_size 1 --seed 42\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: CDAGPT2LMHeadModel\r\n",
      " - model_name_or_path: gpt2\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: None\r\n",
      " - load_path: /home/ongzhiyang/bias-bench-main/results/CDA_FT/gpt2/gender/checkpoint-600\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: gender\r\n",
      " - seed: 42\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <|endoftext|>\r\n",
      "torch.Size([1, 1, 50257])\r\n",
      "100%|███████████████████████████████████████| 6392/6392 [07:35<00:00, 14.04it/s]\r\n",
      "Executing: python stereoset_debias.py --model 'CDAGPT2LMHeadModel' --model_name_or_path 'gpt2' --load_path '/home/ongzhiyang/bias-bench-main/results/CDA_FT/gpt2/gender/checkpoint-700' --bias_type 'gender' --ckpt_num 700 --batch_size 1 --seed 42\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: CDAGPT2LMHeadModel\r\n",
      " - model_name_or_path: gpt2\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: None\r\n",
      " - load_path: /home/ongzhiyang/bias-bench-main/results/CDA_FT/gpt2/gender/checkpoint-700\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: gender\r\n",
      " - seed: 42\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <|endoftext|>\r\n",
      "torch.Size([1, 1, 50257])\r\n",
      "100%|███████████████████████████████████████| 6392/6392 [07:25<00:00, 14.34it/s]\r\n",
      "Executing: python stereoset_debias.py --model 'CDAGPT2LMHeadModel' --model_name_or_path 'gpt2' --load_path '/home/ongzhiyang/bias-bench-main/results/CDA_FT/gpt2/gender/checkpoint-800' --bias_type 'gender' --ckpt_num 800 --batch_size 1 --seed 42\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: CDAGPT2LMHeadModel\r\n",
      " - model_name_or_path: gpt2\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: None\r\n",
      " - load_path: /home/ongzhiyang/bias-bench-main/results/CDA_FT/gpt2/gender/checkpoint-800\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: gender\r\n",
      " - seed: 42\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <|endoftext|>\r\n",
      "torch.Size([1, 1, 50257])\r\n",
      "100%|███████████████████████████████████████| 6392/6392 [07:24<00:00, 14.37it/s]\r\n",
      "Executing: python stereoset_debias.py --model 'CDAGPT2LMHeadModel' --model_name_or_path 'gpt2' --load_path '/home/ongzhiyang/bias-bench-main/results/CDA_FT/gpt2/gender/checkpoint-900' --bias_type 'gender' --ckpt_num 900 --batch_size 1 --seed 42\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: CDAGPT2LMHeadModel\r\n",
      " - model_name_or_path: gpt2\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: None\r\n",
      " - load_path: /home/ongzhiyang/bias-bench-main/results/CDA_FT/gpt2/gender/checkpoint-900\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: gender\r\n",
      " - seed: 42\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <|endoftext|>\r\n",
      "torch.Size([1, 1, 50257])\r\n",
      "100%|███████████████████████████████████████| 6392/6392 [07:13<00:00, 14.74it/s]\r\n",
      "Executing: python stereoset_debias.py --model 'CDAGPT2LMHeadModel' --model_name_or_path 'gpt2' --load_path '/home/ongzhiyang/bias-bench-main/results/CDA_FT/gpt2/gender/checkpoint-1000' --bias_type 'gender' --ckpt_num 1000 --batch_size 1 --seed 42\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: CDAGPT2LMHeadModel\r\n",
      " - model_name_or_path: gpt2\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: None\r\n",
      " - load_path: /home/ongzhiyang/bias-bench-main/results/CDA_FT/gpt2/gender/checkpoint-1000\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: gender\r\n",
      " - seed: 42\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <|endoftext|>\r\n",
      "torch.Size([1, 1, 50257])\r\n",
      "100%|███████████████████████████████████████| 6392/6392 [07:17<00:00, 14.60it/s]\r\n",
      "Executing: python stereoset_debias.py --model 'CDAGPT2LMHeadModel' --model_name_or_path 'gpt2' --load_path '/home/ongzhiyang/bias-bench-main/results/CDA_FT/gpt2/gender/checkpoint-1100' --bias_type 'gender' --ckpt_num 1100 --batch_size 1 --seed 42\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: CDAGPT2LMHeadModel\r\n",
      " - model_name_or_path: gpt2\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: None\r\n",
      " - load_path: /home/ongzhiyang/bias-bench-main/results/CDA_FT/gpt2/gender/checkpoint-1100\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: gender\r\n",
      " - seed: 42\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <|endoftext|>\r\n",
      "torch.Size([1, 1, 50257])\r\n",
      " 88%|██████████████████████████████████▏    | 5604/6392 [06:40<00:53, 14.60it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/fyp/lib/python3.10/site-packages/IPython/utils/_process_posix.py:156\u001b[0m, in \u001b[0;36mProcessHandler.system\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;66;03m# res is the index of the pattern that caused the match, so we\u001b[39;00m\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;66;03m# know whether we've finished (if we matched EOF) or not\u001b[39;00m\n\u001b[0;32m--> 156\u001b[0m     res_idx \u001b[38;5;241m=\u001b[39m \u001b[43mchild\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpect_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpatterns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28mprint\u001b[39m(child\u001b[38;5;241m.\u001b[39mbefore[out_size:]\u001b[38;5;241m.\u001b[39mdecode(enc, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreplace\u001b[39m\u001b[38;5;124m'\u001b[39m), end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/fyp/lib/python3.10/site-packages/pexpect/spawnbase.py:383\u001b[0m, in \u001b[0;36mSpawnBase.expect_list\u001b[0;34m(self, pattern_list, timeout, searchwindowsize, async_, **kw)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 383\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mexp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpect_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/fyp/lib/python3.10/site-packages/pexpect/expect.py:169\u001b[0m, in \u001b[0;36mExpecter.expect_loop\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;66;03m# Still have time left, so read more data\u001b[39;00m\n\u001b[0;32m--> 169\u001b[0m incoming \u001b[38;5;241m=\u001b[39m \u001b[43mspawn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_nonblocking\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspawn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaxread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspawn\u001b[38;5;241m.\u001b[39mdelayafterread \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/fyp/lib/python3.10/site-packages/pexpect/pty_spawn.py:500\u001b[0m, in \u001b[0;36mspawn.read_nonblocking\u001b[0;34m(self, size, timeout)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;66;03m# Because of the select(0) check above, we know that no data\u001b[39;00m\n\u001b[1;32m    498\u001b[0m \u001b[38;5;66;03m# is available right now. But if a non-zero timeout is given\u001b[39;00m\n\u001b[1;32m    499\u001b[0m \u001b[38;5;66;03m# (possibly timeout=None), we call select() with a timeout.\u001b[39;00m\n\u001b[0;32m--> 500\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (timeout \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m(spawn, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mread_nonblocking(size)\n",
      "File \u001b[0;32m~/anaconda3/envs/fyp/lib/python3.10/site-packages/pexpect/pty_spawn.py:450\u001b[0m, in \u001b[0;36mspawn.read_nonblocking.<locals>.select\u001b[0;34m(timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mselect\u001b[39m(timeout):\n\u001b[0;32m--> 450\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mselect_ignore_interrupts\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchild_fd\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/fyp/lib/python3.10/site-packages/pexpect/utils.py:143\u001b[0m, in \u001b[0;36mselect_ignore_interrupts\u001b[0;34m(iwtd, owtd, ewtd, timeout)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mselect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43miwtd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mowtd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mewtd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m command \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython stereoset_debias.py --model \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCDAGPT2LMHeadModel\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m --model_name_or_path \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpt2\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m --load_path \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/ongzhiyang/bias-bench-main/results/CDA_FT/gpt2/gender/checkpoint-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mckpt_num\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m --bias_type \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgender\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m --ckpt_num \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mckpt_num\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m --batch_size 1 --seed 42\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecuting: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcommand\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msystem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/fyp/lib/python3.10/site-packages/ipykernel/zmqshell.py:657\u001b[0m, in \u001b[0;36mZMQInteractiveShell.system_piped\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    655\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_ns[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_exit_code\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m system(cmd)\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 657\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_ns[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_exit_code\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43msystem\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvar_expand\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/fyp/lib/python3.10/site-packages/IPython/utils/_process_posix.py:180\u001b[0m, in \u001b[0;36mProcessHandler.system\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    179\u001b[0m         \u001b[38;5;66;03m# Ensure the subprocess really is terminated\u001b[39;00m\n\u001b[0;32m--> 180\u001b[0m         \u001b[43mchild\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mterminate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mforce\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;66;03m# add isalive check, to ensure exitstatus is set:\u001b[39;00m\n\u001b[1;32m    182\u001b[0m child\u001b[38;5;241m.\u001b[39misalive()\n",
      "File \u001b[0;32m~/anaconda3/envs/fyp/lib/python3.10/site-packages/pexpect/pty_spawn.py:646\u001b[0m, in \u001b[0;36mspawn.terminate\u001b[0;34m(self, force)\u001b[0m\n\u001b[1;32m    644\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    645\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkill(signal\u001b[38;5;241m.\u001b[39mSIGCONT)\n\u001b[0;32m--> 646\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdelayafterterminate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    647\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39misalive():\n\u001b[1;32m    648\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# for ckpt_num in range(100, 2001, 100):\n",
    "for ckpt_num in range(100, 2001, 100):\n",
    "    command = f\"python stereoset_debias.py --model 'CDAGPT2LMHeadModel' --model_name_or_path 'gpt2' --load_path '/home/ongzhiyang/bias-bench-main/results/CDA_FT/gpt2/gender/checkpoint-{ckpt_num}' --bias_type 'gender' --ckpt_num {ckpt_num} --batch_size 1 --seed 42\"\n",
    "    print(f\"Executing: {command}\")\n",
    "    get_ipython().system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4403bd62162a43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T14:13:08.628366Z",
     "start_time": "2024-08-03T14:13:08.628132Z"
    }
   },
   "outputs": [],
   "source": [
    "# for ckpt_num in range(100, 2001, 100):\n",
    "for ckpt_num in range(100, 2001, 100):\n",
    "    command = f\"python stereoset_debias.py --model 'CDAGPT2LMHeadModel' --model_name_or_path 'gpt2' --load_path '/home/ongzhiyang/bias-bench-main/results/CDA_FT/gpt2/race/checkpoint-{ckpt_num}' --bias_type 'race-color' --ckpt_num {ckpt_num} --batch_size 1 --seed 42\"\n",
    "    print(f\"Executing: {command}\")\n",
    "    get_ipython().system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ce64e6ea627b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ckpt_num in range(100, 2001, 100):\n",
    "for ckpt_num in range(100, 2001, 100):\n",
    "    command = f\"python stereoset_debias.py --model 'CDAGPT2LMHeadModel' --model_name_or_path 'gpt2' --load_path '/home/ongzhiyang/bias-bench-main/results/CDA_FT/gpt2/religion/checkpoint-{ckpt_num}' --bias_type 'religion' --ckpt_num {ckpt_num} --batch_size 1 --seed 42\"\n",
    "    print(f\"Executing: {command}\")\n",
    "    get_ipython().system(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbbbd6f136f59f9",
   "metadata": {},
   "source": [
    "# Phi2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7659fe6541f305ca",
   "metadata": {},
   "source": [
    "### Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7b498ef063986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 6392/6392 [30:33<00:00,  3.49it/s]\r\n",
      "Executing: python stereoset_debias.py --model 'CDAPhi2LMHeadModel' --model_name_or_path 'microsoft/phi-2' --load_path '/home/ongzhiyang/bias-bench-main/results/CDA_FT/phi2/gender/checkpoint-500' --bias_type 'gender' --ckpt_num 500 --batch_size 1 --seed 42\n",
      "/home/ongzhiyang/anaconda3/envs/fyp/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\r\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\r\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: CDAPhi2LMHeadModel\r\n",
      " - model_name_or_path: microsoft/phi-2\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: None\r\n",
      " - load_path: /home/ongzhiyang/bias-bench-main/results/CDA_FT/phi2/gender/checkpoint-500\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: gender\r\n",
      " - seed: 42\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:05<00:00,  2.83s/it]\r\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\r\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <|endoftext|>\r\n",
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\r\n",
      "torch.Size([1, 1, 50295])\r\n",
      "100%|███████████████████████████████████████| 6392/6392 [30:54<00:00,  3.45it/s]\r\n",
      "Executing: python stereoset_debias.py --model 'CDAPhi2LMHeadModel' --model_name_or_path 'microsoft/phi-2' --load_path '/home/ongzhiyang/bias-bench-main/results/CDA_FT/phi2/gender/checkpoint-600' --bias_type 'gender' --ckpt_num 600 --batch_size 1 --seed 42\n",
      "/home/ongzhiyang/anaconda3/envs/fyp/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\r\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\r\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: CDAPhi2LMHeadModel\r\n",
      " - model_name_or_path: microsoft/phi-2\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: None\r\n",
      " - load_path: /home/ongzhiyang/bias-bench-main/results/CDA_FT/phi2/gender/checkpoint-600\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: gender\r\n",
      " - seed: 42\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:05<00:00,  2.94s/it]\r\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\r\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <|endoftext|>\r\n",
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\r\n",
      "torch.Size([1, 1, 50295])\r\n",
      "100%|███████████████████████████████████████| 6392/6392 [31:07<00:00,  3.42it/s]\r\n",
      "Executing: python stereoset_debias.py --model 'CDAPhi2LMHeadModel' --model_name_or_path 'microsoft/phi-2' --load_path '/home/ongzhiyang/bias-bench-main/results/CDA_FT/phi2/gender/checkpoint-700' --bias_type 'gender' --ckpt_num 700 --batch_size 1 --seed 42\n",
      "/home/ongzhiyang/anaconda3/envs/fyp/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\r\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\r\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: CDAPhi2LMHeadModel\r\n",
      " - model_name_or_path: microsoft/phi-2\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: None\r\n",
      " - load_path: /home/ongzhiyang/bias-bench-main/results/CDA_FT/phi2/gender/checkpoint-700\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: gender\r\n",
      " - seed: 42\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:05<00:00,  2.97s/it]\r\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\r\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <|endoftext|>\r\n",
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\r\n",
      "torch.Size([1, 1, 50295])\r\n",
      "100%|███████████████████████████████████████| 6392/6392 [30:49<00:00,  3.46it/s]\r\n",
      "Executing: python stereoset_debias.py --model 'CDAPhi2LMHeadModel' --model_name_or_path 'microsoft/phi-2' --load_path '/home/ongzhiyang/bias-bench-main/results/CDA_FT/phi2/gender/checkpoint-800' --bias_type 'gender' --ckpt_num 800 --batch_size 1 --seed 42\n",
      "/home/ongzhiyang/anaconda3/envs/fyp/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\r\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\r\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: CDAPhi2LMHeadModel\r\n",
      " - model_name_or_path: microsoft/phi-2\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: None\r\n",
      " - load_path: /home/ongzhiyang/bias-bench-main/results/CDA_FT/phi2/gender/checkpoint-800\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: gender\r\n",
      " - seed: 42\r\n",
      "Executing: python stereoset_debias.py --model 'CDAPhi2LMHeadModel' --model_name_or_path 'microsoft/phi-2' --load_path '/home/ongzhiyang/bias-bench-main/results/CDA_FT/phi2/gender/checkpoint-900' --bias_type 'gender' --ckpt_num 900 --batch_size 1 --seed 42\n",
      "Executing: python stereoset_debias.py --model 'CDAPhi2LMHeadModel' --model_name_or_path 'microsoft/phi-2' --load_path '/home/ongzhiyang/bias-bench-main/results/CDA_FT/phi2/gender/checkpoint-1000' --bias_type 'gender' --ckpt_num 1000 --batch_size 1 --seed 42\n",
      "Executing: python stereoset_debias.py --model 'CDAPhi2LMHeadModel' --model_name_or_path 'microsoft/phi-2' --load_path '/home/ongzhiyang/bias-bench-main/results/CDA_FT/phi2/gender/checkpoint-1100' --bias_type 'gender' --ckpt_num 1100 --batch_size 1 --seed 42\n",
      "Executing: python stereoset_debias.py --model 'CDAPhi2LMHeadModel' --model_name_or_path 'microsoft/phi-2' --load_path '/home/ongzhiyang/bias-bench-main/results/CDA_FT/phi2/gender/checkpoint-1200' --bias_type 'gender' --ckpt_num 1200 --batch_size 1 --seed 42\n",
      "Executing: python stereoset_debias.py --model 'CDAPhi2LMHeadModel' --model_name_or_path 'microsoft/phi-2' --load_path '/home/ongzhiyang/bias-bench-main/results/CDA_FT/phi2/gender/checkpoint-1300' --bias_type 'gender' --ckpt_num 1300 --batch_size 1 --seed 42\n",
      "^C\r\n",
      "Executing: python stereoset_debias.py --model 'CDAPhi2LMHeadModel' --model_name_or_path 'microsoft/phi-2' --load_path '/home/ongzhiyang/bias-bench-main/results/CDA_FT/phi2/gender/checkpoint-1400' --bias_type 'gender' --ckpt_num 1400 --batch_size 1 --seed 42\n",
      "Executing: python stereoset_debias.py --model 'CDAPhi2LMHeadModel' --model_name_or_path 'microsoft/phi-2' --load_path '/home/ongzhiyang/bias-bench-main/results/CDA_FT/phi2/gender/checkpoint-1500' --bias_type 'gender' --ckpt_num 1500 --batch_size 1 --seed 42\n",
      "Executing: python stereoset_debias.py --model 'CDAPhi2LMHeadModel' --model_name_or_path 'microsoft/phi-2' --load_path '/home/ongzhiyang/bias-bench-main/results/CDA_FT/phi2/gender/checkpoint-1600' --bias_type 'gender' --ckpt_num 1600 --batch_size 1 --seed 42\n",
      "Executing: python stereoset_debias.py --model 'CDAPhi2LMHeadModel' --model_name_or_path 'microsoft/phi-2' --load_path '/home/ongzhiyang/bias-bench-main/results/CDA_FT/phi2/gender/checkpoint-1700' --bias_type 'gender' --ckpt_num 1700 --batch_size 1 --seed 42\n",
      "Executing: python stereoset_debias.py --model 'CDAPhi2LMHeadModel' --model_name_or_path 'microsoft/phi-2' --load_path '/home/ongzhiyang/bias-bench-main/results/CDA_FT/phi2/gender/checkpoint-1800' --bias_type 'gender' --ckpt_num 1800 --batch_size 1 --seed 42\n",
      "Executing: python stereoset_debias.py --model 'CDAPhi2LMHeadModel' --model_name_or_path 'microsoft/phi-2' --load_path '/home/ongzhiyang/bias-bench-main/results/CDA_FT/phi2/gender/checkpoint-1900' --bias_type 'gender' --ckpt_num 1900 --batch_size 1 --seed 42\n",
      "Executing: python stereoset_debias.py --model 'CDAPhi2LMHeadModel' --model_name_or_path 'microsoft/phi-2' --load_path '/home/ongzhiyang/bias-bench-main/results/CDA_FT/phi2/gender/checkpoint-2000' --bias_type 'gender' --ckpt_num 2000 --batch_size 1 --seed 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for ckpt_num in range(100, 2001, 100):\n",
    "for ckpt_num in range(100, 2001, 100):\n",
    "    command = f\"python stereoset_debias.py --model 'CDAPhi2LMHeadModel' --model_name_or_path 'microsoft/phi-2' --load_path '/home/ongzhiyang/bias-bench-main/results/CDA_FT/phi2/gender/checkpoint-{ckpt_num}' --bias_type 'gender' --ckpt_num {ckpt_num} --batch_size 1 --seed 42\"\n",
    "    print(f\"Executing: {command}\")\n",
    "    get_ipython().system(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71594266520f9f8",
   "metadata": {},
   "source": [
    "### Race-color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cde73ebb116f414a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 6392/6392 [27:17<00:00,  3.90it/s]\r\n",
      "Executing: python stereoset_debias.py --model 'CDAPhi2LMHeadModel' --model_name_or_path 'microsoft/phi-2' --load_path '/home/ongzhiyang/bias-bench-main/results/CDA_FT/phi2/race/checkpoint-1900' --bias_type 'race-color' --ckpt_num 1900 --batch_size 1 --seed 42\n",
      "/home/ongzhiyang/anaconda3/envs/fyp/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\r\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\r\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: CDAPhi2LMHeadModel\r\n",
      " - model_name_or_path: microsoft/phi-2\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: None\r\n",
      " - load_path: /home/ongzhiyang/bias-bench-main/results/CDA_FT/phi2/race/checkpoint-1900\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: race-color\r\n",
      " - seed: 42\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:05<00:00,  2.74s/it]\r\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\r\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <|endoftext|>\r\n",
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\r\n",
      "torch.Size([1, 1, 50295])\r\n",
      "100%|███████████████████████████████████████| 6392/6392 [29:37<00:00,  3.60it/s]\r\n",
      "Executing: python stereoset_debias.py --model 'CDAPhi2LMHeadModel' --model_name_or_path 'microsoft/phi-2' --load_path '/home/ongzhiyang/bias-bench-main/results/CDA_FT/phi2/race/checkpoint-2000' --bias_type 'race-color' --ckpt_num 2000 --batch_size 1 --seed 42\n",
      "/home/ongzhiyang/anaconda3/envs/fyp/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\r\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\r\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: CDAPhi2LMHeadModel\r\n",
      " - model_name_or_path: microsoft/phi-2\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: None\r\n",
      " - load_path: /home/ongzhiyang/bias-bench-main/results/CDA_FT/phi2/race/checkpoint-2000\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: race-color\r\n",
      " - seed: 42\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:05<00:00,  2.81s/it]\r\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\r\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <|endoftext|>\r\n",
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\r\n",
      "torch.Size([1, 1, 50295])\r\n",
      "100%|███████████████████████████████████████| 6392/6392 [29:40<00:00,  3.59it/s]\r\n"
     ]
    }
   ],
   "source": [
    "# for ckpt_num in range(100, 2001, 100):\n",
    "for ckpt_num in range(100, 2001, 100):\n",
    "    command = f\"python stereoset_debias.py --model 'CDAPhi2LMHeadModel' --model_name_or_path 'microsoft/phi-2' --load_path '/home/ongzhiyang/bias-bench-main/results/CDA_FT/phi2/race/checkpoint-{ckpt_num}' --bias_type 'race-color' --ckpt_num {ckpt_num} --batch_size 1 --seed 42\"\n",
    "    print(f\"Executing: {command}\")\n",
    "    get_ipython().system(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04496d18fdda285",
   "metadata": {},
   "source": [
    "### Religion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d770a25b95e0265",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T02:02:28.556700Z",
     "start_time": "2024-07-05T01:34:46.735083Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing: python stereoset_debias.py --model 'CDAPhi2LMHeadModel' --model_name_or_path 'microsoft/phi-2' --load_path '/home/ongzhiyang/bias-bench-main/results/CDA_FT/phi2/religion/checkpoint-1200' --bias_type 'religion' --ckpt_num 1200 --batch_size 1 --seed 42\n",
      "/home/ongzhiyang/anaconda3/envs/fyp/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\r\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\r\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: CDAPhi2LMHeadModel\r\n",
      " - model_name_or_path: microsoft/phi-2\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: None\r\n",
      " - load_path: /home/ongzhiyang/bias-bench-main/results/CDA_FT/phi2/religion/checkpoint-1200\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: religion\r\n",
      " - seed: 42\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:04<00:00,  2.37s/it]\r\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\r\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <|endoftext|>\r\n",
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\r\n",
      "torch.Size([1, 1, 50295])\r\n",
      "100%|███████████████████████████████████████| 6392/6392 [27:23<00:00,  3.89it/s]\r\n"
     ]
    }
   ],
   "source": [
    "# for ckpt_num in range(100, 2001, 100):\n",
    "for ckpt_num in range(1200, 1201, 100):\n",
    "    command = f\"python stereoset_debias.py --model 'CDAPhi2LMHeadModel' --model_name_or_path 'microsoft/phi-2' --load_path '/home/ongzhiyang/bias-bench-main/results/CDA_FT/phi2/religion/checkpoint-{ckpt_num}' --bias_type 'religion' --ckpt_num {ckpt_num} --batch_size 1 --seed 42\"\n",
    "    print(f\"Executing: {command}\")\n",
    "    get_ipython().system(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb033a3c383da67",
   "metadata": {},
   "source": [
    "# llama 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f453777c2a34d4c",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-28T15:43:30.247081Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing: python stereoset_debias.py --model 'CDALlama2LMHeadModel' --model_name_or_path 'meta-llama/Llama-2-7b-hf' --load_path '/home/FYP/on0008an/bias-bench-main/results/CDA_FT/llama2/gender/checkpoint-300' --bias_type 'gender' --ckpt_num 300 --batch_size 1 --seed 42\n",
      "/home/FYP/on0008an/.conda/envs/RunJupyter/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\r\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\r\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/FYP/on0008an/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/FYP/on0008an/bias-bench-main\r\n",
      " - model: CDALlama2LMHeadModel\r\n",
      " - model_name_or_path: meta-llama/Llama-2-7b-hf\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: None\r\n",
      " - load_path: /home/FYP/on0008an/bias-bench-main/results/CDA_FT/llama2/gender/checkpoint-300\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: gender\r\n",
      " - seed: 42\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:33<00:00, 16.94s/it]\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <s>\r\n",
      "torch.Size([1, 1, 32000])\r\n",
      "100%|█████████████████████████████████████| 6392/6392 [2:03:49<00:00,  1.16s/it]\r\n",
      "Executing: python stereoset_debias.py --model 'CDALlama2LMHeadModel' --model_name_or_path 'meta-llama/Llama-2-7b-hf' --load_path '/home/FYP/on0008an/bias-bench-main/results/CDA_FT/llama2/gender/checkpoint-400' --bias_type 'gender' --ckpt_num 400 --batch_size 1 --seed 42\n",
      "/home/FYP/on0008an/.conda/envs/RunJupyter/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\r\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\r\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/FYP/on0008an/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/FYP/on0008an/bias-bench-main\r\n",
      " - model: CDALlama2LMHeadModel\r\n",
      " - model_name_or_path: meta-llama/Llama-2-7b-hf\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: None\r\n",
      " - load_path: /home/FYP/on0008an/bias-bench-main/results/CDA_FT/llama2/gender/checkpoint-400\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: gender\r\n",
      " - seed: 42\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:33<00:00, 16.97s/it]\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <s>\r\n",
      "torch.Size([1, 1, 32000])\r\n",
      " 86%|███████████████████████████████▊     | 5504/6392 [1:46:34<16:36,  1.12s/it]"
     ]
    }
   ],
   "source": [
    "# for ckpt_num in range(100, 2001, 100):\n",
    "for ckpt_num in range(400, 2001, 100):\n",
    "    command = f\"python stereoset_debias.py --model 'CDALlama2LMHeadModel' --model_name_or_path 'meta-llama/Llama-2-7b-hf' --load_path '/home/ongzhiyang/bias-bench-main/results/CDA_FT/llama2/gender/checkpoint-{ckpt_num}' --bias_type 'gender' --ckpt_num {ckpt_num} --batch_size 1 --seed 42\"\n",
    "    print(f\"Executing: {command}\")\n",
    "    get_ipython().system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e18e976d7471892",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T16:01:57.885883Z",
     "start_time": "2024-08-06T13:46:41.928829Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing: python stereoset_debias.py --model 'CDALlama2LMHeadModel' --model_name_or_path 'meta-llama/Llama-2-7b-hf' --load_path '/home/ongzhiyang/bias-bench-main/results/CDA_FT/llama2/race/checkpoint-100' --bias_type 'race-color' --ckpt_num 100 --batch_size 1 --seed 42\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: CDALlama2LMHeadModel\r\n",
      " - model_name_or_path: meta-llama/Llama-2-7b-hf\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: None\r\n",
      " - load_path: /home/ongzhiyang/bias-bench-main/results/CDA_FT/llama2/race/checkpoint-100\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: race-color\r\n",
      " - seed: 42\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:20<00:00, 10.01s/it]\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <s>\r\n",
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\r\n",
      "torch.Size([1, 1, 32000])\r\n",
      "100%|███████████████████████████████████████| 6392/6392 [44:25<00:00,  2.40it/s]\r\n",
      "Executing: python stereoset_debias.py --model 'CDALlama2LMHeadModel' --model_name_or_path 'meta-llama/Llama-2-7b-hf' --load_path '/home/ongzhiyang/bias-bench-main/results/CDA_FT/llama2/race/checkpoint-200' --bias_type 'race-color' --ckpt_num 200 --batch_size 1 --seed 42\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: CDALlama2LMHeadModel\r\n",
      " - model_name_or_path: meta-llama/Llama-2-7b-hf\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: None\r\n",
      " - load_path: /home/ongzhiyang/bias-bench-main/results/CDA_FT/llama2/race/checkpoint-200\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: race-color\r\n",
      " - seed: 42\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:13<00:00,  6.94s/it]\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <s>\r\n",
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\r\n",
      "torch.Size([1, 1, 32000])\r\n",
      "100%|███████████████████████████████████████| 6392/6392 [44:33<00:00,  2.39it/s]\r\n",
      "Executing: python stereoset_debias.py --model 'CDALlama2LMHeadModel' --model_name_or_path 'meta-llama/Llama-2-7b-hf' --load_path '/home/ongzhiyang/bias-bench-main/results/CDA_FT/llama2/race/checkpoint-300' --bias_type 'race-color' --ckpt_num 300 --batch_size 1 --seed 42\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: CDALlama2LMHeadModel\r\n",
      " - model_name_or_path: meta-llama/Llama-2-7b-hf\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: None\r\n",
      " - load_path: /home/ongzhiyang/bias-bench-main/results/CDA_FT/llama2/race/checkpoint-300\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: race-color\r\n",
      " - seed: 42\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:14<00:00,  7.08s/it]\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <s>\r\n",
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\r\n",
      "torch.Size([1, 1, 32000])\r\n",
      "100%|███████████████████████████████████████| 6392/6392 [44:38<00:00,  2.39it/s]\r\n"
     ]
    }
   ],
   "source": [
    "# for ckpt_num in range(100, 2001, 100):\n",
    "for ckpt_num in range(100, 301, 100):\n",
    "    command = f\"python stereoset_debias.py --model 'CDALlama2LMHeadModel' --model_name_or_path 'meta-llama/Llama-2-7b-hf' --load_path '/home/ongzhiyang/bias-bench-main/results/CDA_FT/llama2/race/checkpoint-{ckpt_num}' --bias_type 'race-color' --ckpt_num {ckpt_num} --batch_size 1 --seed 42\"\n",
    "    print(f\"Executing: {command}\")\n",
    "    get_ipython().system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7aa10b25517283a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-07T11:55:35.586937Z",
     "start_time": "2024-07-07T09:06:33.904413Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing: python stereoset_debias.py --model 'CDALlama2LMHeadModel' --model_name_or_path 'meta-llama/Llama-2-7b-hf' --load_path '/home/ongzhiyang/bias-bench-main/results/CDA_FT/llama2/religion/checkpoint-100' --bias_type 'religion' --ckpt_num 100 --batch_size 1 --seed 42\n",
      "/home/ongzhiyang/anaconda3/envs/fyp/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\r\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\r\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: CDALlama2LMHeadModel\r\n",
      " - model_name_or_path: meta-llama/Llama-2-7b-hf\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: None\r\n",
      " - load_path: /home/ongzhiyang/bias-bench-main/results/CDA_FT/llama2/religion/checkpoint-100\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: religion\r\n",
      " - seed: 42\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.87s/it]\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <s>\r\n",
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\r\n",
      "torch.Size([1, 1, 32000])\r\n",
      "100%|███████████████████████████████████████| 6392/6392 [33:21<00:00,  3.19it/s]\r\n",
      "Executing: python stereoset_debias.py --model 'CDALlama2LMHeadModel' --model_name_or_path 'meta-llama/Llama-2-7b-hf' --load_path '/home/ongzhiyang/bias-bench-main/results/CDA_FT/llama2/religion/checkpoint-200' --bias_type 'religion' --ckpt_num 200 --batch_size 1 --seed 42\n",
      "/home/ongzhiyang/anaconda3/envs/fyp/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\r\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\r\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: CDALlama2LMHeadModel\r\n",
      " - model_name_or_path: meta-llama/Llama-2-7b-hf\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: None\r\n",
      " - load_path: /home/ongzhiyang/bias-bench-main/results/CDA_FT/llama2/religion/checkpoint-200\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: religion\r\n",
      " - seed: 42\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:10<00:00,  5.37s/it]\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <s>\r\n",
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\r\n",
      "torch.Size([1, 1, 32000])\r\n",
      "100%|███████████████████████████████████████| 6392/6392 [33:08<00:00,  3.21it/s]\r\n",
      "Executing: python stereoset_debias.py --model 'CDALlama2LMHeadModel' --model_name_or_path 'meta-llama/Llama-2-7b-hf' --load_path '/home/ongzhiyang/bias-bench-main/results/CDA_FT/llama2/religion/checkpoint-300' --bias_type 'religion' --ckpt_num 300 --batch_size 1 --seed 42\n",
      "/home/ongzhiyang/anaconda3/envs/fyp/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\r\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\r\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: CDALlama2LMHeadModel\r\n",
      " - model_name_or_path: meta-llama/Llama-2-7b-hf\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: None\r\n",
      " - load_path: /home/ongzhiyang/bias-bench-main/results/CDA_FT/llama2/religion/checkpoint-300\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: religion\r\n",
      " - seed: 42\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:10<00:00,  5.05s/it]\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <s>\r\n",
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\r\n",
      "torch.Size([1, 1, 32000])\r\n",
      "100%|███████████████████████████████████████| 6392/6392 [33:01<00:00,  3.23it/s]\r\n",
      "Executing: python stereoset_debias.py --model 'CDALlama2LMHeadModel' --model_name_or_path 'meta-llama/Llama-2-7b-hf' --load_path '/home/ongzhiyang/bias-bench-main/results/CDA_FT/llama2/religion/checkpoint-400' --bias_type 'religion' --ckpt_num 400 --batch_size 1 --seed 42\n",
      "/home/ongzhiyang/anaconda3/envs/fyp/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\r\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\r\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: CDALlama2LMHeadModel\r\n",
      " - model_name_or_path: meta-llama/Llama-2-7b-hf\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: None\r\n",
      " - load_path: /home/ongzhiyang/bias-bench-main/results/CDA_FT/llama2/religion/checkpoint-400\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: religion\r\n",
      " - seed: 42\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:10<00:00,  5.17s/it]\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <s>\r\n",
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\r\n",
      "torch.Size([1, 1, 32000])\r\n",
      "100%|███████████████████████████████████████| 6392/6392 [33:51<00:00,  3.15it/s]\r\n",
      "Executing: python stereoset_debias.py --model 'CDALlama2LMHeadModel' --model_name_or_path 'meta-llama/Llama-2-7b-hf' --load_path '/home/ongzhiyang/bias-bench-main/results/CDA_FT/llama2/religion/checkpoint-500' --bias_type 'religion' --ckpt_num 500 --batch_size 1 --seed 42\n",
      "/home/ongzhiyang/anaconda3/envs/fyp/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\r\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\r\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: CDALlama2LMHeadModel\r\n",
      " - model_name_or_path: meta-llama/Llama-2-7b-hf\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: None\r\n",
      " - load_path: /home/ongzhiyang/bias-bench-main/results/CDA_FT/llama2/religion/checkpoint-500\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: religion\r\n",
      " - seed: 42\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:10<00:00,  5.06s/it]\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <s>\r\n",
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\r\n",
      "torch.Size([1, 1, 32000])\r\n",
      "100%|███████████████████████████████████████| 6392/6392 [33:35<00:00,  3.17it/s]\r\n"
     ]
    }
   ],
   "source": [
    "# for ckpt_num in range(100, 2001, 100):\n",
    "for ckpt_num in range(100, 501, 100):\n",
    "    command = f\"python stereoset_debias.py --model 'CDALlama2LMHeadModel' --model_name_or_path 'meta-llama/Llama-2-7b-hf' --load_path '/home/ongzhiyang/bias-bench-main/results/CDA_FT/llama2/religion/checkpoint-{ckpt_num}' --bias_type 'religion' --ckpt_num {ckpt_num} --batch_size 1 --seed 42\"\n",
    "    print(f\"Executing: {command}\")\n",
    "    get_ipython().system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a55610b1b0e36a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fyp] *",
   "language": "python",
   "name": "conda-env-fyp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
