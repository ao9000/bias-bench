{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T05:33:29.334198Z",
     "start_time": "2024-06-11T05:30:34.129640Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/FYP/on0008an/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/FYP/on0008an/bias-bench-main\r\n",
      " - model: CDAGPT2LMHeadModel\r\n",
      " - model_name_or_path: gpt2\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: None\r\n",
      " - load_path: /home/FYP/on0008an/bias-bench-main/results/CDA_checkpoints_seed0_gpt2/checkpoint-500\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: gender\r\n",
      " - seed: 1\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <|endoftext|>\r\n",
      "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\r\n",
      "You may ignore this warning if your `pad_token_id` (50256) is identical to the `bos_token_id` (50256), `eos_token_id` (50256), or the `sep_token_id` (None), and your input is not padded.\r\n",
      "torch.Size([1, 1, 50257])\r\n",
      "100%|███████████████████████████████████████| 6392/6392 [02:43<00:00, 38.98it/s]\r\n"
     ]
    }
   ],
   "source": [
    "!python stereoset_debias.py --model \"CDAGPT2LMHeadModel\" --model_name_or_path \"gpt2\" --load_path \"/home/FYP/on0008an/bias-bench-main/results/CDA_checkpoints_seed0_gpt2/checkpoint-500\" --bias_type \"gender\" --batch_size 1 --seed 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a10cfc7234ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python stereoset_debias.py --model \"CDAGPT2LMHeadModel\" --model_name_or_path \"gpt2\" --load_path \"/home/FYP/on0008an/bias-bench-main/results/CDA_checkpoints_seed0_gpt2/checkpoint-500\" --bias_type \"gender\" --batch_size 1 --seed 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1db89ac3bf8ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python stereoset_debias.py --model \"CDAGPT2LMHeadModel\" --model_name_or_path \"gpt2\" --load_path \"/home/FYP/on0008an/bias-bench-main/results/CDA_checkpoints_seed0_gpt2/checkpoint-500\" --bias_type \"gender\" --batch_size 1 --seed 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde73ebb116f414a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "afb033a3c383da67",
   "metadata": {},
   "source": [
    "# llama 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f453777c2a34d4c",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-28T15:43:30.247081Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing: python stereoset_debias.py --model 'CDALlama2LMHeadModel' --model_name_or_path 'meta-llama/Llama-2-7b-hf' --load_path '/home/FYP/on0008an/bias-bench-main/results/CDA_FT/llama2/gender/checkpoint-300' --bias_type 'gender' --ckpt_num 300 --batch_size 1 --seed 42\n",
      "/home/FYP/on0008an/.conda/envs/RunJupyter/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\r\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\r\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/FYP/on0008an/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/FYP/on0008an/bias-bench-main\r\n",
      " - model: CDALlama2LMHeadModel\r\n",
      " - model_name_or_path: meta-llama/Llama-2-7b-hf\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: None\r\n",
      " - load_path: /home/FYP/on0008an/bias-bench-main/results/CDA_FT/llama2/gender/checkpoint-300\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: gender\r\n",
      " - seed: 42\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:33<00:00, 16.94s/it]\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <s>\r\n",
      "torch.Size([1, 1, 32000])\r\n",
      "100%|█████████████████████████████████████| 6392/6392 [2:03:49<00:00,  1.16s/it]\r\n",
      "Executing: python stereoset_debias.py --model 'CDALlama2LMHeadModel' --model_name_or_path 'meta-llama/Llama-2-7b-hf' --load_path '/home/FYP/on0008an/bias-bench-main/results/CDA_FT/llama2/gender/checkpoint-400' --bias_type 'gender' --ckpt_num 400 --batch_size 1 --seed 42\n",
      "/home/FYP/on0008an/.conda/envs/RunJupyter/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\r\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\r\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/FYP/on0008an/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/FYP/on0008an/bias-bench-main\r\n",
      " - model: CDALlama2LMHeadModel\r\n",
      " - model_name_or_path: meta-llama/Llama-2-7b-hf\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: None\r\n",
      " - load_path: /home/FYP/on0008an/bias-bench-main/results/CDA_FT/llama2/gender/checkpoint-400\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: gender\r\n",
      " - seed: 42\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:33<00:00, 16.97s/it]\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <s>\r\n",
      "torch.Size([1, 1, 32000])\r\n",
      " 86%|███████████████████████████████▊     | 5504/6392 [1:46:34<16:36,  1.12s/it]"
     ]
    }
   ],
   "source": [
    "# for ckpt_num in range(100, 2001, 100):\n",
    "for ckpt_num in range(400, 2001, 100):\n",
    "    command = f\"python stereoset_debias.py --model 'CDALlama2LMHeadModel' --model_name_or_path 'meta-llama/Llama-2-7b-hf' --load_path '/home/FYP/on0008an/bias-bench-main/results/CDA_FT/llama2/gender/checkpoint-{ckpt_num}' --bias_type 'gender' --ckpt_num {ckpt_num} --batch_size 1 --seed 42\"\n",
    "    print(f\"Executing: {command}\")\n",
    "    get_ipython().system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553f06b2e609d27a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
