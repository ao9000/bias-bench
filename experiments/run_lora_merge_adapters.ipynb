{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9505407f34e84781",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T14:21:50.505594Z",
     "start_time": "2024-07-22T14:21:49.872386Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jul 22 22:21:49 2024       \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 535.183.01             Driver Version: 535.183.01   CUDA Version: 12.2     |\r\n",
      "|-----------------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                      |               MIG M. |\r\n",
      "|=========================================+======================+======================|\r\n",
      "|   0  NVIDIA RTX A6000               Off | 00000000:01:00.0 Off |                  Off |\r\n",
      "| 48%   74C    P2             263W / 300W |  17024MiB / 49140MiB |     76%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "|   1  NVIDIA RTX A6000               Off | 00000000:21:00.0 Off |                  Off |\r\n",
      "| 30%   31C    P8              20W / 300W |      3MiB / 49140MiB |      0%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "|   2  NVIDIA RTX A6000               Off | 00000000:41:00.0 Off |                  Off |\r\n",
      "| 41%   69C    P2             245W / 300W |  15310MiB / 49140MiB |     73%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "|   3  NVIDIA RTX A6000               Off | 00000000:42:00.0 Off |                  Off |\r\n",
      "| 35%   63C    P2             173W / 300W |  14652MiB / 49140MiB |     65%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                            |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\r\n",
      "|        ID   ID                                                             Usage      |\r\n",
      "|=======================================================================================|\r\n",
      "|    0   N/A  N/A    727088      C   ...e/vda/anaconda3/envs/mwp/bin/python      360MiB |\r\n",
      "|    0   N/A  N/A    729965      C   ...e/vda/anaconda3/envs/mwp/bin/python      360MiB |\r\n",
      "|    0   N/A  N/A    736690      C   /home/vda/.venv/bin/python                16292MiB |\r\n",
      "|    2   N/A  N/A    727088      C   ...e/vda/anaconda3/envs/mwp/bin/python    15304MiB |\r\n",
      "|    3   N/A  N/A    729965      C   ...e/vda/anaconda3/envs/mwp/bin/python    14646MiB |\r\n",
      "+---------------------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2aa2af63fe81b557",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T14:21:55.969328Z",
     "start_time": "2024-07-22T14:21:55.962339Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1420a145d4de5e",
   "metadata": {},
   "source": [
    "# CDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a540fa78a30147",
   "metadata": {},
   "source": [
    "# GPT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T14:22:07.318810Z",
     "start_time": "2024-07-22T14:21:56.558884Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ongzhiyang/anaconda3/envs/fyp/lib/python3.10/site-packages/peft/tuners/lora/layer.py:1119: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\r\n",
      "  warnings.warn(\r\n",
      "Unloading and merging model: 100%|██████████| 212/212 [00:00<00:00, 1423.44it/s]\r\n",
      "Saved final merged checkpoint to: /home/ongzhiyang/bias-bench-main/results/CDA_FT/gpt2/gender/merged_adapters\r\n"
     ]
    }
   ],
   "source": [
    "!python lora_merge_adapters.py --adapter_model_path \"/home/ongzhiyang/bias-bench-main/results/CDA_FT/gpt2/gender\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "952336e484deb993",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T14:23:22.456294Z",
     "start_time": "2024-07-22T14:23:13.219901Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ongzhiyang/anaconda3/envs/fyp/lib/python3.10/site-packages/peft/tuners/lora/layer.py:1119: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\r\n",
      "  warnings.warn(\r\n",
      "Unloading and merging model: 100%|██████████| 212/212 [00:00<00:00, 1471.00it/s]\r\n",
      "Saved final merged checkpoint to: /home/ongzhiyang/bias-bench-main/results/CDA_FT/gpt2/religion/merged_adapters\r\n"
     ]
    }
   ],
   "source": [
    "!python lora_merge_adapters.py --adapter_model_path \"/home/ongzhiyang/bias-bench-main/results/CDA_FT/gpt2/religion\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b0f9448c226691d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T14:23:37.121853Z",
     "start_time": "2024-07-22T14:23:27.646986Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ongzhiyang/anaconda3/envs/fyp/lib/python3.10/site-packages/peft/tuners/lora/layer.py:1119: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\r\n",
      "  warnings.warn(\r\n",
      "Unloading and merging model: 100%|██████████| 212/212 [00:00<00:00, 1497.89it/s]\r\n",
      "Saved final merged checkpoint to: /home/ongzhiyang/bias-bench-main/results/CDA_FT/gpt2/race/merged_adapters\r\n"
     ]
    }
   ],
   "source": [
    "!python lora_merge_adapters.py --adapter_model_path \"/home/ongzhiyang/bias-bench-main/results/CDA_FT/gpt2/race\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b18a4dbe87f31c1",
   "metadata": {},
   "source": [
    "# Phi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44cb08ef4b29252e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T14:25:08.671025Z",
     "start_time": "2024-07-22T14:24:36.957846Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:04<00:00,  2.40s/it]\r\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\r\n",
      "Unloading and merging model: 100%|██████████| 615/615 [00:00<00:00, 3397.92it/s]\r\n",
      "Saved final merged checkpoint to: /home/ongzhiyang/bias-bench-main/results/CDA_FT/phi2/gender/merged_adapters\r\n"
     ]
    }
   ],
   "source": [
    "!python lora_merge_adapters.py --adapter_model_path \"/home/ongzhiyang/bias-bench-main/results/CDA_FT/phi2/gender\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44550cc223e388aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T14:25:43.812783Z",
     "start_time": "2024-07-22T14:25:19.108150Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:02<00:00,  1.13s/it]\r\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\r\n",
      "Unloading and merging model: 100%|██████████| 615/615 [00:00<00:00, 3275.65it/s]\r\n",
      "Saved final merged checkpoint to: /home/ongzhiyang/bias-bench-main/results/CDA_FT/phi2/religion/merged_adapters\r\n"
     ]
    }
   ],
   "source": [
    "!python lora_merge_adapters.py --adapter_model_path \"/home/ongzhiyang/bias-bench-main/results/CDA_FT/phi2/religion\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4a21731fd11fde3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T14:26:13.170452Z",
     "start_time": "2024-07-22T14:25:43.814211Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:04<00:00,  2.39s/it]\r\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\r\n",
      "Unloading and merging model: 100%|██████████| 615/615 [00:00<00:00, 3232.24it/s]\r\n",
      "Saved final merged checkpoint to: /home/ongzhiyang/bias-bench-main/results/CDA_FT/phi2/race/merged_adapters\r\n"
     ]
    }
   ],
   "source": [
    "!python lora_merge_adapters.py --adapter_model_path \"/home/ongzhiyang/bias-bench-main/results/CDA_FT/phi2/race\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72b0e8823a37c4",
   "metadata": {},
   "source": [
    "# Llama2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "edc6209b117f5593",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T14:27:23.573067Z",
     "start_time": "2024-07-22T14:26:33.222634Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:10<00:00,  5.11s/it]\r\n",
      "Unloading and merging model: 100%|██████████| 678/678 [00:00<00:00, 2909.95it/s]\r\n",
      "Saved final merged checkpoint to: /home/ongzhiyang/bias-bench-main/results/CDA_FT/llama2/gender/merged_adapters\r\n"
     ]
    }
   ],
   "source": [
    "!python lora_merge_adapters.py --adapter_model_path \"/home/ongzhiyang/bias-bench-main/results/CDA_FT/llama2/gender\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77db12ce38f354f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T14:28:14.366862Z",
     "start_time": "2024-07-22T14:27:23.574509Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:10<00:00,  5.04s/it]\r\n",
      "Unloading and merging model: 100%|██████████| 678/678 [00:00<00:00, 2950.09it/s]\r\n",
      "Saved final merged checkpoint to: /home/ongzhiyang/bias-bench-main/results/CDA_FT/llama2/religion/merged_adapters\r\n"
     ]
    }
   ],
   "source": [
    "!python lora_merge_adapters.py --adapter_model_path \"/home/ongzhiyang/bias-bench-main/results/CDA_FT/llama2/religion\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce25e57345ec2c51",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T14:29:06.072164Z",
     "start_time": "2024-07-22T14:28:14.367935Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:10<00:00,  5.14s/it]\r\n",
      "Unloading and merging model: 100%|██████████| 678/678 [00:00<00:00, 2952.41it/s]\r\n",
      "Saved final merged checkpoint to: /home/ongzhiyang/bias-bench-main/results/CDA_FT/llama2/race/merged_adapters\r\n"
     ]
    }
   ],
   "source": [
    "!python lora_merge_adapters.py --adapter_model_path \"/home/ongzhiyang/bias-bench-main/results/CDA_FT/llama2/race\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8180061abe7964",
   "metadata": {},
   "source": [
    "# Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a5cfcdccd73355a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T14:41:00.541720Z",
     "start_time": "2024-07-22T14:40:49.976528Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ongzhiyang/anaconda3/envs/fyp/lib/python3.10/site-packages/peft/tuners/lora/layer.py:1119: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\r\n",
      "  warnings.warn(\r\n",
      "Unloading and merging model: 100%|██████████| 212/212 [00:00<00:00, 1555.72it/s]\r\n",
      "Saved final merged checkpoint to: /home/ongzhiyang/bias-bench-main/results/dropout_FT/gpt2/merged_adapters\r\n"
     ]
    }
   ],
   "source": [
    "!python lora_merge_adapters.py --adapter_model_path \"/home/ongzhiyang/bias-bench-main/results/dropout_FT/gpt2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a4a4f1a3933fef4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T14:41:31.661923Z",
     "start_time": "2024-07-22T14:41:00.543103Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:04<00:00,  2.33s/it]\r\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\r\n",
      "Unloading and merging model: 100%|██████████| 615/615 [00:00<00:00, 2903.95it/s]\r\n",
      "Saved final merged checkpoint to: /home/ongzhiyang/bias-bench-main/results/dropout_FT/phi2/merged_adapters\r\n"
     ]
    }
   ],
   "source": [
    "!python lora_merge_adapters.py --adapter_model_path \"/home/ongzhiyang/bias-bench-main/results/dropout_FT/phi2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0c37a79612da2f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T14:42:22.865131Z",
     "start_time": "2024-07-22T14:41:31.663011Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:10<00:00,  5.10s/it]\r\n",
      "Unloading and merging model: 100%|██████████| 678/678 [00:00<00:00, 2900.72it/s]\r\n",
      "Saved final merged checkpoint to: /home/ongzhiyang/bias-bench-main/results/dropout_FT/llama2/merged_adapters\r\n"
     ]
    }
   ],
   "source": [
    "!python lora_merge_adapters.py --adapter_model_path \"/home/ongzhiyang/bias-bench-main/results/dropout_FT/llama2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6179e18411a59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fyp] *",
   "language": "python",
   "name": "conda-env-fyp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
