{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T12:53:29.989365Z",
     "start_time": "2024-08-03T12:53:29.338497Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Aug  3 20:53:29 2024       \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 535.183.01             Driver Version: 535.183.01   CUDA Version: 12.2     |\r\n",
      "|-----------------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                      |               MIG M. |\r\n",
      "|=========================================+======================+======================|\r\n",
      "|   0  NVIDIA RTX A6000               Off | 00000000:01:00.0 Off |                  Off |\r\n",
      "| 30%   36C    P8              25W / 300W |  30304MiB / 49140MiB |      0%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "|   1  NVIDIA RTX A6000               Off | 00000000:21:00.0 Off |                  Off |\r\n",
      "| 30%   45C    P2              82W / 300W |  15657MiB / 49140MiB |     11%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "|   2  NVIDIA RTX A6000               Off | 00000000:41:00.0 Off |                  Off |\r\n",
      "| 51%   77C    P2             294W / 300W |  42584MiB / 49140MiB |     77%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "|   3  NVIDIA RTX A6000               Off | 00000000:42:00.0 Off |                  Off |\r\n",
      "| 48%   73C    P2             284W / 300W |  32449MiB / 49140MiB |     89%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                            |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\r\n",
      "|        ID   ID                                                             Usage      |\r\n",
      "|=======================================================================================|\r\n",
      "|    0   N/A  N/A   2852658      C   python                                     1264MiB |\r\n",
      "|    0   N/A  N/A   3247148      C   ...e/vda/anaconda3/envs/mwp/bin/python    28668MiB |\r\n",
      "|    0   N/A  N/A   3250212      C   ...e/vda/anaconda3/envs/mwp/bin/python      360MiB |\r\n",
      "|    1   N/A  N/A   3250212      C   ...e/vda/anaconda3/envs/mwp/bin/python    15154MiB |\r\n",
      "|    1   N/A  N/A   3686483      C   python                                      494MiB |\r\n",
      "|    2   N/A  N/A   2852658      C   python                                    42578MiB |\r\n",
      "|    3   N/A  N/A   3518720      C   python                                     6204MiB |\r\n",
      "|    3   N/A  N/A   3666595      C   python                                    26236MiB |\r\n",
      "+---------------------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34a6282a193e9bda",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T12:53:33.283300Z",
     "start_time": "2024-08-03T12:53:33.279626Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e6a4c558c1f392",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-03T12:53:33.677009Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing: python stereoset_debias.py --model 'DropoutGPT2LMHeadModel' --model_name_or_path 'gpt2' --load_path '/home/ongzhiyang/bias-bench-main/results/dropout_FT/gpt2/checkpoint-100' --ckpt_num 100 --batch_size 1 --seed 42\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: DropoutGPT2LMHeadModel\r\n",
      " - model_name_or_path: gpt2\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: None\r\n",
      " - load_path: /home/ongzhiyang/bias-bench-main/results/dropout_FT/gpt2/checkpoint-100\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: None\r\n",
      " - seed: 42\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <|endoftext|>\r\n",
      "torch.Size([1, 1, 50257])\r\n",
      "100%|███████████████████████████████████████| 6392/6392 [07:32<00:00, 14.14it/s]\r\n",
      "Executing: python stereoset_debias.py --model 'DropoutGPT2LMHeadModel' --model_name_or_path 'gpt2' --load_path '/home/ongzhiyang/bias-bench-main/results/dropout_FT/gpt2/checkpoint-200' --ckpt_num 200 --batch_size 1 --seed 42\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: DropoutGPT2LMHeadModel\r\n",
      " - model_name_or_path: gpt2\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: None\r\n",
      " - load_path: /home/ongzhiyang/bias-bench-main/results/dropout_FT/gpt2/checkpoint-200\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: None\r\n",
      " - seed: 42\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <|endoftext|>\r\n",
      "torch.Size([1, 1, 50257])\r\n",
      "100%|███████████████████████████████████████| 6392/6392 [07:32<00:00, 14.13it/s]\r\n",
      "Executing: python stereoset_debias.py --model 'DropoutGPT2LMHeadModel' --model_name_or_path 'gpt2' --load_path '/home/ongzhiyang/bias-bench-main/results/dropout_FT/gpt2/checkpoint-300' --ckpt_num 300 --batch_size 1 --seed 42\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: DropoutGPT2LMHeadModel\r\n",
      " - model_name_or_path: gpt2\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: None\r\n",
      " - load_path: /home/ongzhiyang/bias-bench-main/results/dropout_FT/gpt2/checkpoint-300\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: None\r\n",
      " - seed: 42\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <|endoftext|>\r\n",
      "torch.Size([1, 1, 50257])\r\n",
      "100%|███████████████████████████████████████| 6392/6392 [07:37<00:00, 13.97it/s]\r\n",
      "Executing: python stereoset_debias.py --model 'DropoutGPT2LMHeadModel' --model_name_or_path 'gpt2' --load_path '/home/ongzhiyang/bias-bench-main/results/dropout_FT/gpt2/checkpoint-400' --ckpt_num 400 --batch_size 1 --seed 42\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: DropoutGPT2LMHeadModel\r\n",
      " - model_name_or_path: gpt2\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: None\r\n",
      " - load_path: /home/ongzhiyang/bias-bench-main/results/dropout_FT/gpt2/checkpoint-400\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: None\r\n",
      " - seed: 42\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <|endoftext|>\r\n",
      "torch.Size([1, 1, 50257])\r\n",
      "100%|███████████████████████████████████████| 6392/6392 [07:35<00:00, 14.02it/s]\r\n",
      "Executing: python stereoset_debias.py --model 'DropoutGPT2LMHeadModel' --model_name_or_path 'gpt2' --load_path '/home/ongzhiyang/bias-bench-main/results/dropout_FT/gpt2/checkpoint-500' --ckpt_num 500 --batch_size 1 --seed 42\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: DropoutGPT2LMHeadModel\r\n",
      " - model_name_or_path: gpt2\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: None\r\n",
      " - load_path: /home/ongzhiyang/bias-bench-main/results/dropout_FT/gpt2/checkpoint-500\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: None\r\n",
      " - seed: 42\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <|endoftext|>\r\n",
      "torch.Size([1, 1, 50257])\r\n",
      "100%|███████████████████████████████████████| 6392/6392 [07:33<00:00, 14.09it/s]\r\n",
      "Executing: python stereoset_debias.py --model 'DropoutGPT2LMHeadModel' --model_name_or_path 'gpt2' --load_path '/home/ongzhiyang/bias-bench-main/results/dropout_FT/gpt2/checkpoint-600' --ckpt_num 600 --batch_size 1 --seed 42\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: DropoutGPT2LMHeadModel\r\n",
      " - model_name_or_path: gpt2\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: None\r\n",
      " - load_path: /home/ongzhiyang/bias-bench-main/results/dropout_FT/gpt2/checkpoint-600\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: None\r\n",
      " - seed: 42\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <|endoftext|>\r\n",
      "torch.Size([1, 1, 50257])\r\n",
      "100%|███████████████████████████████████████| 6392/6392 [07:27<00:00, 14.29it/s]\r\n",
      "Executing: python stereoset_debias.py --model 'DropoutGPT2LMHeadModel' --model_name_or_path 'gpt2' --load_path '/home/ongzhiyang/bias-bench-main/results/dropout_FT/gpt2/checkpoint-700' --ckpt_num 700 --batch_size 1 --seed 42\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: DropoutGPT2LMHeadModel\r\n",
      " - model_name_or_path: gpt2\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: None\r\n",
      " - load_path: /home/ongzhiyang/bias-bench-main/results/dropout_FT/gpt2/checkpoint-700\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: None\r\n",
      " - seed: 42\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <|endoftext|>\r\n",
      "torch.Size([1, 1, 50257])\r\n",
      "100%|███████████████████████████████████████| 6392/6392 [07:25<00:00, 14.35it/s]\r\n",
      "Executing: python stereoset_debias.py --model 'DropoutGPT2LMHeadModel' --model_name_or_path 'gpt2' --load_path '/home/ongzhiyang/bias-bench-main/results/dropout_FT/gpt2/checkpoint-800' --ckpt_num 800 --batch_size 1 --seed 42\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: DropoutGPT2LMHeadModel\r\n",
      " - model_name_or_path: gpt2\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: None\r\n",
      " - load_path: /home/ongzhiyang/bias-bench-main/results/dropout_FT/gpt2/checkpoint-800\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: None\r\n",
      " - seed: 42\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <|endoftext|>\r\n",
      "torch.Size([1, 1, 50257])\r\n",
      "100%|███████████████████████████████████████| 6392/6392 [07:14<00:00, 14.70it/s]\r\n",
      "Executing: python stereoset_debias.py --model 'DropoutGPT2LMHeadModel' --model_name_or_path 'gpt2' --load_path '/home/ongzhiyang/bias-bench-main/results/dropout_FT/gpt2/checkpoint-900' --ckpt_num 900 --batch_size 1 --seed 42\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: DropoutGPT2LMHeadModel\r\n",
      " - model_name_or_path: gpt2\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: None\r\n",
      " - load_path: /home/ongzhiyang/bias-bench-main/results/dropout_FT/gpt2/checkpoint-900\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: None\r\n",
      " - seed: 42\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <|endoftext|>\r\n",
      "torch.Size([1, 1, 50257])\r\n",
      "100%|███████████████████████████████████████| 6392/6392 [07:18<00:00, 14.59it/s]\r\n",
      "Executing: python stereoset_debias.py --model 'DropoutGPT2LMHeadModel' --model_name_or_path 'gpt2' --load_path '/home/ongzhiyang/bias-bench-main/results/dropout_FT/gpt2/checkpoint-1000' --ckpt_num 1000 --batch_size 1 --seed 42\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: DropoutGPT2LMHeadModel\r\n",
      " - model_name_or_path: gpt2\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: None\r\n",
      " - load_path: /home/ongzhiyang/bias-bench-main/results/dropout_FT/gpt2/checkpoint-1000\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: None\r\n",
      " - seed: 42\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <|endoftext|>\r\n",
      "torch.Size([1, 1, 50257])\r\n",
      "100%|███████████████████████████████████████| 6392/6392 [07:32<00:00, 14.12it/s]\r\n",
      "Executing: python stereoset_debias.py --model 'DropoutGPT2LMHeadModel' --model_name_or_path 'gpt2' --load_path '/home/ongzhiyang/bias-bench-main/results/dropout_FT/gpt2/checkpoint-1100' --ckpt_num 1100 --batch_size 1 --seed 42\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: read).\r\n",
      "Your token has been saved to /home/ongzhiyang/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "Running StereoSet:\r\n",
      " - persistent_dir: /home/ongzhiyang/bias-bench-main\r\n",
      " - model: DropoutGPT2LMHeadModel\r\n",
      " - model_name_or_path: gpt2\r\n",
      " - bias_direction: None\r\n",
      " - projection_matrix: None\r\n",
      " - load_path: /home/ongzhiyang/bias-bench-main/results/dropout_FT/gpt2/checkpoint-1100\r\n",
      " - batch_size: 1\r\n",
      " - bias_type: None\r\n",
      " - seed: 42\r\n",
      "Evaluating intrasentence task.\r\n",
      "Unconditional start token: <|endoftext|>\r\n",
      "torch.Size([1, 1, 50257])\r\n",
      " 33%|█████████████                          | 2136/6392 [02:29<04:42, 15.07it/s]"
     ]
    }
   ],
   "source": [
    "# for ckpt_num in range(100, 2001, 100):\n",
    "for ckpt_num in range(100, 2001, 100):\n",
    "    command = f\"python stereoset_debias.py --model 'DropoutGPT2LMHeadModel' --model_name_or_path 'gpt2' --load_path '/home/ongzhiyang/bias-bench-main/results/dropout_FT/gpt2/checkpoint-{ckpt_num}' --ckpt_num {ckpt_num} --batch_size 1 --seed 42\"\n",
    "    print(f\"Executing: {command}\")\n",
    "    get_ipython().system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05ce7e3f026c729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ckpt_num in range(100, 2001, 100):\n",
    "for ckpt_num in range(100, 2001, 100):\n",
    "    command = f\"python stereoset_debias.py --model 'DropoutPhi2LMHeadModel' --model_name_or_path 'microsoft/phi-2' --load_path '/home/ongzhiyang/bias-bench-main/results/dropout_FT/phi2/checkpoint-{ckpt_num}' --ckpt_num {ckpt_num} --batch_size 1 --seed 42\"\n",
    "    print(f\"Executing: {command}\")\n",
    "    get_ipython().system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c3e6200c238659",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ckpt_num in range(100, 2001, 100):\n",
    "    command = f\"python stereoset_debias.py --model 'DropoutLlama2LMHeadModel' --model_name_or_path 'meta-llama/Llama-2-7b-hf' --load_path '/home/ongzhiyang/bias-bench-main/results/dropout_FT/llama2/checkpoint-{ckpt_num}' --ckpt_num {ckpt_num} --batch_size 1 --seed 42\"\n",
    "    print(f\"Executing: {command}\")\n",
    "    get_ipython().system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce08e857c6fd6081",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fyp] *",
   "language": "python",
   "name": "conda-env-fyp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
